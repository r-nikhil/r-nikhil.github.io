# http://rnikhil.com llms-full.txt

## AI and Gaming Insights
- [Will MCP stay for the long term?](https://rnikhil.com/2025/03/26/mcp-standard-llm) Mar '25
- [Introduction to AI agents](https://rnikhil.com/2025/03/14/intro-ai-agents) Mar '25
- [Quick thoughts on investing during tech cycles](https://rnikhil.com/2025/03/10/investing-tech-cycle) Mar '25
- [Diffusion models are interesting](https://rnikhil.com/2025/03/06/diffusion-models-eval) Mar '25
- [Quick thoughts on evaluating agents](https://rnikhil.com/2025/02/27/short-note-evaluating-agents) Feb '25
- [How much does a man need?](https://rnikhil.com/2025/02/18/tolstoy-man-need) Feb '25
- [How to make consistent cold coffees?](https://rnikhil.com/2024/12/19/cold-coffee-consistent) Dec '24
- [No, You can't bet on everything (and that's okay)](https://rnikhil.com/2024/12/18/prediction-market-crypto) Dec '24
- [How to (Accurately) Evaluate RAG Systems on Tabular Data](https://rnikhil.com/2024/09/22/rag-eval-tabular-data) Sep '24
- [Tackling the Explainability Gap in RAG Hallucination Evals](https://rnikhil.com/2024/09/22/rag-eval-hallucination) Sep '24
- [Unlocking Differential Privacy for >7B Parameter LLMs](https://rnikhil.com/2024/09/22/differential-privacy-llm) Sep '24
- [Integrating Explainable LLM Data Leakage Testing into your CI/CD Pipeline](https://rnikhil.com/2024/08/30/llm-eval-pii-membership-inference) Aug '24
- [Testing LLMs for Data Leakage Vulnerabilities](https://rnikhil.com/2024/07/31/data-leakage-llm-eval) Jul '24
- [Why do I write?](https://rnikhil.com/2024/01/07/why-i-write) Jan '24
- [Attacks on machine learning models](https://rnikhil.com/2024/01/07/attacking-neural-networks) Jan '24
- [AI Alignment - Weak-to-strong generalization (W2SG) explained](https://rnikhil.com/2024/01/04/ai-weak-strong-generalization-openai) Jan '24
- [Counterfactual Regret Minimization or How I won any money in Poker?](https://rnikhil.com/2023/12/31/ai-cfr-solver-poker) Dec '23
- [LLM security - Part 2](https://rnikhil.com/2023/12/22/ai-llm-security-part2) Dec '23
- [LLM security - Introduction](https://rnikhil.com/2023/12/18/ai-llm-security-part1) Dec '23
- [Building a chrome extension using only AI](https://rnikhil.com/2023/11/30/ai-coding) Nov '23
- [Chinchilla Paper explained](https://rnikhil.com/2023/11/28/llm-scaling) Nov '23
- [Farewell to the felt - Quitting the full-time Poker scene](https://rnikhil.com/2023/11/12/quitting-fulltime-poker) Nov '23
- [Gaming - Pre and Post launch checklist](https://rnikhil.com/2023/07/06/game-metrics-checklist) Jul '23
- [How to evaluate a game for your startup?](https://rnikhil.com/2023/05/14/evaluating-games) May '23
- [Do multi-gaming apps make sense?](https://rnikhil.com/2023/04/09/multi-vs-single-gaming) Apr '23
- [Some notes on Real Money Gaming (RMG) in India](https://rnikhil.com/2023/04/03/gaming-state-india) Apr '23
- [Classifying 2022 DeFi protocols](https://rnikhil.com/2023/01/26/enhancer-compounder) Jan '23
- [The magic words are squeamish ossifrage](https://rnikhil.com/2022/10/12/wolfram-crypto) Oct '22
- [A take on web3/DeFi](https://rnikhil.com/2022/09/01/my-take-crypto) Sep '22
- [Problem statements to solve for a retail investor in DeFi](https://rnikhil.com/2022/08/28/defi-user-journey) Aug '22
- [Make Poker fun again](https://rnikhil.com/2022/08/22/profit-growth-gamification) Aug '22
- [Derivative protocols in DeFi](https://rnikhil.com/2022/08/15/defi-derivatives) Aug '22
- [We should all have something to hide - Tornado cash takedown](https://rnikhil.com/2022/08/09/tornado-cash-block) Aug '22
- [Blockchain gaming - Current state](https://rnikhil.com/2022/06/27/web3-gaming) Jun '22
- [GTO Inspector - My attempt at building an online business](https://rnikhil.com/2022/06/15/gtoinspector-startup) Jun '22
- [New website theme, job and hobbies](https://rnikhil.com/2022/06/02/welcome-back) Jun '22
- [Luasec - Lua HTTPS Library](https://rnikhil.com/2017/08/23/luasec-https-library) Aug '17
- [A Secure Portknocking Implementation - Portsmith](https://rnikhil.com/2016/12/12/port-knocking-python) Dec '16
- [Sailor - A MVC framework in Lua](https://rnikhil.com/2016/05/03/sailor-lua-elasticsearch-admincenter) May '16

## About Nikhil
## About

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
| [Twitter](https://twitter.com/rnikhilcom) | [LinkedIn](https://www.linkedin.com/in/rnikhilcom/) | [HN](https://news.ycombinator.com/user?id=whoami_nr) | [GitHub](https://github.com/r-nikhil) | [Email](mailto:contact@rnikhil.com) |

Hey, I am Nikhil (நிக்கில்). I love to learn and hack around with new technologies. This site is a partial collection of stories I’ve written down, my general musings and the software I work on. There is no particular theme to this site; it’s just a place to hang random text.

Top 5 posts by views:

- [Attacks on machine learning models](https://rnikhil.com/2024/01/07/attacking-neural-networks.html)
- [Counterfactual Regret Minimization or How I won any money in Poker?](https://rnikhil.com/2023/12/31/ai-cfr-solver-poker.html)
- [Diffusion models are interesting](https://rnikhil.com/2025/03/06/diffusion-models-eval)
- [How to bundle different games?](https://rnikhil.com/2023/04/09/multi-vs-single-gaming.html)
- [We should all have something to hide - Tornado cash takedown](https://rnikhil.com/2022/08/09/tornado-cash-block.html)

#### Short resume

- 2025-Present
  - Doing some AI stuff at Accel
- 2024
  - Led product for DynamoEval. An LLM evaluation suite for detecting data leakages, hallucinations, compliance/goverance issues and other security vulnerabilities.
- 2018-2023
  - Led the product and business for the Poker app in Paytm and scaled it to a $10m biz
  - Trading and yeild farming across all DeFi protocols
  - Played professional poker (all.in adj 11bb/100), built a poker analytics tool startup and ran a coaching and staking operation
  - Started at Flipkart as a PM to build their data platform ingestion pipelines and BNPL product
- 2014-2018
  - Focus was on learning how computers work. Self taught programmer. Started with web dev but spent majority time on OS, computer security and network protocols. Contributed a ton to FOSS projects
  - Wrote malware shellcode obfuscators for OWASP and added packaet sniffing suport for Mathematica
  - Did [some](https://summerofcode.withgoogle.com/)[cool](https://owasp.org/www-community/initiatives/code_sprint/)[internships](https://education.wolfram.com/summer-school) with low acceptance rates

## Innovative Side Projects
## Random assortment of side projects

#### [**LLM Consortium**](https://llm-consortium.rnikhil.com/)

Send your prompt to multiple models and then ask a judge model to synthesize the final response. Based on this [tweet](https://x.com/karpathy/status/1869860858006049259) from Karpathy. Inspired by the [LLM consoritum](https://github.com/irthomasthomas/llm-consortium) project. There is a lot of scope to make the judge/arbiter model better by either using logprobs to evaluate confidence or by adding dynamic confidence weighting based on past responses.

![](https://rnikhil.com/assets/files/consortium.png)

#### [**GTOInspector**](https://www.youtube.com/watch?v=rv5AEZbo-XA)

A hand analysis software for poker professionals. Fix your weak points by uploading hand histories to be compared against game theory optimal(GTO) solutions. While building this, I also consulted and helpedpoker websites to combat fraud (multi-accounting, chip dumping, bonus abuse, collusion detection) and improve matchmaking efficiency.

![](https://rnikhil.com/assets/files/gtoinspect.png)

#### [**Twitter Meme Bot**](https://github.com/r-nikhil/twitterMEMEbot)

Pulls the latest tweets for a set of accounts, ranks them based on engagement potential and then creates a meme to be posted as a reply. Works with your twitter cookies. Uses [IMGFlip AI meme API](https://imgflip.com/ai-meme) and supermeme. GPT-4o rewrites/summarises the tweet into a prompt for the imagegen pipeline.

#### [**Resume writing crew**](https://github.com/r-nikhil/Resume-Agent-Crew)

Resume optimization project that uses AI agents(CrewAI) to enhance resumes based on company data and job descriptions. The system has four agents working collaboratively - a Resume Analyzer that examines the uploaded resume for key details, a Job Analyzer that scrapes and understands job requirements and company details from provided URLs or web search, a Resume Writer that optimizes the resume while maintaining authenticity, and a Quality Controller that oversees the entire process(can trigger rewrites, more web searches etc).

#### [**BAYC Clone bot**](https://github.com/r-nikhil/BAYCBOT)

An autonomous AI Twitter agent that engages in contextual conversations using OpenAI for text and Replicate (image model fine-tuned on BAYC art) for image generation. It maintains conversation history of recent interactions and intelligently decides between text and image responses when replying to mentions and threads.

#### [**Pomodoro timer**](https://pomodoro.rnikhil.com/)

25min timer for us folks who need tools to take a break or concentrate.

#### [**LLM Backroom Simulator**](https://simulator.rnikhil.com/)

Simulate backroom conversations with LLMs. Give each LLM a character or persona and watch them talk in a group chat. Fun for simulating rap battles between random personalities. Endless entertainment value if you know how to prompt the LLMs and give character definitions.

![](https://rnikhil.com/assets/files/baka.png)

#### [**Haiku Vision**](https://rnikhil.com/heli/)

three.js powered clone of the popular Flash helicopter game.

#### [**Helicopter game**](https://haiku-vision.rnikhil.com/)

Convert your camera feed into poetry. Takes an image and sends it to Claude Haiku asking it to generate a 3 line poem.

#### [**Habit tracker**](https://habits.rnikhil.com/)

Browser based habit tracker. All data is stored locally and perists across refresh. No login or sign up needed. A small tool which I use every day to track my streaks.

#### [**TODO app**](https://todo.rnikhil.com/)

Browser based todo app. All data is stored locally and perists across refresh. No login or sign up needed. A small tool which I use every day to track my todos.

#### [**Wolfram Mathematica**](https://github.com/r-nikhil/wolfram-2017)

Added a Network Analysis feature to Mathematica 11.3 to visualise the packet stream in a real time manner to help in debugging systems and network issues reducing average testing time by 30%. Notebook can be found [here](https://education.wolfram.com/summer/school/alumni/2017/ramesh/)

#### [**ZSC Tool Project**](https://github.com/OWASP/ZSC/commits/master/?author=r-nikhil)

ZSC is a Shellcode/Obfuscate Code Generator. I added support for 64 bit Windows (using PEB )in Assembly while also implementing the opcoder and support for various encodings to OS X shellcodes. Also built a code obfuscation module based on some flattening techniques.

#### [**Portsmith**](https://github.com/r-nikhil/Portsmith)

A secure Port Knocking Implementation in Python using single packet authorization. Uses TCP and IND-CCA secure requests to open a port on the server. Uses hping3 to craft TCP packets. The knock packet is encrypted using the key transferred from the server and then sent to the knockport. It is then decrypted and the required port is then opened for the sourceIP using a custom iptables command. There is an integrated SOCKS proxy to perform knocks before routing application traffic. Started work on a kernel module implementation using Netfilter hooks, nftables and cryptographic primitives instead of high level libraries.

#### [**Sailor Web Framework**](https://github.com/r-nikhil/sailor)

Integrated Elasticsearch with Sailor so that ES indexes can now be stored/searched as Sailor models. Developed a config editor to change configuration without downtime greatly easing the development workflow.GSoc 2016 work.

#### [**Luasec**](https://github.com/r-nikhil/luasec)

Added support for HTTPS CONNECT Tunnel, HTTPS Redirects, SNI tests and HTTP/2 support for Luasec HTTP networking library. GSoc 2017 work.

#### [**SSMS Portal**](https://github.com/r-nikhil/StarMash)

Billing and inventory management system used daily at all messes and canteens to handle transactions about 6 lakh Rupees monthly for all 4500 registered students.Written in PHP, MySQL.

#### [**PyGoogle**](https://github.com/r-nikhil/pygoogle)

CLI for Google search. This was useful back in 2012.

#### [**StarMash**](https://github.com/r-nikhil/StarMash)

FaceMash clone but with celeb photos scraped from IMBD

#### [**MicroTracer**](https://github.com/r-nikhil/microTracer)

System Call tracer for Linux based systems which displays the syscalls used by a particular program in a neatly formatted manner without the complex details as shown by programs like strace.

#### [**PintOS**](https://github.com/r-nikhil/pintos)

Extended the OS by adding virtual memory, message passing queues, POSIX threads and OS-level semaphores. Implemented “fork” and “exec” system calls and the ability to run user program. Implemented indexed filesystem, hierarchical directory structure and buffer cache. IIRC, this is part of some CS course at Stanford.

#### **Tracker**

It is to help developers jump start developing any kind of mobility tracking applications. Tracker let’s any type or number of GPS enabled endpoints to send data to a NodeJs server which then maps their location history using Google Maps API.

#### **Peer to Peer Streaming Protocol**

Was involved in the building a statistics module for an application layer streaming protocol in Python. It records information related to the stream, number of peers (audience) per minute, in/out of peers, total peers, etc. Wrote a graphical interface for viewing the numbers built using d3.js. Learnt a bunch about WebRTC

## Search Options
## Search

## Sailor Framework Enhancements
## Sailor - A MVC framework in Lua

I will be working with Lablua this summer as part of Google Summer of Code (GSoC). I shall be extending the Sailor framework by adding an centralized configuration editor and adding integrations to facilitate Elasticsearch indexes to be stored as Sailor Models. Sailor is a Web Framework. View the proposal [here](https://rnikhil.com/assets/files/LabLua%20GSoc%202016%20Proposal%20-%20Nikhil.%20R.pdf)

### What is a [Web Framework](https://en.wikipedia.org/wiki/Web_framework) ?

From Wikipedia,

> > A web framework (WF) or web application framework (WAF) is a software framework that is designed to support the development of web applications including web services, web resources and web APIs.As it says, it’s basically used to remove the same redundant overhead associated with creating web applications. Most web applications have/do the following things

- Database access, mapping, configuration
- Session Management
- User Interfaces
- Secure authorization and authentication
- URL routing/mapping

Web frameworks promote code re-use by providing easy ways to do the above mentioned stuff. They differ in each other in their architectural pattern, the most common one being the M(Database logic) V(User Interface) C(Business logic) [MVC architecture](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller).

I will be working on a Web Framework named [Sailor](http://sailorproject.org/) this summer.

### Sailor

Sailor is a web development framework and all applications are structured in a MVC(Model-View-Controller) architecture. It uses a Javascript virtual machine for use of Lua in the browser if required. An example of the JS Virtual Machine can be found [here](https://github.com/paulcuth/starlight)

### Features

- Compatible with Lua 5.1, Lua 5.2 and LuaJIT
- MVC Structure
- Routing
- Friendly URL’s
- Lua at Client using JS virtual machines deployed with the application
- Model generation from the database
- CRUD function generation using the models
- Validation module
- Object relational mapping( [ORM](https://en.wikipedia.org/wiki/Object-relational_mapping) layer for the database)
- Form Generation
- Integrated Themes and layouts
- Runs on both nix and windows

### What exactly am I doing for Sailor ?

**Centralized configuration editor**

Most web frameworks generally have an admin center for editing configuration files, making controllers, models etc. Sailor has autogenerator fucntions which create models and controllers for you. My task is to encompass a configuration file editor, the autogen functions inside a protected environment for use in development.

**Elasticsearch Integration**

[Elasticsearch](https://www.elastic.co/products/elasticsearch) is a search database server based on [Apache Lucene](https://lucene.apache.org/). It can be used to search all kinds of documents. It provides scalable search, has near real-time search, and supports multitenancy(One instance of a software being shared by multiple users).

There is a low level client for this in lua called [elasticsearch-lua](https://github.com/DhavalKapil/elasticsearch-lua) and I shall be integrating this into Sailor. Once done, you can search an elasticsearch instance using the form module in Sailor. You can also use Elasticsearch indexes as Sailor Models.

Edit: I worked on these features and you can see the corresponding pull request [here](https://github.com/sailorproject/sailor/pull/125).

May 3, 2016 · [coding](https://rnikhil.com/tag/coding), [lua](https://rnikhil.com/tag/lua), [GSoC](https://rnikhil.com/tag/GSoC), [web](https://rnikhil.com/tag/web), [elasticsearch](https://rnikhil.com/tag/elasticsearch), [internship](https://rnikhil.com/tag/internship)

## Secure Port Knocking
## A Secure Portknocking Implementation - Portsmith

[Source](https://github.com/r-nikhil/Portsmith)

[Port Knocking](https://en.wikipedia.org/wiki/Port_knocking) is a concept where the ports on a particular computer appear to be closed until a special packet/port knock sequence is established. It is a method of externally opening ports in a system by doing a sequence of connection attempts on a set of pre-specified closed ports. Once a correct sequence of connection attempts is made, the firewall rules are dynamically modified to allow the external system to connect to a specified port. This concept has been around for a long time and you can check out some implementations [here.](http://www.portknocking.org/view/implementations)

### Why?

I had a server on Digital Ocean(DO) which kept getting pwned and used for DDosing some poor soul. DO used to shut down networking for my node every four days or so. At least I think this was the case since I had some unauthenticated services running on it. I was using the server as a proxy with an open port on the server at all times. Maybe a botnet was spreading by scanning the network for vulnerable hosts and then exploiting them ? I am not sure. DO has to figure that out.

Anyway, I decided to do something about it and when searching for a method to obscure networking services, I found PortKnocking.

The purpose of this was to prevent port scanners from scanning target systems for exploitable services. The ports appear closed unless the attacker sends the correct knock sequence/packet to the machine. Initially, it was supposed to be a series of connection attempts or knocks on a series of ports but this kind of mechanism was vulnerable to replay attacks. A person watching the network could easily figure out which ports are knocking before a connection is established.

### Implementation

Warning: This project is not ready to be used in production. This is version 0.1(alpha). There are still bugs to be fixed and edge cases to be handled. I would continue working on this in my free time.

#### Server side:

Requirements:

- Python 3
- Cryptography module ( this need OpenSSL too)

Instead of making the client ping a couple of ports, I decided to close all ports and log all connection attempts to these firewalled ports to /var/log/kern.log. I plan to send one encrypted packet to the server which contains the details for the port to be opened. I parse kern.log to to find my encrypted packet and authorize clients.

There is a small script running a bunch of iptables command to close all ports and reject all incoming connections.

First step would be creating keys for each client. I call this profiles. One user can have multiple laptops connecting to the same server.

```
sudo python3 create-profile.py profilename portnumber

```

This creates a folder at ‘/etc/portsmith.d’ and also a subfolder with the profile name. The subfolder contains two files. One is the encryption key which must be kept secret and other is the knockPort which the client has to knock.

The encryption key is a URL-safe base64-encoded 32-byte key. This must be kept secret. Anyone with this key will be able to create and read messages. This folder has to be transferred to the client computer securely using ‘scp’ or some other method.

After this, the server can start listening for knocks.

```
sudo python3 server.py

```

#### Client side:

The Knocker:

```
sudo python3 knocker.py portToOpen host

```

I use hping3 to craft TCP packets. The knock packet is encrypted using the key transferred from the server and then sent to the knockport. It gets logged into kern.log which is read by Portsmith. It is then decrypted and the required port is then opened for the sourceIP using a custom iptables command.

As you can see above, there is hardly any complex logic involved in PortKnocking. There are implementations ranging from simple bash scripts to fully featured C servers which inspect all incoming packets using libpcap. I didn’t want an another extra network service running since this is against the whole point of PortKnocking in the first place.

### TODO

1) It currently uses [Fernet](https://cryptography.io/en/latest/fernet/) Symmetric Encryption Library from the cryptography package. It’s source and spec can be found [here](https://cryptography.io/en/latest/_modules/cryptography/fernet/) and [here](https://github.com/fernet/spec/blob/master/Spec.md) respectively. It uses:

- AES in CBC mode with a 128 bit key for encryption; using PKCS7 for padding
- HMAC using SHA256 for authentication

This is a high level library. I would like to rewrite the cryptomethods using cryptographic.primitives instead. Maybe try out AES in CTR mode ? Either way, the crypto methods are going to be rewritten using low level (hazmat :P) functions. I think this would be good learning experience.

2) Support for multiple profiles on the server. This is almost done.

3) Check and add user permissions when accessing directories, running system commands and changing iptables rules.

4) Fork out the code which has to be run as root and separate it. This would increase security and take the project closer to be used in production.

5) Right now, it only opens ports. It should also close ports after a specified window if there is no successful connection. Also, handle a lot of exceptions and edge cases.

6) Make a daemon for running on the server.

7) I had implemented a simple socks proxy. It performs the required knocks, makes sure the port gets opened before sending the application data to the particular server. Any application supporting socks proxy could technically use it but I couldn’t get it to work properly. Work on the proxy.

7) REWRITE as a kernel module ???? I remember seeing a patch for the linux kernel implementing Portknocking somewhere. Would be amazing if someone could link me to it.

December 12, 2016 · [coding](https://rnikhil.com/tag/coding), [python](https://rnikhil.com/tag/python), [network](https://rnikhil.com/tag/network), [security](https://rnikhil.com/tag/security), [linux](https://rnikhil.com/tag/linux)

## Luasec HTTPS Library
## Luasec - Lua HTTPS Library

I was working on the Luasec library over the summer mainly on fixing the HTTPS redirects, the CONNECT proxy implementation (for redirecting requests over the HTTP CONNECT tunnel) and adding support for HTTP/2(Client).

My fork of Luasec(dev branch) can be found [here](https://github.com/whoami-nr/luasec/tree/dev) which has all the recent updates as part of GSoC and all the relevant commits.

### Work done till now

**HTTPS Module**

I was working to add features for the HTTPS module during the first part of GSoC. It now supports the ability to talk HTTPS with a proxy, redirects through or without the proxy for HTTPS URLs, certain low level HTTP API functions are exposed and also supports SNI now. Work done in this section are relevant to this [file](https://github.com/whoami-nr/luasec/blob/dev/src/https.lua).

- CONNECT proxy support for HTTPS. Now Luasec can be used to initiate a CONNECT tunnel to a HTTP proxy which enables the proxy to relay encrypted packets between Luasec and the final destination. This also works when redirects are enabled. While redirecting HTTPS->HTTPS or HTTP->HTTPS or HTTPS->HTTP(if the unsaferedirect paramter is set) it creates a new tunnel with the proxy for the new redirected destination.

- Support for HTTPS redirects with an additional safeguard for preventing unsafe redirects from HTTPS->HTTP. This involves usage of the `unsaferedirect` paramter.

- Merge and refactor the HTTP module from luasocket into luasec thus unifying the HTTPS module. All the HTTP low level functions have been imported into luasec now. This was done to increase code reuse within the library.

- Test server name indication so that it conforms to section 3.1 of RFC 3546 which can found [here](https://www.ietf.org/rfc/rfc3546.txt).


More details on how to use it and references for the functions can be found on the wiki page of my fork [here](https://github.com/whoami-nr/luasec/wiki/Luasec-HTTPS-Module).

**HTTP/2 Module**

This portion of the module was worked on during the second part of GSoC. I went by implementing RFC’s sequentially while also trying to make sure that I had a basic implementation for sending and receving frames working all along. Work done in this section are relevant to these files.

[1) Error Module](https://github.com/whoami-nr/luasec/blob/dev/src/http2_error.lua)

[2) Stream Module](https://github.com/whoami-nr/luasec/blob/dev/src/http2_stream.lua)

[3) Codec Module](https://github.com/whoami-nr/luasec/blob/dev/src/codec.lua)

[4) Bit Operation Module](https://github.com/whoami-nr/luasec/blob/dev/src/bit.lua)

The Codec Module is used for string packing and unpacking. It provides a unified interface for various modes in `string.pack` and `string.unpack` functions. The Bit operation module smoothens out all the various lua bit libraries and versions. The `bit` libary with luajit, `bit32` libary with lua 5.2 and lua 5.3 built in bit operators are wrapped in a unified function.

The RFC I used can be found [here](http://httpwg.org/specs/rfc7540.html). I also used the lua-http module for lot of reference code. The module can be found [here](https://github.com/daurnimator/lua-http/). The Bit operation module, error module was taken from lua-http and modified to work with luasec. The stream module has certain functions which are taken from lua-http with the cqueue dependency removed and modified to work with luasocket.

The first two sections in the RFC are just an introduction and a generic protcol overview.

1) [Section 3](http://httpwg.org/specs/rfc7540.html#rfc.section.3)

- It deals with starting a HTTP/2 connection.

- Starting HTTP/2 for HTTP url’s (No TLS) involved implementing a upgrade mechanism which informs the server of the upgrade request. For TLS connections the socket is just wrapped with luasec.

- The connection preface is sent after both the client and server have decided to use HTTP/2.

- This section has been completely implemented.


2) [Section 4](http://httpwg.org/specs/rfc7540.html#rfc.section.4)

- It deals with support for all the relevant frame types.

- The HTTP/2 connection module implementing ( send and receive frame functions) the support for sending basic frames like SETTINGS, HEADERS etc has been finished. It supports

- Add a HTTP -> HTTP/2 negotiation scheme so that upgrade requests can be sent from Luasec.

- Maintain a Header table on the client side for implementation of HPACK later on.

- Recieve a process a SETTINGS frame and then also send back a SETTINGS ACK frame thus establishing the stream parameters.

- Implemented functions for writing priority(which specifies the sender advised priority of the stream), rst\_stream (which allows for immediate termination of stream), ping(which helps measure the minimal roundtrip from the sender as well as for determining whether an idle connection is functional), data(which sends http data), headers(which sends http headers), window\_update frames(which is used for implementing flow control), settings( stream session settings), push\_promise(which notifies the peer endpoint in advance of stream the sender intends to initiate) etc. to the socket. All these functions are documented in the wiki.


3) [Section 5](http://httpwg.org/specs/rfc7540.html#rfc.section.5)

- This section deals with Streams and multiplexing them over the same TCP connection or socket.

- This portion has been partially implemented. I tried making a non blocking version using copas for dispatching and creating a queue. It presently works with the `socket.select()` function from luasocket which it uses to wait on the socket to find out if it’s ready to be read or written to. There are basic definition for send and receive functions.

- There is a simple implementation of a priority queue. I set a priority flag and if it’s set I send up that stream first.

- Feature implementing the monitoring of stream states is also done which enables the module to be aware of the stream state and respond accordingly.


4) [Section 6](http://httpwg.org/specs/rfc7540.html#rfc.section.6)

- This section deals with the different frame types and their definition.

- This portion has been completely implemented. The `send_frame` function in the module supports all the 10 types of frames.


_Section 7_ deals with the error module for which I have added a basic module which can be found [here](https://github.com/whoami-nr/luasec/blob/dev/src/http2_error.lua).

_Section 8_ deals with HTTP/2 connection management and deals just with specifying which frames have been used for what kind of requests and what to do when we receive a response. I used this section as a reference for implementing my HTTP/2 connection module. Other sections in the RFC are also just considerations and references for a good implementation.

One of the most important part of this was reading RFC’s and learning to adhere to the specs. Also learnt a lot about debugging a network protocol implementation while getting to know the internals. More details about the implementation and references can be found in the [wiki](https://github.com/whoami-nr/luasec/wiki/Luasec-HTTP-2-Module).

* * *

### Work to be done

- Remove the fake connection object from the HTTPS module which become pointless after the integration.

- Make the connection module non blocking.

- Try to merge the existing PR supporting the ALPN negotiation scheme.


### Roadmap for the HTTP/2 implementation and future work

I have been implementing HTTP/2 based on the RFC going through it one by one. I took a lot of template code from the lua-http module which can be found [here](https://github.com/daurnimator/lua-http/). Certain modules from lua-http were imported without much changes but have been modified to work with luasec. The `connection:methods` and `stream:methods` are mostly based on lua-http module which I have worked on to work with luasocket.

[Section 7](http://httpwg.org/specs/rfc7540.html#rfc.section.7) deals with HTTP/2 error codes for which we have to implement a module specifying the same. Based on this module it also has to be linked with the existing implementation so that all the error’s (essentially error messages) get redirected to it and we receive proper error messages for debugging effectively.

[Section 9](http://httpwg.org/specs/rfc7540.html#rfc.section.9) deals with Additional HTTP/2 requirements like connection management, setting up and following a priority tree and connection reuse.

August 23, 2017 · [coding](https://rnikhil.com/tag/coding), [lua](https://rnikhil.com/tag/lua), [GSoC](https://rnikhil.com/tag/GSoC), [network](https://rnikhil.com/tag/network), [linux](https://rnikhil.com/tag/linux), [internship](https://rnikhil.com/tag/internship)

## Website, Job, and Hobbies
## New website theme, job and hobbies

- Its been a while since I updated the website. While trying to setup a Jekyll environment, I ended up in dependency hell and decided to just boot the entire ruby installation instead of fixing the circular configs. This time, I am using a theme called [Minima](https://github.com/jekyll/minima) in its dark mode version. You may notice some parts of the website still broken or unfinished. Apologies!

- I would also be uploading posts/notes which I’ve wanted to share earlier while I was building my startup in poker (spoiler alert: It didn’t work out). It was a post game study tool for PLO professionals.

- I am currently working on building the poker product at [Paytm First Games](https://firstgames.in/) under [Abhishek Kumar](https://mobile.twitter.com/shakyabhishek). We recently launched tournaments and PLO is coming next. After I wrapped my startup, I was looking for opportunities in the poker ecosystem and this was a perfect one. Will be writing more about my work here in future posts.

- In my spare time, I’ve been building some arb bots using Flashbots trying to capture [MEV](https://ethereum.org/en/developers/docs/mev/). I’ve started doing this after losing a significant percent of my net worth in the recent crash yield farming and leverage trading shit coins. I don’t play much PLO these days apart from some private games.


June 2, 2022 · [blog](https://rnikhil.com/tag/blog), [gaming](https://rnikhil.com/tag/gaming), [job](https://rnikhil.com/tag/job), [product](https://rnikhil.com/tag/product), [crypto](https://rnikhil.com/tag/crypto)

## GTO Inspector Startup
## GTO Inspector - My attempt at building an online business

This document explores the hypothesis and my experience running an online business in the Indian poker ecosystem.

- Quick rundown of events:

  - It is 2019 and I’ve been playing poker for about a year (it all started after I won a big tournament through a satellite right out of college). I then went and joined [Indian Poker Pros](https://www.indianpokerpros.com/) (now defunct) to be staked and coached by them. Although I was crushing mid stakes MTTs comfortably; most of my shot taking didn’t work out because I was severely let down by my inability to put in volume partly due to my day job at Flipkart. Grinding a 9hr day job and 10hrs of poker takes a toll on body and mind as well.

    - Due to aforementioned reasons, I moved to [PLO cash](https://www.pokernews.com/strategy/plo-poker-beginner-guide-pot-limit-omaha-23724.htm) for a flexible time schedule and a possible bigger edge vs opponents (Indians were studying MTTs harder than PLO).
  - Sometime in 2020, I quit my job to focus on poker full time. Along the way, I met an amazing poker player named [Kunal Agarwal](https://in.linkedin.com/in/kunal-agarwal-7b6a76162) and we built some tools to help improve my own game(he was my coach) and one such tool picked up steam in my stable across PLO players. Kunal had a bunch of scripts for analyzing our post game history and I worked alongside him to build a productized version of the software which is sellable to poker stables and professional players. While I won’t go into the details of the product in this post, you can watch a quick demo/tutorial video that I made, here:

GTO Inspector Tutorial - YouTube

GTO Inspector

6 subscribers

[GTO Inspector Tutorial](https://www.youtube.com/watch?v=VdmHds-lylY)

GTO Inspector

Search

Watch later

Share

Copy link

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

More videos

## More videos

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

[Watch on](https://www.youtube.com/watch?v=VdmHds-lylY&embeds_referring_euri=https%3A%2F%2Frnikhil.com%2F)

0:00

0:00 / 3:06•Live

•

[Watch on YouTube](https://www.youtube.com/watch?v=VdmHds-lylY "Watch on YouTube")

#### What problem are we solving?

- While there are coaches doing post game hand analysis and hand reviews, there was no systemic/automated way to figure out how much a player is deviating away from [GTO](https://upswingpoker.com/glossary/gto/) and how much money he/she is losing because of it. Preflop poker studying is broken.

- A tool which narrows down pre flop mistakes super fast in an accurate fashion at a position\*action level would help the player improve in preflop PLO (which is super hard to study, 270k starting hands vs 1.3k in NLHE ).


#### Why?

- There was no such tool available in the market to help professional poker players. Serious players will pay real money for this because of the direct impact on their bottom line.

- We had already built a crude version for my own personal use. Other professionals wanted it and it was easy for me to start a poker business starting from this PLO tool.

- **Market potential**

  - All professional PLO players in the world given we are making a global product. [Jnandez](https://plomastermind.com/) showing his financials sort of helped clarify the scope of the market as well. Coaching is super high ARPU business.

#### How?

Validation approach

1. Distribute the crude version among the poker stable members (About 10 folks)

   - Everybody loved the tool and wanted a full fledged dashboard. Coaches were willing to pay me to work on this full time (apart from my coaching fees on newer players)
2. Given the positive feedback from my circle (read: bubble), and the market potential, we went ahead building a MVP of the tool. The idea was to first launch the PLO version and then eventually expand into more popular game formats like NLHE/Tournaments.


GTM

- We ended up building a small internet business around the product selling to PLO professionals in India, Europe and Mexico. Our early acquisition costs were high but we didn’t pay heed due to high premiums we were charging in the early days (mostly high stakes regs)

  - _Lesson_ : Keep a close eye on the acquisition channels and their corresponding costs from early on. A simple forecast would have helped us avoid some expensive mistakes (Lot of paid marketing)
- Within the first month, we had almost every professional PLO player in India as a customer. Initial customers loved it.

  - Notable Anecdotes:
    - _“A PLO professional”_: I found out I was leaking close to 25bb/100 cold calling 2bets which I didn’t realize before. Made me tighten up and study by calling ranges again.

    - _“A seasoned recreational PLO player”_: After you made me upload my Adda52 hand history of 3L hands, I understood that playing GTO makes money in the long run. Knowing that I am not skilled to deviate profitably from GTO has been eye opening.
- When we tried to scale the business, the obvious issues started showing up. They included high acquisition costs, bad retention rates for foreign players and the general lack of a sizable market for such a product.


#### Conclusion

I had a couple paths forward after reaching monopoly in the Indian PLO market. I could continue scaling the PLO tool or build newer poker tools for bigger audiences.

- Sell the PLO tool to more players (India and abroad)

  - Recreational players found it expensive and hard to learn the terminologies

    - One direct solution was to start building PLO education content around the product and give it away for free. I personally did not find this enjoyable to work on. Re-visiting the basics didn’t seem fun to me.

      - I could also take in interested players, coach them using my tools, in return for their future profits. I eventually ended up starting a poker stable (a staking operation. Same concept as prop trading firms) structured around this tool and other such proprietary tools to monetize the new-to-poker-theory players and PLO regulars wanting to improve/get staked.

      - **This ended up working out super well and still does to some extent. At its peak we had 15 students playing for us.**
  - Professionals abroad found it basic

    - This was expected. I had a long roadmap of cooler stuff I wanted to build and monetise. I had crude python scripts ready for studying post flop GTO as well.

    - Never got there due to the way I decided to scale the business. The entire thing was also bootstrapped by friends plus I was running out of patience.
  - Recreational players abroad are super expensive to acquire and retain

    - Supporting multiple poker web site hand history formats and building hand converters also became a nightmare with our limited engineering bandwidth
- Build more poker tools for popular variants like NLHE and tournaments

  - My experience trying to scale the PLO business made me understand how small the entire market is. Definitely wasn’t worth the time and effort. I was no longer naively optimistic.

  - I was asked super often to build a version of the tool for MTTs by my poker friends. Glad I didn’t blindly follow my customers.
- Start monetising other proprietary tools (custom built for my staking operation) by selling it to poker websites

  - We had built some chip dumping and collusion detection tools to help our stable players identify profitable tables. On the flip side, there was demand from poker companies willing to use this to find multi-accounters, colluders, bonus chip abusers, RTA users etc.

    - **I ended up personally consulting and working with leading poker sites in India to build their anti-fraud systems.**
- Continue selling it to stables and professionals and figure different opportunities

  - I ended up doing the above two.

  - While I was exploring options, I was reached out by a recruiter looking to hire somebody to build their poker business at Paytm. I found this to be decent opportunity to learn the ropes of building a scalable business and joined them at the start of 2022

#### Afterthought

- If I have to do it all over again, I would:

  - Definitely pick a better market. Poker needs to grow as a game globally before there is a meaningful sized market for study tools especially in a country like India. I wasn’t okay serving just 100 customers.

  - Experiment faster. I wasted a lot of time perfecting the tool for my initial PLO customers. PG argues the [opposite](http://paulgraham.com/ds.html), but with a different context. Airbnb folks eventually had a massive market to get into which I didn’t have.

June 15, 2022 · [gaming](https://rnikhil.com/tag/gaming), [startup](https://rnikhil.com/tag/startup), [product](https://rnikhil.com/tag/product), [poker](https://rnikhil.com/tag/poker)

## Web3 Gaming Insights
## Blockchain gaming - Current state

A lot has been said and done about the feasibility of web3 gaming. Hyperbole stuff like _“Decentralized games”, “P2E is the future of gaming”_, etc are great marketing content but fall short rapidly when examined closely. After seeing loads of money being invested into such projects, I was curious as a gaming PM to understand the thesis behind them. This post looks at the feasibility of various projects and the ideas behind them. While I don’t intend to take sides, I personally haven’t seen a legitimate use case for mixing blockchains and gaming **yet**. On a high level, the use cases can be classified like this:

1. Decentralized financial stuff inside games
2. Asset sharing and interoperable games
3. Game dev DAOs
4. Decentralized game distribution infra
5. **ACTUAL** decentralized games

Popular ways to bake in financial mechanics inside games are usually in the following manner:

- Play to earn gaming

  - The current play-to-earn model is unsustainable because it relies too much on money coming in. When there are no new investors, the scheme collapses and leaves investors, in particular the new ones, holding the bag. (basically a ponzi scheme)

  - Mixing economic incentives with games makes them unenjoyable. Users play games to escape reality and forcing you to grind there might make them actually feel like “work”. There exists a subclass of games where players compete to win and they are totally different. (card games, e-sports, etc). There are numerous reports of drop in Axie infinity DAU when the potential for money making reduced further emphasising the fact that people were playing to mainly earn/speculate rather than to actually enjoy the game

  - Here is an article from STEPN which further explores the ponzi nature of the current P2E games: [“Are all play-to-earn games Ponzi?”](https://stepnofficial.medium.com/are-all-play-to-earn-games-ponzi-a2ddcc31db29)
- Pay to win

  - This is basically implemented as micro transactions in the current industry. Its widely hated by all kinds of players.

  - The most downvoted comment on reddit is basically EA trying to justify micro transactions on Star Wars Battlefront.

    - EA sets a Guinness world record: https://www.thegamer.com/ea-guinness-world-record-most-downvoted-reddit-comment/
    - ![Reddit EA ](https://rnikhil.com/assets/files/reddit.png)
- There are other games with financial mechanics inside them but they are basically gambling/betting/trading platforms.


Apart from baking in financial mechanics, another common use case for blockchains inside games(or games inside blockchains) is interoperability and asset sharing between games.

- Imagine a world where you can use your car from RocketLeague on Mario kart. Even if one of the game shuts down, all your assets and achievements can be used/traded for in a different game. This is very hard to implement in real practice because thousands of game developers have to come together to agree on a standard to build assets on. Now, to enable this in an decentralized manner is a monumental task with some super complex infra requiring large amount of upfront capital.

- [Forte.io](https://forte.io/) is trying to solve this problem by building the common base Infra. They have raised about a [billion dollars](https://www.businesswire.com/news/home/20211112005457/en/) and have folks from gaming industry working on it. Maybe they go down this path and figure out a legitimate use case. [Topology.gg](https://topology.gg/) is trying the above as well. [Fractal.is](https://www.fractal.is/) is another startup from Justin (ex twitch founder) for building common sharable collectables for games.

- Folks behind Unity or CryEngine3 or Unreal Engine or any gaming engines could come together and bake in something like this in their SDK for faster adoption.


If you can’t put the games on blockchain (they require ridiculous amount of compute and we have ETH doing 15txn per second) or money inside games, people have also tried to structure game studios as a DAO

- I see no exact reason for this. Why have a slow and decentralized org structure to make a centralized game? Its also comedic how many DAO’s think they can make the next GTA V with just 5 Million dollars

- However, I can see some creator focused games which can function as a DAO for better monetization and creative control. Stuff like custom Minecraft mods , Roblox, Garry’s mod can benefit from this. However, I would bucket this use case under web3 for creator economy rather than gaming


Decentralized game distribution infrastructure is a legitimate use case (any decentralized file distribution for that matter) but beating incumbents like Steam would be a long and arduous task. You can maybe operate in a niche - SEGA emulator games on IPFS/Filecoin.

Finally, most of the _web3 games_ are currently centralized and don’t use any meaningful decentralization mechanism.In most games, the NFT’s are traded/stored on-chain whereas the game is still centralized, controller and developed by a single body. The wider decentralized gaming infrastructure will need peer-to-peer game clients (run by the players), decentralized storage layers, dedicated execution layers etc. This is a legitimate use case where we are super early.

Games built and hosted on smart contracts with procedurally generated worlds have some cool possibilities which can be only accomplished inside a shared state machine like EVM. Check out [Dark Forest](https://dfwiki.net/wiki/Main_Page) for an early example on this. It is a universe-traversing, planet-capturing, real-time strategy game. The inspiration for the Dark Forest game is based on the novel of the same name, [The Dark Forest](https://en.wikipedia.org/wiki/The_Dark_Forest). It is an open-source game, and all interactions within the game are validated by the Gnosis (previously xDai) blockchain.

It is also the only game to utilize [zkSnarks](https://en.wikipedia.org/wiki/Non-interactive_zero-knowledge_proof) as a mechanic - the in-game fog of war.

### Conclusion

Blockchains are useless for most games, but they can be used to enhance certain aspects, in specific cases. Censorship resistant game distribution, asset sharing, games on smart contracts are some areas where it may work. Current NFTs, GameFI etc are justifiably hated by the larger gaming community for the fact that they don’t add any real value yet.

Did I miss any use case? Am I short sighted about something? Do let me know by writing to me [here](mailto:contact@rnikhil.com) or tweeting to me [here](https://twitter.com/rnikhilcom)

June 27, 2022 · [crypto](https://rnikhil.com/tag/crypto), [gaming](https://rnikhil.com/tag/gaming), [web3](https://rnikhil.com/tag/web3), [opinion](https://rnikhil.com/tag/opinion)

## Tornado Cash Blacklisting Insights
## We should all have something to hide - Tornado cash takedown

[HN Discussion](https://news.ycombinator.com/item?id=32403504)

> ” If you have nothing to hide, you have nothing to fear”

This is a common saying parroted by folks (made popular in the US after 9/11) for justifying many types of surveillance. It is also sometimes mistakenly used to justify the current blanket surveillance we all are a victim of. With the development in technology and rapid increase of surveillance budgets, law enforcement has gotten a lot easier as well.

Recently, Tornado cash, a [mixer website](https://en.wikipedia.org/wiki/Cryptocurrency_tumbler) used to obfuscate the origin and destination of your money has been [blacklisted](https://home.treasury.gov/news/press-releases/jy0916) by the US Treasury. The implications prevent anybody from transacting with them which means, all the money held in their smart contract is effectively tainted. Funnily enough, they blacklisted only the contract address on the Ethereum but not the contract on Arbitrum or BSC. While it is no secret that this service was used by criminals (like DPRK) to launder their money, there are some legitimate use cases for such a product as well.

Since all transaction data is on-chain (which is public) and can be queried by anybody, it poses serious risks to privacy of individuals. Connecting their wallet address with their real life identity and to their rest of of their transaction data leads to some disturbing scenarios like:

- Any (d)app you use will instantly know your entire transaction history

  - Imagine you sign up with your email on a random website and they suddenly now have access to your entire bank statement. Higher medical insurance premiums because they know that you transacted often in an online pharmacy. Expensive delivery charges because they know you can afford it.
- Any donations to a controversial cause (which is legal) is attached to you but you don’t want to handle the repercussions

  - You don’t want your patriotic Russian neighbors knowing that you donated to the Ukraine fund or your co-workers knowing that you donated to a particular political party
- Everybody will know your net worth

- Your employer will know how exactly you spend your funds.


These are just use cases which are commonly known and well extrapolated already. However, there are so many scenarios and use cases which we haven’t even discovered yet as a society which one day which be also legitimate and common.

For example, In the last decade, there has been an increasing number of headline-grabbing legal changes everywhere in the world: growing number of countries are working towards legalizing marijuana and same-sex marriages. While people laud these countries for being forward thinking and developed, these “legal” victories were mostly improbably without the ability to break the law at some point. If we lived in a dystopian future where the cops are 100% effective such that any and all law offenders would be caught magically, the above changes may not have come to happen. How would the country legalize a drug if nobody has ever used it? How could states decide that same sex marriage should be permitted, if nobody had ever seen or participated in a same sex relationship?

We can only desire for a change based on what we know. If our present experiences are limited and controlled tightly, its gets harder to understand what is possible and should be allowed. In a liberal democracy, these marketplace of possibilities are presented in front our political system to eventually made into laws based on what the society wants. This is why illegal drug consumption is a necessary pre-condition to eventual drug legalizations. Even the internet originally was used for illegal commerce and was shunned away from adoption.

While I digressed (ranted) away on the reasons why such bans are bad, the current scenario poses some other questions as well:

- What happens to the FOSS developers who contributed to the project? Are they sanctioned as well?
- What will happen to the tainted money? This figure is about $400M. I expect a secondary market for TCtETH (Tornado cash tainted ETH)
- What about the people who donated through Gitcoin?
- What happens to the protocols/pools/(d)apps which interacted with it?

_This also might be the first time where a piece of code got sanctioned._

I really hope that the political authorities dig deeper and technically understand services like Tornado cash and come to a realization that criminal behavior exists everywhere and cannot be blanket banned by shutting down legitimate services. You can’t just end up banning hard cash just because its used by criminals and for money laundering. [(They tried this in India but it didn’t go as expected)](https://en.wikipedia.org/wiki/2016_Indian_banknote_demonetisation).

August 9, 2022 · [privacy](https://rnikhil.com/tag/privacy), [web3](https://rnikhil.com/tag/web3), [defi](https://rnikhil.com/tag/defi), [opinion](https://rnikhil.com/tag/opinion)

## DeFi Derivatives Overview
## Derivative protocols in DeFi

This post is a summary of all the options products available in the DeFi space. I embarked on doing a bit of research after I wanted to hedge my LP positions given the current volatile market and the impending [merge](https://ethereum.org/en/upgrades/merge/).

Before going ahead, it helps the reader to have a basic understanding of what options/futures are. You can read a basic primer [here](https://zerodha.com/varsity/module/option-theory/) from [Zerodha](https://zerodha.com/) which elaborates on the fundamentals of an options contract in TradFi.

One of the main differences between TradFi options and DeFi options is the additional component of a liquidity pool. Since we can’t have order books (due to limited TPS, available block space etc) in DeFi, liquidity providers come together to provide liquidity to the pool in return for earning some yield. You can think of these LP’s as the equivalent of market makers(banks/hedge funds/prop trading shops) in TradFi.

Most of these product are inspired from the equivalent TradFi products and follow along closely in terms of their equivalent implementation.

[Perp.com](https://perp.com/)

- One of the first on-chain futures which were composable. Deribit/Bybit might predate them but they we based on CEX’s.

- Everlasting contracts with no expiry. Imagine a NIFTY futures contract without an expiry date.


In TradFi, the price of the futures contract is usually different from the underlying’s prices and converges to the value of the underlying on the expiry date. The deviation is caused by the risk free interest rate and/or any dividend given out by the underlying before the expiry period. Since we don’t have expiry dates here, we need a mechanism to price these contracts. Enter funding rates which the longs pay the shorts to help keep the futures price close to it underlying.

![perp](https://rnikhil.com/assets/files/funding.png)

Basically funding rates will always tend towards zero as other market participants (traders/arbitrageurs/etc) will take advantage of the rate by going long when its negative or going short when its positive, thereby aligning the price of the of the perp with the underlying. If the funding rate is positive, you can short perps and buy ETH on the spot market for a delta neutral strategy. A bunch of start-ups have automated this trade:

- Diamond protocol does this cash and carry strategy (as a vault) using an algorithm to find the best rebalance frequency for the current market and rebalance automatically for the vault’s depositors.

- Due to the fact that these primitives are composable, there are also tokens which represent the above trade. Holding them would earn you funding payment without exposure to price. $BYE (Basis Yield ETH) is one such token.


[Opyn](https://www.opyn.co/)

- I stumbled onto them quite late (by crypto standards) while reading this [paradigm article](https://www.paradigm.xyz/2021/08/power-perpetuals)

- While they have “normal” perp options, I am interested in power perps (power contracts are basically attached to the square of the underlying’s price. If BTC goes 2x, the power^2 perp goes, 4x) because of their non linear returns similar to how options behave

- Squeeth (that’s how they call their square perp) doesn’t have expiry dates or even strike prices for that matter.They run distributed option vaults (DOVs) with their inhouse product Squeeth instead of “regular” options these days.

- For detailed payoff diagrams and explanations on how Squeeth behaves during different market conditions, you can check this article [here](https://medium.com/opyn/the-best-market-conditions-to-squeeth-3e92d868b533)


[Hegic](https://www.hegic.co/)

- They run a liquidity pool marketplace for operating an American style option. American options are slightly expensive than European options for the fact that they can be exercised anytime.

- Options trade in secondary markets where market makers/option writers can define the price of the option using their internal model. It looks like Hegic controls the IV variable and thereby the price of option as well.

- Options purchased on this platform are not composable meaning, I cant trade/use this position somewhere else in the DeFi ecosystem


[Zeta](https://www.zeta.markets/)

- Given really long block times and the inability to structure atomic trades, most of these option writers require full collateralization. However, due to faster L2’s and alternative L1’s going mainstream, we can now have faster M2M update which will help us price our options better which in turn means ability to offer under collateralized options

- Zeta provides under-collateralized options with an on-chain pricing engine and margin system.


While the above platforms mostly work on fundamental primitives, there are also a lot of companies providing pre-made option strategies for retail participants to invest in. These are particularly attractive to the less-complicated user who wants a quicker investing/gambling experience.

### Distributed Option Vaults (DOVs)

- DOVs are a new form of structured product which are mostly a collection of pre-defined option strategies. DOV’s are pretty important because they are able to democratize access to options without the user needing to understand complex jargon, choosing strikes/expiry or the risk of losing a lot.

- In TradFI, a specific combination of derivatives are selected, packaged and sold to clients looking for custom non-traditional payout curves. These clients are usually HNI’s/institutions and the intermediary (banks mostly) charge a fee for setting this up.


Let’s look at how these products are structured in the DeFi space:

[Ribbon Finance](https://www.ribbon.finance/)

- DOVs, with most of them running a basic covered call strategy. The call options are minted from the Opyn vault.

- They usually run covered call or cash covered put strategies which is a great on-ramp solve for retail traders looking to get some exposure in derivatives.

- Imagine Zerodha having a one click auto compounding covered call strategy against all your stock holdings. That would be really convenient.


[Friktion](https://friktion.fi/)

- **Volt1**: This is a basic DOV with covered call strategy on SOL, BTC, ETH etc.

- **Volt2**: Cash secured puts on the same assets as above.

- **Volt3**: Deltra neutral crab strategy. In TradFi, I would usually express this sentiment with a stradle or a strangle. Here, they use power perps to come up with a novel way to delta hedge. Payoff looks something like this:

  - ![payoff](https://rnikhil.com/assets/files/payoff.png)
- **Volt4**: Basis yield (delta neutral strategy which is used for eating the funding rate in perps as discussed above). During a positive funding environment, this strategy goes short on the perp contract and long on the spot to earn the funding rate and vice verse during negative funding environments.


[BrahmaFi](https://www.brahma.fi/)

- PMUSDC
  - A simple vault which does LP yield farming (boost LP rewards through convex and reinvest back into LP pool. sort of like yearn finance) with an added addition of taking a momentum trade using the yield on Lyra/perp.com

  - The extra edge in this strategy comes mainly from their internal momentum bot. Otherwise, its just a yearn finance strategy with extra fees. They used to do the same trade on GMX earlier

There are a lot more derivate platforms which further build on top of yield aggregators, DOVs etc. We shall have a look at them in the next post.

Disclosere: I use the above platforms and don’t endorse any of them.

If you like it, check out my other posts too:

- [We should all have something to hide - Tornado cash takedown](https://rnikhil.com/2022/08/09/tornado-cash-block.html)

August 15, 2022 · [defi](https://rnikhil.com/tag/defi), [derivatives](https://rnikhil.com/tag/derivatives), [protocols](https://rnikhil.com/tag/protocols), [web3](https://rnikhil.com/tag/web3)

## Gamifying Poker Experience
## Make Poker fun again

#### Introduction

- Lets face it, poker has become a commoditized game/product where most poker platforms look like skins of each other. There is hardly any differentiation in the products and all of them simply focus on the betting/gambling function of the game while a human centric focus on the user journey takes a back seat.

  - This is primarily due to the fact that human focussed features/design elements particularly don’t drive revenue directly. However, they make the product more fun to indulge in.

  - Unfortunately most platforms are just laser focussed betting tools which are designed to get the user wagering as soon as possible. Its almost like 2000s traders made poker software products.

Poker’s market cap is not growing at pace with the rest of the real money gaming ecosystem. E-sports and casual gaming are growing much faster (on a bigger base too) compared to real money gaming(and especially poker. Online Gaming has become ubiquitous especially in the post COVID world where people are staying more and more indoor and interacting with others online. online gaming has surpassed from being just an entertainment thing used by a bunch of geeks to mainstream extension of one’s identify online. It one of the [top categories](https://www.globenewswire.com/news-release/2022/07/06/2475487/0/en/Online-Gaming-Market-Size-to-Achieve-USD-132-Billion-by-2030-Growing-at-10-2-CAGR-Fueled-by-Massive-Investments-in-the-Gaming-Industry-Exclusive-Report-by-Acumen-Research-and-Consu.html) online in [terms of spends](https://www.businessofapps.com/data/fortnite-statistics/) as well.

#### Why is growth important?

- Opportunity cost of investing in poker vs other games/sectors. While poker is generally a profitable vertical for RMG (real money gaming) companies, the “real” value of the vertical/game is usually measured by the future cash flows which in turn is determined by your growth rate.

- In the stages of a business from early PMF to a scalable PMF to a scalable profitable PMF, its very important that the vertical displays potential for scalability much before we think about profitability. Poker usually starts making money(profits) early on but scalability is still a question mark.

- As part of my job, my responsibility is to explore ways to grow the poker ecosystem in India. With everybody playing games, its not a leap to suggest incorporating certain gamification elements to make poker more enjoyable.


* * *

There are bunch of vectors to drive growth. The direct way includes discounting, increased marketing burn etc whereas the harder way includes gamification, offering more products/services (cross-selling), community building, identifying profit pools in the value chain and building around them, etc

We want to craft a user experience which is much more than just **Deposit Money-> Select table -> Start betting**.

This article focuses on bring elements of games into poker to make it more fun and thereby drive growth. Using the [Octalysis framework](https://www.udemy.com/course/gamification-behavioral-design-the-octalysis-framework/), we can look at some possible elements and understand how they may be applicable to poker. While its hard to wrap the actual betting mechanics/UX into a gamified journey, we can look at other adjacent flows too. The key elements of the framework include:

1. A bigger narrative/meaning
2. Feeling of progress and accomplishments
3. Creative user participation
4. Sense of ownership
5. Social influence
6. FOMO
7. Unpredictability
8. Loss avoidance

#### A bigger narrative/meaning

- It is the Core Drive where a player believes that he is doing something greater than himself or he was “chosen” to do something. Attaching meaning to playing the game becomes an intrinsic motivating factor for the player

- We see a lot of companies playing to this sentiment like CRED(a lifestyle company), D2C brands, early Spotify (younger cool kids music app), etc

- While regular games have storylines, fictious identities, in poker, making the player win something big in a practice/tutorial step, or in the first session thereby making the player feel “chosen” creates a welcoming atmosphere for new poker players.

- Currently poker is also viewed mainly as gambling in India. Maybe organising Poker as an India wide talent competition under the assumption that people view winning the competition as a prestigious thing helps. It also creates social influence among your peers too. This is definitely the case with WSOP. Also creating content around the skill aspect of poker and popularising it would help change the narrative on how poker is viewed in our Tier-2 or Tier-3 cities.


#### Feeling of progress and accomplishments

- Development & Accomplishment is the internal drive of making progress, developing skills, and eventually overcoming challenges.

- This is one of the easiest to design for and already widely implemented across the industry. In poker, common implementations include:

  - Challenges/goals/tasks which are staggered with multiple sub-levels incentivising the user to finish a set of tasks.
  - Anything else to make the user feel that they are making progress:
    - Skill scores
    - Limited winner/time bound leader boards
    - Lavish use of progress bars
    - A super high rake back tier given only to the top 5 players on the platform
    - Special locked emojis/effects/time banks etc
    - Special custom effects for winning pots/losing pots which can be customised for a particular players

#### Creative user participation

- Empowerment of Creativity & Feedback is when users are engaged in a creative process where they have to repeatedly figure things out and try different combinations. People not only need ways to express their creativity, but they need to be able to see the results of their creativity, receive feedback, and respond in turn.

- We need a feature with tight feedback loop which takes in user input and something which preferably has a creative element attached to it. IKEA furniture have this element of self-assembly which makes the user care for the product.

  - In poker, some common methods include
    - User avatar customization (filters,emojis)
    - Custom table/card and background themes, social features ,etc. making their version of the client unique for them
    - Allowing users to design their own card/table themes is unexplored currently though
    - Social features (creative pre-defined voice chats, meme based emojis etc) which the user can use to express various sentiments inside the game
- Waze (the traffic app) intelligently uses user generated content where the platform users feel a sense of ownership in keeping the data accurate and up to date.


#### Sense of ownership

- This is the drive where users are motivated because they feel like they own something. When a player feels ownership, she innately wants to make what she owns better and own even more.

- Also, if a person spends a lot of time to customize her profile or her avatar, she automatically feels more ownership towards it too. Same applies to user earned virtual points/goods which can be be exchanged for other goods. We see a lot of companies implementing their own inhouse tokens/coins.

- In fact, this is (token sale) is one of the most common GTM strategies in the web3 space. The assumption is that with early community ownership, folks are incentivised to drive product adoption and growth.

- In poker we want to make the user feel that they own their identity/progress inside the game.

  - Custom avatar(which the user spent time customizing/assembling) which can be minted/exchanged for something else
  - In-game coins which can used for
    - As a proxy for giving rake back
    - Exchangeable for real-money, virtual goods or even physical goods
    - Give power to the user to boost a pot size (like splash the pot which is user controlled. [Reference](https://www.runitonce.eu/features/splash-the-pot/#:~:text=At%20Run%20It%20Once%2C%20we,collected%20back%20on%20the%20tables.))

#### Social influence

- This drive incorporates all the social elements that drive people, including: mentorship, acceptance, social responses, companionship, as well as competition and envy.

- Often implemented in the form of social events, group/team competitions, contests (with a lot of PR for the winners), televising etc by most companies. This is usually well executed as well as I see most platforms having a strong social media presence.

  - When you see your friend winning big in a poker competition, you automatically feel like playing the game too.

#### FOMO

- Scarcity, impatience or basically the drive of wanting something because you can’t have it.

- Often executed in the form of chosen waiting lists (Ultrahuman which onboarded only certain people early day), gatekeeping for certain users (CRED, early Facebook), etc. In poker we can

  - Exclusive private high stake tables allowed for only certain players
  - Invite only tournaments and other events
  - Even basic tournament prize structure which pays out only top 5 players and tapes out super fast. TLB with limited winners

#### Unpredictability

- Generally, this is a harmless drive of wanting to find out what will happen next. If you don’t know what’s going to happen, your brain is engaged and you think about it often. Many people watch movies or read novels because of this drive. **However, this drive is also the primary factor behind gambling addiction**.

- Lotteries, sweepstakes, slot machines, scratch cards work for said reason although they are sometimes confused against achievements/badges. In poker, its commonly implemented as

  - Different animations for turn/river cards trying to peak the user curiosity
  - Random splash pots where pots are randomly boosted sometimes

#### Loss avoidance

- This core drive is based upon the avoidance of something negative happening.

- Commonly executed by making the user lose previous progress, emphasising the sunk cost, rake back tiers which expire, bonus points which expire etc. Most reactivation campaigns play to this sentiment.


* * *

#### Summary

The core idea is to tailor make features which apply these concepts for **your** product, **your** community, **your** currency etc.

Poker products need not be just simple betting/gambling platforms. Poker can become a _fun_, _skill-based_ game where people share their progress, discuss strategies, buy/sell in-game loyalty points, compare skill-scores, set avatars and also brag about their winnings.

If you liked reading my post, you can check other similar posts too:

- [Blockchain gaming - Current state](https://rnikhil.com/2022/06/27/web3-gaming.html)
- [GTO Inspector - My attempt at building an online business](https://rnikhil.com/2022/06/15/gtoinspector-startup.html)

August 22, 2022 · [poker](https://rnikhil.com/tag/poker), [Octalysis](https://rnikhil.com/tag/Octalysis), [gamification](https://rnikhil.com/tag/gamification), [gaming](https://rnikhil.com/tag/gaming)

## DeFi User Journey
## Problem statements to solve for a retail investor in DeFi

The first section of the article inspects the various user personas interacting with DeFi protocols and their individual requirements. The second section identifies various products which solve for these use cases. We mostly look for on-chain use cases which already have a reasonable amount of adoption. This post simply surfaces the various participants across the value chain and identifies open problems. Some cutting-edge novel cases with nascent adoption might get overlooked. Nevertheless, we keep an eye out for unsolved/potential growth segments and see what we can build there.

#### User Personas

Broad retail requirements for interacting with financial services and products can be classified as:

- Investing
- Speculating/Trading
- Remittances
- Bill/Utility payments
- Commerce
  - Collectibles
  - Shopping
- Gaming
- Entertainment
  - Social
  - Content
- Transfers (P2P)/Cross border payments
  - Want to transfer money to somebody instantaneously with the lowest fees.
  - User Requirement and priorities
    - Easy on-off ramp
    - Global availability
    - Access to Payment rails
    - Network of peers/merchants already on-boarded into the network
      - Chicken/egg problem
    - Trust /Safety
- New user personas who may start using on-chain products. The requirements for those users would be different and dependent on what use case they on-board for.
  - For example, my mom started using online payments (UPI) after Quick commerce (10min delivery) became commonplace).

Currently, the first two user personas ( **Investor and the speculator**) are the most common place in DeFi. In fact every other use case is in fact a minority. Lets look at them deeper.

| **Average investor** | **Speculator/ trader** |
| --- | --- |
| Wants economic exposure to DeFi. Is not every sophisticated, intends to make +ve ROI, wants an engaging experience. | Wants a platform get access to capital and trade/gamble. High returns on capital is the ultimate priority. |
| _Product requirements_<br> \- Savings<br> \- Investing<br> \- Lending/Borrowing<br> \- Insurance | _Product Requirements_<br> \- Investing<br> \- Trading across asset classes <br> \- Coin/NFT launchpads<br> \- Credit (Lending/Borrowing/Leverage)<br> \- Other financial products (derivatives/swaps/bonds/etc)<br> \- Insurance<br> \- Data and Analytics |
| _First priorities_<br> \- Easy on-ramp and off-ramp<br> \- High yield products<br> \- Minimal friction while adding/removing/transferring/spending money<br> \- KYC/Identity<br> \- Regulatory/Compliance and clarity<br> \- Taxation/Ease of filing<br> \- Trust/Safety in the platform<br> \- Principal protection (low volatility) for investment products<br> \- Easy to use (non complicated) UX<br> \- Wants a personalized UX which is engaging as well as efficient<br> \- Easy Access everywhere (on mobile while travelling)<br> \- Speed of transactions have to instantaneous <br> \- (Single preferably) centralized market place/platform access to all products<br> \- Variety of markets available<br> \- Custody/Asset management<br> \- Cheap transaction costs<br> \- Best APR/APY (for savings/investments) and credit products<br> \- Easy onboarding | _First priorities_<br> \- Everything from Average investor<br> \- Advanced feature rich snappy UX <br> \- Portfolio management<br> \- Strategy builder<br> \- Risk Management<br> \- Centralized market place/platform access to all products<br> \- Variety of markets available with sufficient liquidity to do big trades<br> \- Derivatives/Spot/Prediction/FX products<br> \- Integration with other DeFi protocols<br> \- Regulatory compliance/clarity<br> \- Custody/Asset management<br> \- Rakeback for transaction fees<br> \- Best margin funding rate/leverage tools<br> \- Lowest interest fees<br> \- Best bid/offer spread<br> \- Low slippage<br> \- Easy onboarding<br> \- Capital efficiency(DeFi composability)<br> \- Loyalty programs |

Broad institutional personas who interact with financial services and products can be classified as:

- HNIs/Banks/Hedge Funds/Trading firms/ Market makers
- MNC Companies
- SME
- Governments/Treasuries

They all want economic exposure to DeFi and to leverage the benefits of transacting on-chain (distributed/ decentralized/trust less/ permission less/cheaper / available/etc). Some requirements for the above actors:

Product Requirements:

|     |     |
| --- | --- |
| Everything from a retail speculator |  |
| Risk Management | Portfolio management |
| Data and Analytics services | Credit management |
| Client relationship management | Invoice financing |
| Supply chain financing | Equity financing |
| B2B payments and transfers | Payroll |
| Insurance | Foreign exchange |
| Principal protected yield | Treasury management |

* * *

Products which solve core user requirements which overlap across the most number of personas have the highest likelihood of attaining scalable PMF (duh!). Now, we shall the investigate the user journey of these personas and try to understand the active participants in the value chain.

Profit pools are nothing but the total profit earned at all points along the value chain of an industry. When we analyse a value chain, it becomes imperative to define the boundaries of the sub-segment before digging deeper. Each of these segment profitability may, for example, vary widely by customer group, product category, geographic market, or distribution channel. Moreover, the pattern of profit concentration in an industry is often very different from the pattern of revenue concentration. You can check this [article](https://hbr.org/1998/05/how-to-map-your-industrys-profit-pool) on HBR to know how to map an industry’s pool.

In this section, we attempt to dig deeper into some open problem statements and propose possible solutions. In the next article, we shall investigate these participants from a profit/operating margin PoV to understand which problem statement is worth solving financially.

#### User Journey

Lets pick an **average retail DeFI investor** and look at their user journey.

Intent to invest

- High level actions in the user journey
  - On-boarding into a custody platform (interoperable platform)
  - Infrastructure plumbing (equivalent of the payment rails)
  - Fiat to crypto purchase
  - Transfers/uses it on a Dapp

Now, lets break down each of these steps and inspect the actors.

**Custody and Asset Management**

Similar to how fiat money is usually stored in savings accounts, central depositories, etc, crypto currencies have to stored in an online equivalent. Blockchains use digital signatures to secure money. Digital signatures are a pair of random keys, where one key is a “private key” and the other a “public key”. Through digital signatures, any person with the “private key” can “sign” a transaction and spend the digital currencies. Therefore, it is crucial to safeguard the “private key”. Some tech-savvy users of blockchains opt to safeguard this key themselves, and accept the risk of theft or loss of the key (and therefore the loss of their funds). In contrast, other blockchain users trust online wallets or exchanges with the safeguarding of their keys.

Custody management solutions overlap typically with the first step in the boarding process.Here, we are primarily focussing on the DeFi custody experience and not CeX related on-boarding flows.

Using the user requirements we looked at in the first step, lets see where the current gaps exist:

- Recovery/Portability is cumbersome and user has to remember a key phrase usually.
- UX while using it across Dapps is broken (identity and auth).
  - It is a multi-step process. Sign/Approve spend/Transact. No standardized experience
  - Transaction details are hard to understand
    - Txn costs are hard to predict
    - Txn details include lengthy hex strings which don’t mean much to the user.
    - Multiple confirmation steps and non-instantaneous transactions leads the user to confusion
- Managing multiple wallets/addresses is cumbersome
- From a first time web3 user perspective, its hard to understand what to do with the wallet after you install it on your phone. Onboarding through the specific Dapp directly has been more successful maybe for this reason.
- Interoperability across the ecosystem is not mature

Let’s look at the current type of wallets and understand what they do:

**Self-custodial**

- User is responsible for their private keys
  - Typically stored locally in the user browser/device/mobile
  - Recovery through a key phrase only
  - Easy to create and discard.
  - Examples:
    - Metamask
    - Trustwallet

**Exchange wallets**

- Investor allocates the control and management of private and public keys to exchanges.
- Gives control of keys in return for seamless access, lower fess but added counter party risk
- Examples of exchange wallets:
  - Coinbase
  - Binance
  - Vauld

**Third party custody**

- Service providers storing digital assets on behalf of (business)customers
- Custom-defined features and controls for controlled management of the asset.
- Ideal for institutional crypto custody
- Enterprise security and insurance is usually offered
- Examples (usually institutional):
  - Bitgo
  - Coinbase Prime
  - Instadapp sort of does this for retail.

  - _Wallet as a service_
    - MPC wallets where the key is split between you and a third party.
    - This means if you lose access to your private key, the key to your wallet is still safe and recoverable. This helps with portability and availability across devices
    - Sort of like multi-sig wallets where both the third party and you have to sign transactions
    - Examples of wallets powered by this:
      - Coinbase dappbrowser
      - Coindcx Okta

_What can we work on?_:

- Onboarding and discovery solutions helping a new user navigate web3 DeFi products
  - Unified payments/transaction experience across chains/wallets
  - Multi chain interoperable wallets
    - User ideally wants to live inside one wallet. Chains/protocols/etc should all be interoperable and talking to each other to provide a unified experience
- MPC based wallets offer the ideal mix of good onboarding/operating experience without trade off on security/privacy

Identity (Polygon ID, dynamic.xyz)

- Identity and authentication while preserving privacy
  - Unified standards for interaction with protocols (authorization and authentication)
    - Ethereum foundation is working on account abstractions ( [EIP-4337](https://eips.ethereum.org/EIPS/eip-4337))
      - ZK proofs powered stealth address (where you can have a DeFi app level address which you can control but nobody else will know that you control it)
      - Social recovery features
  - Decentralized identity provider
    - Attach a name (ENS)
    - Attach POAP or Proof of Humanity (privacy preserving using zk proofs)
    - Imagine an identity provider who can log you into web2 apps also because we can basically verify identity and the users also have way more control over their data

These Dapps which the users want to interact with are built on top of blockchains which we will investigate in the next section. While an average CeX user may not even interact with blockchains (just buys on Coinbase and doesn’t do anything else), we are discussing about a web3 DeFi investor here. The user also doesn’t pay for these services as they are usually available for free but instead monetized through adjacent offerings. In the next section, we shall look at some of the core infra DeFi products as well.

**Infrastructure**

This is the plumbing needed for all of web3 to function. As an user, I don’t really care how what the name of the chain is or the infrastructure complexity. The only requirements here are:

- Availability across Dapps. (interoperability)
- Speed and security
- No overheads, cheap txn costs

The participants here include:

- L1/L2 chains. The block chains on which the Dapps are built on. Some core participants here include:
  - Mining
    - Mining pools
      - Mining as a service
    - Node operators
  - Staking
    - Validator Node operators
    - Delegators
      - Staking as a service
  - Searchers extracting MeV
    - ![mev](https://rnikhil.com/assets/files/mev.png)
  - Multi chain protocols (shared liquidity/data layers)
  - Identity (authentication and authorization) layers

_What can we work on?_:

- L1/L2 scaling and its subdivisions
- Staking
  - Staking as a service for institutions
    - Controls for returns/risk adjustments
    - Taxation/Regulation/Compliance solutions based on geography
  - Given that most chains are moving to PoS, staking providers become one of the key participants in the value chain. Loads of capital is going to be locked up and further hypothecated for use across DeFi. Proving a plumbing solution is imperative here.
  - Multi chain staking + interop solve for staking
    - When I stake and get a liquid token in return, most of the user cases are siloed into the particular chain on which staking happens. As a staking provider, I should be able to provide cross chain liquid tokens which are easily transferrable.
- Block chain interoperability related problems
  - Given the fact that the user doesn’t bother with actual chain names and their respective trade offs and just wants a simple investing experience, it becomes imperative to find a solution to abstract away all the noise.
  - Multi chain protocols primarily solve for sharing of data and liquidity across chains. Use cases include cross chain governance, basic state share, cross chain lending/borrowing
  - Generic message transfer
    - Example: What does it mean for a lending protocol
      - Currently you put ETH as collateral (on ETH chain) and borrow. Then bridge it (to yield farming chain), swap (for yield token), yield farm, swap back again, bridge back again, then unlock collateral on ETH chain. Clearly this flow is broken.
      - Ideal flow should be something like “lock collateral on ETH” chain, message goes to destination chain and you borrow directly there. Repay in destination chain and message comes back to ETH chain where your collateral gets unlocked.
      - State transfer
        - Transfer any piece of critical information across chain from your protocol.
        - Unified governance where votes are cast across chains
  - Liquidity transfer layer
    - Instead of maintaining individual pair wise pools across chains (ETH on mainnet + ETH on Solana) to facilitate bridging, a more capital efficient way would be to do a common shared liquidity pool across all path ways.
    - Collateral bridging
      - How to power Dapps to have their own liquidity transfer layer across chain
        - aave v3 has aave portal
    - Yield aggregation - Ultimately user just wants to deploy on the most profitable farm
    - DeFi apps
      - Uniswap doesnt want users to leave the platform to go to a bridge and the come back for swapping. It should be able to provide a much unified experience
  - Current ecosytem
    - Middle chain
      - You start with two chains which are atomic and have their own state. Most solutions involve putting in a chain in middle for communicating data. The middle chain comes to consensus on the validity of the transactions and writes to the destination chain
        - You are implicitly trusting the middle chains which makes a big honeypot. Polynetwork is one example
        - Thorchain sort of does this with their common layer where all assets are trading against RUNE
      - Hub - Spoke model
        - System where everything is routed through the middle hub in the center (Polkadot)
        - Entire security requirements are offloaded to the hub
    - Cosmos IBC stuff
      - Takes the block header of all blocks and write it on the destination chain. Repeats the process vice versa
      - Once you have the entire block history, you can validate
        - Very expensive to do this
    - LayerZero/Router protocol (interop as a service)
      - Take single block, stream it on demand and validate it on other chain. Mostly a two part system with a oracle and a relayer. Oracle takes a block header and submits to destination chain and you can plug this oracle layer to different oracles like chainlink etc. The relayer simply takes the transaction proof and submits it on the destination chain.
      - Each Dapp can wrap their contract with these to enable instant interop across any L1 to L2 EVM compatible or not
        - Security is split across multiple parties (multiple oracles and relayers)
    - CeX are basically interop solves as well
    - Native bridges and bridge aggregators (socket.tech)
  - Every chain is going to become interoperable and future users onboarded aren’t even going to recognize the difference between yield farming on Solana vs ETH. Wallet experience and Dapp discovery is going to change because of this. L1/L2 chains which support the most amount of modularity would eventually be best suited to capture this future .
- MeV aware solutions
- Blockchain API and data providers
  - Analytics on blockchain
  - Providing blockchain as a service

* * *

Above DeFi actors capture majority of the value in this step. They are directly/in-directly involved with every user transacting on chain and thereby also are at an intersection of the most value transferred. In the next post, we shall look at some key metrics to evaluate these actors across the value chain.

Now the user has a wallet and connected to a chain to transact. Its time to move on to looking at the next participants in this value chain

**On-Ramp and exchanges**

Remembering that our user is a **retail DeFi investor**, lets look at some user requirements and pain points:

- User just wants to convert his/her fiat into crypto
- Wants to pay the least amount of fees (slippage, txn fees) and wants the best price

Some participants here:

- KYC(if you are going to be regulated anyway, doublick click here for proof for identity/etc like polygon id/ platforms adhering to regulatory compliance are the first step in the on-boarding process (application include aadhar)
- On-ramp solutions which is the primary place to convert fiat to crypto
  - Exchanges usually interact with tradFi banking/payment system to take in fiat money
- Exchange + Liquidity to convert fiat to crypto (swaps)
  - Liquidity protocols providing the markets for the user to trade in.
  - Stable coins
- Gateway products which convert fiat to crypto (banking integrations)
- Stable coin issuers (primarily purchased first because of their ubiquity in web3)

what problems to work on?

- Reduce the number of steps needed to convert crypto through block chain interop
- Geography aware KYC solutions

**Dapp interaction**

Now that the user has converted his/her to fiat to crypto, lets look at the journey to invest in Dapps. As an user, my primary requirements would be:

- Investing
  - Yield farming
    - Staking pools
    - Lending/Borrowing
    - Liquidity pool
      - Yield aggregators/boosters/auto compounders
      - Bribes/Governance co-ordination
      - Derivatives

For the next wave of Defi products to be bigger than the previous/current state we need an influx of new set of users who have never used these products before. Making these investment Dapp retail-newbie friendly is paramount.

#### Summary

As we look across the value chain of a **retail investor**, we notice that major value transacts across these players:

- Custody management
- Staking
- Blockchain interop

Now, depending on which business we are trying to enter, you can further double click to understand all adjacent offerings as well. A liquid staking service would eventually move into wallets to capture more TVL or approach the same problem from the perspective of an institution to offer DeFi products with access controls for risk profile/taxation/regulations etc.

Checkout my other related posts too:

- [We should all have something to hide - Tornado cash takedown](https://rnikhil.com/2022/08/09/tornado-cash-block.html)
- [Option protocols in DeFi](https://rnikhil.com/2022/08/15/defi-derivatives.html)
- [Blockchain gaming - Current state](https://rnikhil.com/2022/06/27/web3-gaming.html)

August 28, 2022 · [defi](https://rnikhil.com/tag/defi), [crypto](https://rnikhil.com/tag/crypto), [web3](https://rnikhil.com/tag/web3), [user](https://rnikhil.com/tag/user)

## Web3 and DeFi Insights
## A take on web3/DeFi

Most use cases for crypto are in an imaginary space. Lot of the details like “why does the customer care?”, “why will they pay for it?”, etc are not necessarily thought out clearly. Most products ask me to “Imagine a world where everything is de-centralized”.

So, what do I think will come out of web3/DeFi mania?

- First off, currently crypto and web3 is really great currently for trading/speculation related use cases. Solving for capital efficiency, security, infra makes sense in long term.

- Then what? Retail investors? Gaming? NFT/Collectibles? Countries run as DAO’s? Its very hard to come up with future (>10yr) use cases but we can look at some analogies.

- Comparison with Internet:
  - Commonly used in super bullish crypto circles, the comparison has some rough edges. Internet started as a way for education/military bases to talk to each other. It started from day 1 solving for a single use case(comms) only instead of 1000 other possible things you can build on top of it. While it didn’t have distribution initially, it took like 15-20 years for apps to go mainstream. People kept building iteratively on top of it.

  - While it may work as a great branding for VC’s, here it just becomes a speculating exercise on potential use cases 10yrs down the line. This is sort of the reverse order as the internet. Imagine somebody trying to raise money for Snapchat in 1990.

  - If you have to borrow analogies from the internet, solving for infra and for specific user personas/use cases today makes the most sense. The internet did it for 15years for some niche user personas.
- In web3, we started **directly** with a compelling vision of no single counter party/no centralised institutions/everybody owns everything/trust less/permission less and then tried to work backwards into solving for use cases.
  - Funnily, most successful crypto companies are currently centralised. While starting like this isn’t necessarily bad, lot of them are not on a path to de-centralisation.
- There is definitely some value in the space. Expectations are currently super high to become a $100 Billion business for everybody but today, it may just be a $1 Billion niche for the time being. When you pump $50 Billion into the ecosystem, it makes it hard to differentiate between utility vs speculation vs any other perverse incentives. Some products assume PMF because of wash trading/bots etc. If you look at the top gas spenders on AVAX/Polygon, it’s mostly bots inside a game or wash trading NFTs. Ponzi schemes, unnatural yields through looping money around etc have become commonplace too.
- It may solve for some specific use cases in the future like remittances (cross border payments, a $5 billion use case ) or market making/infra for trading which is again maybe a $30 Billion business.

I hope in the future, we can solve legitimate problems with this tech. Luckily since this space basically speed runs through everything, the cycle length to actual mass products may not be as long as the internet. Honestly though, these brand of “web3” applications have been coolest new tech(paradigm) in a while and us being technologists, its just a lot of fun to investigate them and play around.

Checkout my other related posts too:

- [We should all have something to hide - Tornado cash takedown](https://rnikhil.com/2022/08/09/tornado-cash-block.html)
- [Problem statements to solve for a retail investor in DeFi](https://rnikhil.com/2022/08/28/defi-user-journey.html)
- [Option protocols in DeFi](https://rnikhil.com/2022/08/15/defi-derivatives.html)
- [Blockchain gaming - Current state](https://rnikhil.com/2022/06/27/web3-gaming.html)

September 1, 2022 · [opinion](https://rnikhil.com/tag/opinion), [crypto](https://rnikhil.com/tag/crypto), [web3](https://rnikhil.com/tag/web3), [defi](https://rnikhil.com/tag/defi)

## RSA Cryptography Overview
## The magic words are squeamish ossifrage

> “The Magic Words are Squeamish Ossifrage” was the solution to a challenge ciphertext posed by the inventors of the RSA cipher in 1977

Howdy! I have been bit busy with launching Pot limit Omaha ( a poker variant) at work and haven’t been able to write regularly. Launching PLO is extra special for me because it sort of makes my poker journey go full circle. From playing PLO professionally, to building products for professional PLO players to finally launching a PLO product as part of a poker website itself; its been a fun ride.

I was part of the Wolfram Summer school which ran during the summers of 2017 in the town of Boston, MA where I built a network sniffer function for their core product. It was a super hectic summer for me where I was simultaneously working on three different projects. I was attending the summer school in USA, doing my second GSoc project ( writing a HTTP2.0 implementation for a network lib) and was also part of the OWASP Code Sprint (worked on a tool for obfuscating assembly shellcodes). In hindsight, I learned an immense amount over the summer while also travelling around New York.

At the start of the summer school, we were asked to pick a topic and write a computational essay to get familiar with the basic functions of Mathematica. I wrote about the basic RSA system. The essay is embedded below. Feel free to run the code yourself.

More details on my summer school work can be found [here](https://education.wolfram.com/summer-school/alumni/2017/ramesh/)

RSA

|     |     |     |     |
| --- | --- | --- | --- |
|  | Insert |  | Sample |

RSA

A simple Public Key Cryptosystem

Introduction

Public-key cryptography, also known as asymmetric cryptography, uses two different but mathematically linked keys, one public and one private. The public key can be shared with everyone, whereas the private key must be kept secret. In RSA cryptography, both the public and the private keys can encrypt a message; the opposite key from the one used to encrypt a message is used to decrypt it. This attribute is one reason why RSA has become the most widely used asymmetric algorithm: It provides a method of assuring the confidentiality, integrity, authenticity and non-reputability of electronic communications and data storage.

Algorithm

Theideaofthealgorithmistoencryptsomemessagebetweentwousers.Fermat’slittletheoremsaysthat,givenaprime

p

andanyinteger

a

,

p-1

a

=

1(modp)

,then

p

a

=

a(modp)

.Thisgeneralizesforanyintegerncoprimetoaandweget

t

a

=

1(modn)

=>

t+1

a

=

a(modn)

.Proofisomittedhereforbrevity.​1)First,eachuserchoosestwobigprimespandq

​​

.Thisis1024binarydigitnumber

In\[8\]:=

{p,q}=RandomPrime\[{2^1023,2^1024},2\]

Out\[8\]=

{124135304750935389101829569207491608858452497369218307570131916500178335285601195620380920185688812460995644721105165863780728156832666913830281793197764623494141542687180596940966781715471216807701536065293555099508547959504605780071665578297999070795076297478091197306199710127348111265364327347687298990243,105804299838591147786332038488124686327319285108316669056604508051021365218259116665144616414673756923507429454104785588699407778130806419551434649691320403442815939739790211646187440010157747464104670107424933595278303681760178662679621865788185713289449160636063768669455462324569119149032689573194781169461}

​

2) Then they compute the products

n=p\*q

and

t=(p-1)(q-1)

.

p

and

q

can be discarded now.

In\[9\]:=

n=p\*q​​t=(p-1)(q-1)

Out\[9\]=

13134049004422856130104341690412807076338184877421027145734840629431186679254739234308828426871131942750284851991414362738984651607162519797913813747974559250462409316025487425060309101936147847997515147613157820810608794204378532523814503122935242339517336863794328758741927461165655862921824556045252958411311290510802202837296466691550619160746806673305079177739942029272523240337534784565490836329566295119900366295860590557192532195047169402521085939197195494237477216193962517077664997795911950463967491557359688377055085332257319762021641514503864302008426124034770298864472725512987989735531287294895968569023

Out\[10\]=

13134049004422856130104341690412807076338184877421027145734840629431186679254739234308828426871131942750284851991414362738984651607162519797913813747974559250462409316025487425060309101936147847997515147613157820810608794204378532523814503122935242339517336863794328758741927461165655862921824556045252958411081350906212676300408305083855002865561034890827544201113205604721323539833674472279965299729203725735397292120650639104712396260083696069139369496308110467300519733766991708490510776070282986192161285384641199682268233690992535319270354070417679517923900665920615332888817553061070759321134270374013888409320

​

3) Choose 2 numbers

e

and

d

such that

e\*d=

1(modt)

. Discard t after this. We should just be careful that e isn’t a divisor of

n

and it should be between 1 and

n

In\[11\]:=

e=RandomPrime\[{1,n}\]

Out\[11\]=

2854289466462136659611101336102597314970341397109371713251441294101027922685938235620400720747901232116856212433934953836178793004777035745706904831215564716398114761600760888500874381242845820744886585789624989716667318471908473714953184681021043419857008473166394591011087248841157437672011841586559918092418879572177786313394001449757995080249619695487070389753452139906564736769990999160575251859710039838585792859749964386403962776636315339390940114998035702774441288360574144000897729622532921022178014011162480447389473857249245443828748991024156413716913070553726594541175355722442941769391984479060376807391

In\[12\]:=

d=PowerMod\[e,-1,t\]

Out\[12\]=

216511704083026632201493887376314631392361542616986703624185291432796437266605579588780195420385126934849151161011787103418073798094948877679666594861666022850734919063117043075674735114021528720570399080785407491956456172651105008711989588372263760269028496316374009473119075007256385256343071055564860199219871466483900844019117717907995047383092142130828040699649079465418886975072315770963774585989561245712619990925484620266937828502411676147571287097172565839906506510978181576173595380012129275048206692185550686410897929140236007513079674017519368898791164548363342313677288206677786644571331320176712268551

4) Now, the couple (e, n) is called the public key(n is called the modulus and

e

is called the exponent) and the private key is

d

​

5) The public key can be given to others but the private key (

d

) should not leave the computer.

6) For a secure enough implementation the modules n has at least 2048 bits. I used much smaller numbers here though

## Encryption

Let’s say the message to be encrypted can be represented as an integer m which is smaller than n. If the integer representation is larger than n, then the message has to be broken down into multiple pieces. m should also be prime to n.

​

Now, to encrypt the message

m

and get the ciphertext

c

(another integer) we compute

c=

e

m

(modn).

Let the secret message be “The magic words are Squeamish Ossifrage”. Let’s convert it into digits before encrypting it over.

In\[13\]:=

m=Total@MapIndexed\[#1\
\
First\[#2-1\]\
\
256\
\
&,ToCharacterCode\["TheMagicWordsareSqueamishOssifrage"\]\]​​c=PowerMod\[m,e,n\]

Out\[13\]=

3305012019449526228978496962940312012718199938660609170647220059089162474114678523318979881044

Out\[14\]=

2926494418312680963702032656640996541406870165125921034982078449349963230216677281512432184507788353191108799408604369354719178653255114369040394004140497286043246642205182730253284240875534073136231682584551345634153416969769020496794820106287298359308958491923984924645399507938513750226792443268965476462260207656864698472764571918041047295550787771196201722114069911642240869792782784999492013847649614052213357047598751057874326399169747584401811398789526102503166866090167399524968701484301951024383779125541003181558031945427493799509734368748658466807831441213624181298123521679661139225042981460885537162835

## Decryption

## Why is it secure ?

As you see, the above functions takes really long(doesn’t finish) and this problem is computationally difficult.

Authorship information

Nikhil. R

20-6-2017

rnikhil275@gmail.com

AAAAAAAAAA

AAAAAAAAAA

AAAAAAAAAA

AAAAAAAAAA

AAAAAAAAAA

AAAAAAAAAA

AAAAAAAAAA

AAAAAAAAAA

AAAAAAAAAA

October 12, 2022 · [crypto](https://rnikhil.com/tag/crypto), [rsa](https://rnikhil.com/tag/rsa), [encryption](https://rnikhil.com/tag/encryption), [internship](https://rnikhil.com/tag/internship)

## 2022 DeFi Protocols Overview
## Classifying 2022 DeFi protocols

DeFi in 2022 was a lot about liquidity provisioning and balance sheet monetization. Everybody was looking for simple and safe yields without the risk of getting their hands burnt. The year has brought the dawn of certain type of protocols like:

- Automation protocols for auto-compounding funds
- Enhancers for looping funds
- Extender protocols

**Automation** protocols re-balance liquidity positions across AMMs and Layer 1s, recycle rewards, and provide “auto-compounding” services. Convex Finance is one the leading examples - they “recycle” $CRV and Curve LP tokens for boosted rewards, trading fees, and governance tokens.

**Enhancers** are protocols that do not introduce new operating models for DeFi, but rather recycle the outputs from existing protocols to optimize returns for the end user. A good example of this is [Abracadabra.money](https://abracadabra.money/), which is similar to MakerDAO but with the important difference that it creates collateralized debt position from yield-bearing assets (and has much looser risk controls).

**Extenders** are protocols that stack various underlying DeFi protocols. Alchemix is a good example. It’s vaults function similarly to MakerDAO’s, but the protocol also rehypothecates its collateral assets and deposits them into yield aggregators like Yearn, creating yield generating synthetic tokens which look like “self-repaying loans.” The rehypothecation creates risk, as the protocol absorbs the risks of the lower-level protocols it’s built on. Still, self-repaying loans!

Checkout my other related posts too:

- [We should all have something to hide - Tornado cash takedown](https://rnikhil.com/2022/08/09/tornado-cash-block.html)
- [Problem statements to solve for a retail investor in DeFi](https://rnikhil.com/2022/08/28/defi-user-journey.html)
- [Option protocols in DeFi](https://rnikhil.com/2022/08/15/defi-derivatives.html)
- [Blockchain gaming - Current state](https://rnikhil.com/2022/06/27/web3-gaming.html)

January 26, 2023 · [defi](https://rnikhil.com/tag/defi), [crypto](https://rnikhil.com/tag/crypto), [market](https://rnikhil.com/tag/market), [protocols](https://rnikhil.com/tag/protocols)

## Real Money Gaming India
## Some notes on Real Money Gaming (RMG) in India

The gaming industry in India has been growing exponentially in recent years, with many people joining the ranks of avid and serious players. India has now become one of the leading countries in the world in terms of gaming, and this is largely due to the large population, the availability of technology, and the increasing enthusiasm and accessibility of gaming platforms. With more and more people playing games, India has become a massive and vibrant gaming community, with people of all ages and backgrounds enjoying the many styles and genres of gaming. From console and PC gaming, to mobile and online gaming, there is something for everyone to enjoy in India’s gaming scene. This post mostly focusses on the real money gaming market, potential profit pool and if somebody is starting a RMG company in India - this document can serve as a preliminary primer in understanding the market.

High level Index:

1. Why bother building in India in the first place?
2. What is the current market scenario in India?

   - How is the entire gaming industry revenue split?

   - Where is majority of the revenue and profit potential?
   - Which sub vertical is growing?
     - What are users majorly playing?
3. Where is the market opportunity?
   - Differentiator for RMG companies starting today and path forward for building a RMG business

### 1\. Why India?

#### Bull case for gaming in India

- About $3Bn market size but having consistent growth. RMG dominates about 55% of this
- Cheap data/ digital payment penetration
- 90% users play on a mobile phone and entry level smartphones are some of the cheapest in the world
- Growing youth population. Already the youngest population which overlaps greatly with the target demographic for gaming. About 400Mn gamers today is the conservative estimate
- This photo illustrate the growing internet user base leading to growing number of gamers » growing number of paid gamers

![](https://rnikhil.com/assets/files/funnel.png)

- Among this - about 110Mn are paying gamers which includes RMG + IAP + subscriptions.
  - This number is set to double along with ARPU according to Redseer (by basically benchmarking with US/China)
- 90% of them are mobile based. 90% revenue also comes in mobile.
- Demand side plus points

  - **Affinitly/Aspiration to make money/win money online is high for our demographic. Aspirational youth population.**
  - Rising disposable income. Lot of this 400Mn gamers are in Tier 1-2 cities
  - Time spent in gaming rivals OTT/Social. About 3.1hrs per week
  - Power user retention and LTV is comparable to international platforms. Example: 20% of MAU of Adda52 are players who are > 3 years old on the platform.

![](https://rnikhil.com/assets/files/timespent.png)

- Supply side

  - Rich cultural history leading to lot of familiar homegrown titles. Rummy is about 85% of the RMG market which in turn is about 55% of the overall gaming market

![](https://rnikhil.com/assets/files/revenuesplit.png)

- Multi gaming platforms (MGP’s) still haven’t exactly cracked the unit economics for hyper casual games but they at least bring in DAU
- Rising consumer trust in online platforms and digital payments

#### Bull case for building outside India?

- ARPU is much higher outside India. While you can argue that the core power user ARPU is comparable, the number of them playing these games for a living/seriously is very little. Check out [this post](https://rnikhil.com/2022/06/15/gtoinspector-startup.html) for more about this set of these power users in India
- Conversion % for casual is ridiculously low in India. About 60% of non-RMG is ad supported
- Regulation for a lot of real money games is unclear. SRO’s (self regulatory organizations) still haven’t been formed and states banning betting overnight is an existential risk.
- Multi gaming platforms haven’t solved for retention thereby leading to unsustainable unit economics for most games (churn is especially higher for the hyper casual real money games).It is still a problem plaguing the industry
- Certain companies have advertising monopolies. Acquisition is expensive compared to the LTV that 80% of the customers offer
- Changing perspective about skill games and their money making potential. People no longer view them as gambling but rather as legitimate career options. Money making potential for certain games like poker in Indian rivals an executive salary at FAANG.

### 2\. Indian Gaming Market

#### Revenue Split

RMG dominates the market account for about 55-60% of the overall revenue. While casual games attract the largest number of users and have been crucial in growing the mobile gaming culture in India, while real money gaming attracts the highest paying users in mobile gaming. As a result, real money games have been the largest revenue source for India’s gaming sector. This segment is expected to grow at 30% CAGR with growing expectation of regulatory clarity.

#### RMG vs Non-RMG

![](https://rnikhil.com/assets/files/rmg.png)

Online RMG market is segmented into 3 game types (Online Rummy, Poker & Fantasy Sports) and by platforms into Single game (>91%) & Multi game (~9%) - collectively growing at a CAGR of ~61% for the last 3 years. Online Real Money Gaming Market split by the following segments :

![](https://rnikhil.com/assets/files/rmggrowth.png)

Rummy is currently the largest segment and is expected to dominate the RMG market in the future due to rising number of new rummy users from north India and increasing propensity to pay of existing users. Rummy market is expected to increase from $1Bn in FY2022 to $2.4Bn-$2.5Bn in FY2026 at CAGR of 24%.

Poker has the least penetration when compared to rummy and fantasy, indicating a very high potential for growth in the coming years. Poker has the highest user retention rate and highest revenue per user among the two games considered here. Poker market is expected to grow from $150Mn in FY2022 to $450Mn in FY2026.

#### Inside Non-RMG, where is the money coming from?

![](https://rnikhil.com/assets/files/nonrmg.png)

Lets now move on how the users are split between RMG vs Non-RMG. The Non-RMG market has two major categories in terms of game types - Casual and Hyper-casual, and core games. Casual and Hyper casual games offer a quick and easy means to pass time and have become a popular entry point for India’s first-time mobile gamers. As a result, this segment has the highest number of overall users, i.e. 350-420 Mn, with very low paid user conversion rate (8-10%). Also, there are around 150-160 Mn core game users with very high conversion of paid gamers (36-43%)

![](https://rnikhil.com/assets/files/usersplit.png)

RMG witnesses a MACU of 12-13 Mn of the total 26-30 Mn real money gamers and it is expected to reach 60- 80 Mn real money gamers in the upcoming years.

Everything else like e-sports, desktop, platforms are rounding off errors at the moment. E-sports grew about 5x on a small base but has plateaued since.

#### Multi Gaming vs Single Gaming platforms

While Single Game Platforms (SGP) currently dominate the market with (~90%) market share; the upcoming format of Multi-game platforms (MGP) may get popular in the future. MGPs offer a wider variety of games to users; and are therefore able to attract gamers from a wider set of interests and abilities. It should conceptually also be able retain them more by keeping them entertained and engaged for a longer time due to the wide array of game offerings (in reality however, this is harder than it looks).

The recent rise of MGP can be attributed to greater game types attracting wider variety of audiences(thereby increasing reach), distributed game dev costs and ability to capitalize on cross game synergies. **In its current state, MGP is growing at ~40%; which is the highest across various segments of RMG; and is expected to be ~12% of the market by 2026. While, the relative share appears low, in absolute terms this translates to nearly $500Mn (viz. ~4x in 5 years) by 2026. This explains the observed interest amongst gaming companies to explore and grow as Multi-gaming Platforms.**

MGP’s have also really lowered customer acquisition costs by spreading it and averaging it between low CAC games like Fantasy/Ludo and high LTV games like Poker/Rummy etc. However, not all things with MGP’s are positive. Majority of the users still go to these app to [play 1-2 games](https://blog.hike.in/rush-homescreen-d64a7406dc78) and don’t deviate beyond them. Habit forming for the rest of the games is still a hit or miss.

### 3\. Some perspective on RMG/gaming and way forward

**How are these RMG businesses differentiated?**

RMG has more or less become a commodity business. Most products look the same and some companies even modify their GTM to match competitors in hopes of attracting users with a familiar platform and better deposit offers(like a [vampire attack](https://finematics.com/vampire-attack-sushiswap-explained/)). Product innovation has been slow or non-existent in this industry for the last ten years. Adda52 from 2013 looks 90% same as today. Moreover, given the extremely low M12 retention rates, you have to keep acquiring users (spending money) every year as your platform churns through them - making this a treadmill business.

Core problems to solve for in RMG:

- LTV/CAC doesn’t work
  - High acquisition costs but low average LTV. For example: CAC for acquiring poker players is about Rs. 15k and its impossible to make this money back if 75% of your new users churn out before 3 months. This problem has to be solved from both ends by lower acquisition costs and improving retention
  - Possible solution: Mini game casual variants of popular card games with shorter game loops would set the product apart in terms of giving new users a feel and taste of the game related wagering/betting while at the same time without diluting the skill aspect.
    - [Timepass.Games](https://play.google.com/store/apps/details?id=com.simpleviralgames.timepass) is doing this for hyper casual games in a TikTok variant. Idea is to engage the user for longer by giving them multiple games in quick shorter formats
    - There are some caveats to making RMG games in shorter formats. As a rule of thumb in RMG businesses, 80% of your revenue comes from 15% of your users. This ratio is extreme for some games like poker and normalized for bigger games like Fantasy. If you reduce the game loop duration, its very hard to have the same ARPU as earlier and retention is still an open problem with hyper casual variants. Having tight game loops along with strong product driven conversion milestones to make the user play the longer variant could alleviate some of these concerns.
- Poor retention

  - In my own experience, the single biggest factor determining the retention of a player is their loss rate(money lost /day). If a player loses money on the platform, he/she is prone to churn. This is unfortunately unstoppable in the RMG business because of its design. However, we can explore couple solutions:

    - Make losing money for new players slower and more enjoyable. At the end of the day, 95% of your players are going to lose money. Giving them a fun and interactive experience lowers chances of churn. Kickass FTUE teaching the players to make sure they learn the rules before wagering is key as well.
    - Re-acquiring them again using a network site model. This is an under explored concept in India where multiple website skins could share liquidity of players. This way, you can have a gamified skin of the game marketed towards one target group and serious/pro friendly version marketed towards a different set of users. They can share player liquidity across all games while still having different fee/reward structures. Taj Rummy/Poker is doing this to some extent with a very bad product at the moment in India but there are no big name players yet. Gameskraft has brilliantly marketed 4 different Rummy versions which all share liquidity to keep re-acquiring their churned out users for cheap.

At the end of the day, majority of your revenue comes from power users who choose your platform primarily for player liquidity and product experience. Recreational users are attracted towards big offers and guarantees but churn out when they lose. Ensuring you can retain/re-acquire recreational users through strong data driven offers/loops and providing superior gaming experience to power users would lead to a sustainable RMG business in my opinion. However, having a great product by itself is not enough. Distribution is super critical and making sure you can acquire users for cheap makes or breaks a platform. Cross game analytics/anti fraud/rewards (which is by large forgotten by most companies) is paramount to predict and minimize churn.

Revenue comparison between some Indian and foreign betting companies shows the market potential for a mature player globally:

![](https://rnikhil.com/assets/files/comp.png)

**Sources**

- Delta Tech(Adda52) DRHP
- Nazara gaming DRHP
- Redseer, BCG and Newzoo research reports
- Lumikai and Konvoy VC blogs

If you liked this, checkout my other related posts too:

- [GTO Inspector - My attempt at building an online business](https://rnikhil.com/2022/06/15/gtoinspector-startup.html)
- [Make Poker Fun again](https://rnikhil.com/2022/08/22/profit-growth-gamification.html)
- [We should all have something to hide - Tornado cash takedown](https://rnikhil.com/2022/08/09/tornado-cash-block.html)

April 3, 2023 · [gaming](https://rnikhil.com/tag/gaming), [market](https://rnikhil.com/tag/market), [rmg](https://rnikhil.com/tag/rmg), [research](https://rnikhil.com/tag/research)

## Multi-Gaming Platforms Explained
## Do multi-gaming apps make sense?

I’ve been thinking about multi-gaming platforms due to their recent meteoric rise to [capture about 10%](https://rnikhil.com/2023/04/03/gaming-state-india.html) of the RMG market and the fact that I have to make a decision at work on bundling a mini-game with our main app. The multi-gaming segment is also growing at about 40% y-o-y which is the highest among all RMG segments. While one can argue that this growth was mostly driven by monstrous advertisement spends, this document tries to dig a bit deeper into the user behavior/personas between Multi Gaming Platforms and Single Gaming Platforms, framework to define value of adding/removing each game in the bundle, mental models for packaging games and finally some perspectives on user requirements/needs and way forward for building multi gaming apps. We want to basically explore why everybody is packaging games together or building yet another subscription service?

### Background

If you talk to my colleagues at work, they will tell you that I’ve been a fan of single gaming apps and against bundling random games together. I’ve been a power user (was playing [PLO](https://www.pokerstars.in/poker/games/omaha/) professionally) and I personally never saw any user (in my bubble) splitting their sessions between playing 500 hands of poker and 100 rounds of rummy. Both are skill games and played with cards but I’ve never seen them played together. If thats the case, why do apps bundle them together? Even worse, they bundle Poker and Fruit Ninja together.

Moreover, given that majority of your revenue is going to come from these power users, I never really understood bundling random games like Fruit Ninja, Ludo etc along with the target game of the power user. In fact, the product folks behind Hike seemed to have reached a similar conclusion. A quote from their post: “Even though we have 10+ games on the platform, most users preferred to play 1 or 2 specific games that they liked the most. Users like to have options but have specific preferences when it comes to actual game play”. You can read the full post [here](https://blog.hike.in/rush-homescreen-d64a7406dc78). Plus, ARPU of single gaming platforms is 3-4x higher than multi-gaming platform. Users seem to spend more on the same game inside the standalone app compared to the multi-gaming app as we can see from the below table:

![](https://rnikhil.com/assets/files/poker.png)

Given these obvious pros of standalone apps (better ARPU, filled with power users) and cons of multi gaming apps(no obvious user overlap, bad ARPU), why are multi gaming platforms growing? This blog post basically tries to prove the above premise (single gaming is generally better than multi gaming) **wrong.**

### Content

- Is bundling games good or bad?
- What is a “correct” package of games?
- How to package games?

#### Is bundling games good or bad?

For the rest of the discussion, we will consider these 4 games: Rummy, Poker, Ludo, Fantasy and debate on whether to build a stand alone app or a multi-gaming app comprising all the games. Let’s also split our users and their behavior like this:

![](https://rnikhil.com/assets/files/usertype.png)

Now that we have our four games and three types of users, lets consider two scenarios:

**Scenario 1:** We build single gaming apps for the games and market them independently. This means, we are primarily trying to attract power users (only fans of Poker would have Poker installed) and will only collect revenue from them. Moreover, a consumer would only have access to game of which they are fans of. They miss out on the other games they otherwise might have played and enjoyed inside a multi-gaming platform. Clearly in this case, we lose out on the casual user revenue if we do single gaming apps and consumers lose out on discovering games they might have liked.

![](https://rnikhil.com/assets/files/gamebundle.png)

**Scenario 2:** We build a multi gaming app which has all the games bundled into it. In this scenario, we not only provide power users their favorite game but also allows them access to game they might be “casual users” of. A poker power user might be a “casual user” of Fantasy sports. Also, from a business standpoint, my total addressable market(TAM) is much bigger than my earlier user base because I am now targeting the casual user market of all the games as well.

We can see that, both the platform and the user benefit from multi gaming apps. While the core power user hasn’t changed their behavior much, we have now allowed for casual users to participate and discover new games. Having casual users on the platform is super beneficial especially in real money gaming(RMG) setting where most match-ups are PvP and prizes are pooled in from the players. The utility or value of a gaming network is exponentially proportional to the number of nodes (players) in the network. Once you have a critical mass of users, you can see hyper exponential growth due to the above relationship. Multi-gaming platforms capitalize on these factors to grow fast and big. Clearly, Single Gaming Platform model doesn’t maximize value because power users don’t get games which they maybe interested in and platform providers clearly cannot run a sustainable business without casual users. We can also philosophically say that having **multi gaming apps is mostly about serving casual users**. (this point will become important towards the end)

Couple things stand out from the above scenarios:

- If you go down the Single Gaming Platform route, you clearly isolate your power users preventing any kind of interaction with casual users. However, power users mainly come for the casual user population to play against and your player volume will suffer. Ultra important for RMG.

- Each power user gets access to a platform which has only the game that they wanted. Even if they wanted to try Fantasy sports during cricket season, that isn’t possible


For example, take the poker variant called Pot Limit Omaha (5card) game. If you ask a random person what it is, you most likely would get a binary answer - either they say that they play the game regularly or ask the full form of the abbreviation. This is because PLO5 has very little casual users - which I believe is attributed to the fact that its never bundled outside of poker apps. A fruit ninja /hyper casual gamer never got PLO5 as part of their Multi Gaming Platforms. However, if you ask a random person if they are a fan of Fantasy sports, the answer this time would fall in a continuous range between a power user(I play every match) to non-user( I’ve tried it once or heard about it somewhere). Fantasy sports certainly has power users but has a big population of casual users too. Interestingly, most of these gamers don’t even know where they started playing Fantasy. It looks like by virtue of signing up for a multi gaming platform, they randomly played a match.

> **Conclusion: Bundling is good for gaming apps when done correctly.**

But, what does “correctly” mean? We also know that ARPU suffers from bundling? How do we measure and understand them? Continue reading the next part to know more.

#### What is a "correct" package of games?

In the previous section, we concluded that bundling games together is beneficial for both the platform and the customer. In this section, we look at some frameworks which will help us decide on which games to add/remove from a bundle? We try to dig deep about what each of our user personas value inside our app and try to look for possible solutions. We also explore some thoughts around evaluating individual games inside a bundle.

By now, most readers of my blog would have understood three basic things about RMG businesses:

- 85% of money is made from 15% power users
- Power users come to your platform for casual user population
- Recreational users come for big bonuses/awards/prizes/competitions

**Question to the reader:** You are a multi-gaming app. You have both Poker and Ludo. They both make the same daily revenue. Which game is better is for the platform? Or in other words, which game is the platform fine with removing?

**Another question to the reader:** You are a multi-gaming app. You are exploring acquiring a game studio and integrate their games into your app. How should both the parties in this transaction think about their decisions?

To answer these questions, we need to define the marginal utility of having the game on the platform. The marginal utility of this game is evaluated based on its ability to acquire new users and retain the existing user base. Or put another way, we should evaluate “how many players would leave my platform, if I remove this game today”? Or from an acquisition POV, “how many players will join my platform if I add this game today?” The quantitative answer to these questions is tightly correlated with the value of the game.

To visualize, this, lets look at at the example between Fantasy and Poker. While Fantasy has lot more users, Poker has higher marginal utility in preventing churn and attracting high value users.

![](https://rnikhil.com/assets/files/usage.png)

For example, lets imagine that if Poker was removed from our multi-gaming app, then 10% of the users would churn. If the overall platform ARPU is about Rs. 300/month and say 1M users play, this would be mean about 100k users churning out, which means a loss of 100k \* Rs.300 \* 12 (yearly) = Rs. 36Cr/yr in revenue at risk. This means, Poker is valued at about Rs.36Cr to the platform\*. This would be somewhat the amount, a gaming studio should be paid yearly if they are running the poker business for multi-gaming app.

Why is Fantasy sports valued at lesser even though it has substantially more usage? Because, the percent of power users who are going to churn out of the app is going to be substantially lesser (Fantasy has a very small power user base). Casual users won’t care much and the platform won’t be affected either.

Lets try to mathematically define this relationship:

> _**Value of game to the multi gaming platform = Value of an average user of the platform \* Marginal utility of the game in preventing churn.**_

Marginal utility of the game in preventing churn is basically the percentage of people who would churn out if you remove the game from the platform. The idea is that the value of the game is related to its impact on EVERY user of the platform. In some sense, we are distributing the power user value of the multi-gaming platform into the broader population of casual users and non-users of the platform. We are exposing them to these games for free which they otherwise would never have found on their own. Finally, to exactly calculate the value of the game, you should remove it from your app, calculate the customers you will lose and establish the revenue loss due to it.

However, this approach is not exactly practical. I cannot remove a game from my app tomorrow to prove that it has value. For a company/product manager to do this exercise, we need an alternate approach to define value of the game. Remember that earlier, I had mentioned that from an acquisition POV, value of a game is the “number of new users” it will bring to the platform because of its addition.

Lets again take the Poker example to explain this situation. I am trying to decide on including Poker into my Multi Gaming Platform. Lets assume that the value of the game standalone is X(whatever an individual game studio makes running it alone). So, if I have to think about integrating poker, how much extra revenue/value would I get? The answer definitely cannot be equal to X. To figure this out, we first need to understand our current user base and how it will overlap with Poker in the first place. Does adding this game unlock an entirely new Total addressable market (TAM) for me? or the players of this new game are already my customers?

Lets consider two extreme scenarios to answer these questions:

**Case 1:** Fully overlapped power user base. Remember, we inherently assume that single gaming apps are composed of power users only(refer to the first section of this post for clarity). This means, all the power users of poker are already an user of the Multi Gaming Platform.

To elaborate further, lets assume that the multi gaming app has 1M users with Rs. 300/month as ARPU. Poker standalone has 250k users with ARPU of Rs. 400/month. In this case of full overlap between the power user base, all these 250k Poker users are already a customer of the multi gaming app. They are poker power users but playing some casual game inside the multi gaming app for now.

In this case, so how much does the platform expect to make when they integrate/launch poker? They are still going to have the same amount of users but they with the addition of poker, the power users get activated(they were casual users before) and start playing the game inside the multi gaming app. A lot of casual users are now getting exposed to poker and power users have increased engagement inside multi-gaming app because they now have their favorite game as well. Power users like the fact that the game is bundled and they don’t have to split their deposits between two platforms and thereby have higher retention too. While some value is getting created, its hard to quantify.

However, this is the worst scenario and adds very little value to the platform. Lets look at the other case.

![](https://rnikhil.com/assets/files/overlap.png)

**Case 2:** Zero overlap between power user base. This means, all the poker power users are isolated and currently don’t play inside the Multi Gaming Platform. They only play on their standalone poker app. From the platforms POV, this is exciting because of new addition of all these power users who are now coming to your Multi Gaming Platform for the game plus the fact that existing customers of Multi Gaming Platform get Poker for free(without installing any extra app). This contributes to direct increase in revenue.

To elaborate further, lets assume that the multi gaming app has 1M users with Rs. 300/month as ARPU. Poker standalone has 250k users with ARPU of Rs. 400/month. Lets look at this integration form the eyes of both the platform and poker standalone app.

Platform: They get these 250k new users directly and get Rs. 300 \* 250k = Rs. 7.5Cr per month extra. If you go back to my first equation which is _value of game to the multi gaming platform = Value of an average user of the platform \* Marginal utility of the game in preventing churn_ and plug the numbers, power users who will leave the platform if you remove the game = value of game (Rs. 7.5cr)/Rs. 300 = 25% This is the percent of the user base which will churn out if you remove Poker which is about 250k users.

Poker standalone: They were making Rs. 10cr earlier, but the platform has assigned a value of only Rs. 7.5cr to it which means they obviously won’t agree with this integration. So, why where will the extra 2.5cr come from? Where is the calculation issue?

To understand this, we need a different way for the platform to calculate value of poker (post integration). They cannot simple use old ARPU numbers. Lets double click on this thought and try to define a practical mathematical relationship:

> _Value of game to the platform = Value of power user (ARPU) of standalone app\* percentage of customers who are power users of your game inside the Multi Gaming Platform post integration_

_Note: LHS of both equations is same.(this will matter later on).If you integrate Poker and 100% of your users become power users of poker, your platform will basically have same value as a standalone app. If nobody becomes a power user, then value of Poker is zero for the platform._

Assuming 25% of them convert to power users inside the app, now the value of the game to the platform = 250k users \* Rs. 400 (new power user ARPU) = Rs. 10Cr. Now they can happily pay the 10Cr that the standalone app wants.

This is the best scenario that the platform as well as the poker standalone app wants. Everybody makes more or equal money than they made before.

Great!. We have established some equations for defining value of a game inside a multi-gaming platform. However, this section started with the promise of teaching you to find the “optimal” packaging of games.

We introduced two ways to define value of a game. One is through understanding churn and another is through understand acquisition. Now, if we equate both sides of this equation, we have:

> _Value of an average user in Multi Gaming Platform \* Marginal utility of the game in preventing churn = Value of power user (ARPU) of standalone app\* percentage of customers who are power users of your game inside the Multi Gaming Platform post integration_

When both the previous equations match, the platform packaging the game and the game provider are in equilibrium. Both of their interests get satisfied and it makes logical sense to package the game instead of running it standalone. I would call this bundle of games “correct”.This summary is interesting because Power user% (RHS) is easer to understand and measure compared to “marginal utility in preventing churn”. For the latter, you can just look at a standalone Poker app for proxy (assuming these newly converted power users will behave the same as standalone app users) but for the former, you will have to remove Poker from a Multi Gaming Platform to measure it accurately.

> Conclusion: We defined what an optimal bundling of games should look like and various parameters affecting it. We came up with an interesting equation which can be used to form mental models regarding relationships about games and how they interact with game bundles.

But what is the implication of this equation? What does it mean for the kind of games I have to choose for my bundle? Is Poker + Ludo a better bundle or Poker + Rummy? Continue reading to answer these questions.

#### How to package games?

In first section, we concluded that, Bundling games is good when done “correctly” and in the second section we defined how to quantify what a correct bundle looks like. Now that we have concluded that we have to bundle games, we need to establish a framework around choosing and picking games to bundle inside a Multi Gaming Platform.

Lets start with the commonly established logic. You should pick and pack games which have the least amount of power user overlap and maximum amount of casual user overlap. This means, you package Poker along with card games but not with candy crush/wordle/bubble shooter etc. This also makes logical sense and I was a firm believer of this as well.

However, this section we try to determine if this is actually true and if you should actually bundle Poker with something like another card game/chess or wordle/racing game/etc.

Lets go back to the second section, where we were trying to ascertain what the game vs game bundle relationship looks like. Lets restate the equation here again:

> _Value of an average user in Multi Gaming Platform \* Marginal utility of the game in preventing churn = Value of power user (ARPU) of standalone app\* percentage of customers who are power users of your game inside the Multi Gaming Platform post integration_

We ascertained that the packaging of games will be optimal(Case 2 is best scenario to package) when there was a completely distinct power user base. The power user base of poker is being used to it maximum value by adding new customers to the platform. In the above equation, given that ARPU of users are unaffected (for our purposes), we can observe that the extra utility of having power user in the platform(preventing churn) is becoming equal to the percentage of customers who are power users of the game inside the Multi Gaming Platform.

So, what does it mean? We have proved that adding a game which already has power user overlap with your app is not the most ideal but rather adding a game which has the least overlap is beneficial. Why though? as you can see below, from the perspective of an user, if you are a power user of rummy or poker or ludo, the Multi Gaming Platform is a good value. From the platforms POV, it gets to add new users because of adding the extra game. From the customers POV, if they are a power user of either Poker or Rummy or Ludo, the app is a good deal. You can the Shishir’s post linked at the bottom for a generalized explanation of this behavior.

Now if the Multi Gaming Platform is already valuable to the user (they installed it for some game of which they are a power user of), they will not care about adding another game to it. The value of the app for the power user comes only from their target game. So, you are better off adding a game that someone else (ideally a non-user) would be a power user of instead of adding another similar game.

![](https://rnikhil.com/assets/files/mgp.png)

The customer will see value in the Multi Gaming Platform compared to the Single Gaming Platform if

- it has the game he is a power user of
- product experience of that game is equal to Single Gaming Platform
- it has at least one more game that he is a casual user of, that he wants to play. (else he will install the standalone app only)

To take this to an extreme, the best multi gaming platform would have all the games its users are power users of. Everyone gets their favorite game and also gets access to a game there are casual users of(1 game per user basically). If there are no casual users (meaning, I play only one game), then this is no worse than installing the game separately. But any amount of casual user overlap will justify the packaging of games. Fundamentally, this basically tells that multi gaming apps is more about providing value for casual users than power users.

> Conclusion: Add games which have minimum power user overlap and maximum casual user overlap. This is why Poker + Ludo is better than Poker + Rummy.

This section is the most counter intuitive of all the other sections. Because, we basically concluded that we should be adding games which are diverse and have the least amount of power user overlap. Does this mean, I will add a racing game to my Poker platform? Short answer is yes, but with some nuances. It is hard to market super diverse bundles. If very hard to market a poker + racing Multi Gaming Platform compared to poker+rummy Multi Gaming Platform. But that is just a marketing challenge because we now know for a fact that our games have to super diverse and minimize power user overlap. Same reason Amazon is bundling Prime Video with fast shipping. To summarize :

- Put together a list of games with minimum power user overlap and maximum casual user overlap
- Ensure that there is no downgrade in user experience for power users in each of these games
- Show users only the games that they are likely to be a power user of
- Make sure there is clear integration value and the app is overall coherent.

**_Final thoughts_**

Bundling is a natural evolution for many businesses and can lead to increased productivity and value. Amazon, Netflix, McDonald’s, etc all use it to their advantage and continue to add very diverse items into their bundles. Netflix has games. McDonald’s hands out toys with burgers and the Amazon Prime package is massive and diverse.

However, we should be cautious as well. There are some unmeasured factosr which I have omitted in the article like:

- conversion% of power users after you integrate may not be 100%
- power user behavior can change with time (influenced by losing money)
- matching product experiences between SGP and MGP is hard
- this framework doesn’t work if the ARPU difference is very high between the game and the platform

This framework can be applied to more general product development, such as contemplating which set of features to put behind a subscription service. You can use this framework to decide the marginal utility of any single feature/product. Bundles of the future will be larger and more diverse than what we have today because packaging has a natural economy of scale attached to it. It is much easier to go from 100M users to 101M users than it is to go from 0 to 1M users. This is largely caused by casual user overlap (there are no 100M power users) - the larger your bundle, the more casual users you can amortize costs between and faster you grow.

If you liked reading this post, please share it with your product and business friends and checkout my other posts too:

- [GTO Inspector - My attempt at building an online business](https://rnikhil.com/2022/06/15/gtoinspector-startup.html)
- [Some notes on RMG market in India](https://rnikhil.com/2023/04/03/gaming-state-india.html)
- [Make Poker Fun again](https://rnikhil.com/2022/08/22/profit-growth-gamification.html)

Further Reading and Sources:

- [The effect of anchoring in product bundles](https://repositorio.ucp.pt/bitstream/10400.14/26226/1/152116038%20Marta%20Gomes%20W.pdf)
- [How Buyers Evaluate Product Bundles: A Model of Anchoring and Adjustment](https://www.jstor.org/stable/2489825)
- [Shishir Mehrotra’s post on bundling in general](https://coda.io/@shishir/four-myths-of-bundling)
- [The OG Chris Dixon post on “How bundling benefits sellers and buyers”](https://cdixon.org/2012/07/08/how-bundling-benefits-sellers-and-buyers)

\*Do notice the fact that we aren’t talking about game revenues here but some intrinsic concept called “value of the game” which we are trying to define.

April 9, 2023 · [gaming](https://rnikhil.com/tag/gaming), [product](https://rnikhil.com/tag/product), [opinion](https://rnikhil.com/tag/opinion), [bundling](https://rnikhil.com/tag/bundling)

## Game Evaluation Guide
## How to evaluate a game for your startup?

As a product manager working in gaming, its impossible to miss the recent rise of multi gaming platforms which package multiple individual games together inside one app. Doing this has a lot of benefits and you can read my previous blog posts to better understand [how bundling benefits everybody in the ecosystem](https://rnikhil.com/2023/04/09/multi-vs-single-gaming.html). In this post, we investigate intrinsic aspects of a game apart from their **powerUser:casualUser** ratio and delve deeper into what makes a game successful by itself. In the previous post, we looked at how different games interact with each other inside a MGP and in this post, we will look at ways in no particular order to evaluate a game in isolation. All games are looked at from a real money gaming POV.

#### Market

- How big is the market currently? How fast is it growing? Ludo was a nascent market couple years ago but it has been growing faster than the rest of the other games in the last couple years. While Poker is an older game, it has been growing slower than the rest of the industry.
- [Some notes on RMG market in India](https://rnikhil.com/2023/04/03/gaming-state-india.html)
- Size of the market would also determine your competition. If you are planning to enter Rummy today, your acquisition costs would be high relatively compared to doing a new game like Carrom.

#### Learning Curve

- There are two important factors here:

  - Skill vs luck ratio of the game which makes it appealing for a new player(because its winnable) to participate. You want a new player to think that he has a chance at winning at money online.
  - Steepness of the learning curve and how long it takes to master the game.
- You ideally want games which are super easy to learn and takes infinite time to master. This will ensure longevity and the game might eventually become a sport.


![](https://rnikhil.com/assets/files/lcurve.png)

#### Legality and regulations

- This is actually getting clearer by the day in India. Self Regulatory Organizations (SRO) are going to be established in about 2-3 months. These SRO’s comprised of [AIGF](https://www.aigf.in/) \+ the leading RMG companies from India will determine what is a “skill” game and define frameworks around game certification. Presumably, once certified as a skill game, you should be able to advertise and promote freely everywhere. Overnight bans from different states will reduce and RMG can finally stop being a “gray” market in some jurisdictions.

#### Familiarity of mechanics or Popularity of the game

- Games like Rummy and Ludo are culturally familiar to us and thereby also are immensely popular digital games. Ludo has always been in the Top 3 highest grossing casual game on Google Playstore and Rummy RMG has been about 90% of the industry since inception. Almost all RMG games are round off errors (except Fantasy of course) when compared to Rummy.
- This does not mean that you cannot be launching any new game in India. Familiar game mechanics inside a new context ( [Coinmaster](https://play.google.com/store/apps/details?id=com.moonactive.coinmaster&hl=en&gl=US) or Striker club (Marvel snap + Fantasy) is one approach as well. You can also look for game inspirations where your current RMG users spend time (like a casino, Win Patti by MPL is an example) or look at casual gaming charts to make RMG variants or create new monetization business models (like PUBG, GGX etc).
- **Is there enough power user population for the game?** Can it be a (e)sport someday?

#### Monetization potential

- As we know in RMG, 80% of our revenue is going to be derived from 20% of your super users. If the game never reaches super user potential and all you can run is Rs.1 loops of the game, you will not be profitable. There should be enough users who have passed your skill(or luck) curve that they are willing to play Rs. 1000 loops of your game. If there is not enough critical mass achievable here, the game won’t work in a RMG setting.
- Alternate monetization angles like collectibles and IAP for free to play games are growing these days too.

#### Network effects

- Does the game get better with more people playing it? While tournament formats are fueled by compounding network effects, cash game/1v1/ SnG variants don’t benefit as much from more players playing (beyond a point, it doesn’t matter if you have 1000 active players on one stake or 10000 players.). Games where MTTs(or any tournaments) is the main format like Fantasy benefit from this for example.

#### Variance in reward distribution

- Variance in nothing but the _standard deviation_ of the players win rate. While the previous skill vs luck discussion tells us about the outcome, variance tells us the distribution of outcome with time
- Some examples of standard deviation for different poker formats: NLH(9max): 60-80 BB/100, PLO 6-max: 120-160 BB/100, PLO Heads up: 220 BB/100. Higher the number, higher the variance. You can see that heads up poker has insanely high variance compared to full ring poker.This basically tells us the randomness of the reward distribution from the average win rate of the player. So, a short heads up session will have a bigger monetary swing compared to a similar session on a full ring (9max) table on an average.
- Higher the variance = higher the wins and losses w.r.t time = more fun for new players

### Conclusion

- In the previous blog, we discussed about how two games interact with each other and in this post, we looked at some ways to evaluate and pick a game for our bundle. Do remember that the games you pick initially and the dimension you focus on to evaluate them would determine your product and strategy. For example, if the game has high power user population, your game discovery should be more towards satisfying their core need/game, skill vs Luck factor of the game would determine your FTUE and how you will deal with the learning curve and cultural significance of the game would determine your GTM etc. Ultimately, your selection of games should determine the product and discovery and not the other way around. I would like to end this post with a rap written by GPT4 summarizing this post.

If you liked reading this, checkout my other posts too:

- [Do multi gaming apps make sense?](https://rnikhil.com/2023/04/09/multi-vs-single-gaming.html)
- [Some notes on RMG market in India](https://rnikhil.com/2023/04/03/gaming-state-india.html)
- [Make Poker Fun again](https://rnikhil.com/2022/08/22/profit-growth-gamification.html)

May 14, 2023 · [gaming](https://rnikhil.com/tag/gaming), [product](https://rnikhil.com/tag/product), [rmg](https://rnikhil.com/tag/rmg), [opinion](https://rnikhil.com/tag/opinion)

## Game Metrics Checklist
## Gaming - Pre and Post launch checklist

This post is a checklist for game developers and product managers to use during the pre-launch period and some important metrics to track immediately post launch. We are assuming that the game has been developed(and tested) and is in the final stages of going live in a single country.

I made this list originally about 8 months back as part of launching PLO at Paytm First Games and have edited it minimally for this blog post.

### Pre launch checklist

Imagine you are launching a game on Google Play Store. This document gives you a high level checklist to run through to make sure you don’t miss any pre-requisites before your deployment. This is a very generic checklist not specific to a platform or region and this is why you wont see any mention of build file types or translation. Also this is for the final launch not for soft launch and experiments before worldwide publishing. At every step of the checklist ensure that you have a “Final approver” who owns the individual items.

- Pre-register app campaigns to build up excitement and the rush of install on Day 1. Make sure to open up pre-registration a couple weeks before your launch
- Ensure that you have the game icon, screenshots, advertising banners, social promotional banners, sneak peak trailer, launch video trailer, advertising optimized videos and the emailer/mailing list ready for launch date
- Assuming that QA has signed off on the game(including analytics pipelines/reports testing and game load testing), we should also be doing QA for the banner/video ads, IAP, referral system, app store review system and basically any additional SDK that is baked into the game
- Get a team ready for player support. They should be equipped with FAQs, should be able to answer general queries and available through email and any game forums. Do a CST tool integration also if necessary
- Setup an escalation matrix in case of emergencies for tech, art, server, QA, marketing, acquisition, analytics, live ops legal and the core game
- Research competitors to make sure there aren’t any impending launches coming up around your launch date. Analyze the CPI for various games in the same genre, theme, or even monetization model. Consider your options and budget for promoting, maintaining the game as part of this process.
- Make sure to have your influencer marketing pipeline ready for Day 1 of launch
- Copy/content for keywords, short/long description of the game, emailers (prelaunch and launch), PR, social posts should be ready as well

### Post launch tracking

This section of the document deals with some important stuff you should be tracking after your game is launched.

- Traffic/Views/Download/Install/Sign up/Finish tutorial (funnel analysis)
- Leads generated from launch campaigns
- Acquisition funnel at a channel level along with promo channel metrics
- Number of downloads
- Cost per install
- User stickiness (DAU/WAU, WAU/MAU). Should also be measured at a channel/affiliate level to measure quality of incoming traffic
- Retention and churn rates (for different time periods)
- Conversion rate, time to first purchase and average revenue per install
- [Day 1 minutes played vs Day 2 retention](https://medium.com/googleplaydev/why-the-first-ten-minutes-is-crucial-if-you-want-to-keep-players-coming-back-to-your-mobile-game-4a89031b6308)
- [DAU return % vs DAU/MAU](https://medium.com/googleplaydev/why-focusing-on-tomorrow-brings-back-players-in-the-long-run-e57c51bd3481)
- Daily revenue (DAU \* conversion rate \* ARPDAU) and customer lifetime value
- Minutes per day and per session. Also measure time between sessions
- Level progression and retention rates for each level (assuming you have some kind of tiered progression inside the game)
- k-factor (% of referral invites which were accepted and on-boarded). Sort of measures the viral nature of the game
- Customer support ticket reports, IAP reports, daily play store review reports

July 6, 2023 · [gaming](https://rnikhil.com/tag/gaming), [product](https://rnikhil.com/tag/product), [checklist](https://rnikhil.com/tag/checklist), [metrics](https://rnikhil.com/tag/metrics)

## Quitting Full-Time Poker
## Farewell to the felt - Quitting the full-time Poker scene

[HN discussion](https://news.ycombinator.com/item?id=38262425)

> This post is mostly about the shortcomings of a **professional** Poker career

I used to play Poker for a living from 2018-2021. These days whenever I recount my past with new people, everyone inevitably asks me why I stopped playing the game (full time) if it was profitable to do so. Its understandably hard to comprehend why anybody would stop pursuing a money making endeavour. So, I want to write this post to summarily answer most questions around this topic and mostly because I am tired of repeating myself again and again.

I was working as a product manager at [Flipkart.com](https://flipkart.com/) back in 2020 and around that time, I quit my job to pursue the game for two main reasons:

- The lifestyle and the freedom that comes along with playing Poker full time. You aren’t answerable to anybody. You set your own schedule. You can play from anywhere, travel all the time and visit casinos in cool places.
- Financial incentives. Poker has the best hourly rate for any job in India. The money is simply un-comparable to any job a 20 year old can get and is close to VP+ level in unicorn/FAANG companies

I stopped playing full time because both of the above premises turned out to be _false_. Let me explain

- Imagine sitting in front of a screen for 12-16hrs a day, clicking buttons (without [tilting](https://en.wikipedia.org/wiki/Tilt_(poker))) for a living. Money has lost its meaning long time ago. You don’t care about the wins anymore and the losses still hurt. Winning is not fun because by now you are very conscious of the fact that you can lose 10x that amount any week/day. Your net worth is swinging everyday and variance can be brutal. In fact, you are at the mercy of variance on a day to day basis. I have seen fellow top notch Poker players running below EV for 5-6L hands which is a year worth of effort. Imagine doing everything correct(studying, playing well, not tilting etc) and still end up negative for the entire year and have nothing to show for the work. This is entirely normal in certain high variance Poker games like PLO6, especially when relative edges are lower and rake is high (Indian high stakes basically)

  - As a Poker player, the main fundamental thing is putting volume(no. of hands played / hour/day/week whatever). Now, you can’t be jet setting around the globe and putting in the required hands.
  - _There is a reason professional Poker players are called grinders. Its a grind_.
  - Moreover, its not at all enough to just play Poker. You need to be at the top shape mentally and physically as the game takes a heavy toll on yourself. This means getting mental coaching session 3x a week, getting theory coaching, hand reviews, etc which is up to 20hrs a week. Its actually way way more hectic schedule than working a simple day job especially given there are no breaks/weekends/festivals etc.
    - But all of the above sacrifice is worth it because you are also making 10x your day job. Right? Not really. Let me explain in the next section.
- The 95th percentile Poker income is about $200-250k. While this number looks big on paper(relative to what they pay at Flipkart), there are some caveats. Also, when you suddenly start making 10x your previous income, it clouds your judgment. Its hard to think long term.

  - This figure doesn’t grow with time. Sure you can move up the stakes but then you will also be playing vs really good players and your relative edge goes down. Beating the rake is hard and you have to constantly study/work on your game everyday. Your skill curve will plateau hard after a point and its super hard to become the world best. Its basically professional athletics at that level.
  - However, tech salaries and startup outcomes grow with time. Your experience compounds. You get equity. 95th percentile financial outcome in tech is much much bigger. Flipkart is actually a good example of a top percentile outcome for its employees. 50+ folks supposedly made $10mil + which is super hard to make in Indian Poker in 15 years. “Indian Poker” is the key word here.
- And finally and this was one of the _biggest_ reasons I shifted back to job is because I missed:

  - **Working with smart folks**. Sure, I was lucky to study/learn from some really smart folks but most days I am playing against randoms and its not intellectually stimulating. (remember winning money has stopped being stimulating as well and now you are searching for something better)
  - **Building something tangible at the end of the day**. I want to have something to show at the end of 10yrs and not just numbers in my bank account
  - Poker is a very lonely game. You are solely responsible for your outcomes. While this is intoxicating as a naive young kid, you soon realize that all worthwhile stuff is built through collaboration and smart folks working together
  - Mental health goes for a toss as you are swinging for a % of net worth everyday. You results are sometimes out of your hand and that sucks. Your base dopamine levels get screwed and you no longer get excited by stuff which you used to enjoy before. Its actually a pretty commonly acknowledged problem in the poker/trading community
  - Politics and networking. While some Poker players argue that this is part and parcel of being a professional, I was personally uncomfortable sucking up to whales/big fishes to get access to their games. I was unwilling to fake my persona/feelings just to get a juicy chance to play in a game. I just wanted to put in my hands, play my game style, move on and not deal with the politics. With that attitude and disinclination towards bum-hunting, I was anyway not cutout for the highest stakes (its a compulsory now to do this as highest stakes in India are all private games). One of my Poker and life heroes Phil Galfond writes a lot about this on his [blog](https://newsletter.philgalfond.com/). Do check it out.

TBH, in-spite of all the reasons stated above, I was totally confident in my self to become one of the top pros in the world if I grinded for another 10-15 years. But after meeting them, their lifestyle, earnings, swings etc, I wasn’t sure I wanted that life for myself when I am in my early 40s or late 30s. I was pretty sure I didn’t want to be playing cards for a living for 20-25% of my lifespan which felt incredibly wasteful to me personally.

The above were my personal reasons for moving away from Poker. There are some other things like changing life priorities, achieving financial security, long-term sustainability concerns and regulatory/compliance challenges which I haven’t elaborated much on. While bidding farewell to a successful career in professional Poker is undoubtedly a significant decision, it is essential to recognize that life is a dynamic journey, and priorities evolve. I would like to think that I evolved and can judge decisions better.

In conclusion, I didn’t think through the minor caveats of the career path and was fascinated by the competitive aspect(you play something for a living which I still find fun) and the money. However, I am still extremely grateful about my journey. I learned another skill and I probably can always find a way to support myself in dire situations. Poker has taught me a lot of life lessons and has immensely shaped how I view the world on a day to day basis. I am better at quantifying risk , looking at decisions from a EV perspective(instead of being results oriented) and overall having a good idea of how to judge EV of a situation. Things like bank roll management, the mental stamina, propensity to take immense amount of stress repeatedly, grit etc are also things that Poker teaches you and I probably should write another post about my life lessons from the game if enough people ask me that question IRL.🤣

If you liked this, checkout my other posts on building a business in Poker and how to think about bundling games:

- [GTO Inspector - My attempt at building an online study tool](https://rnikhil.com/2022/06/15/gtoinspector-startup.html)
- [Do multi gaming apps make sense?](https://rnikhil.com/2023/04/09/multi-vs-single-gaming.html)

November 12, 2023 · [poker](https://rnikhil.com/tag/poker), [gaming](https://rnikhil.com/tag/gaming), [opinion](https://rnikhil.com/tag/opinion), [startup](https://rnikhil.com/tag/startup)

## Scaling Laws for LLMs
## Chinchilla Paper explained

Whenever I see a discussion online about the current generation of LLMs, there is an inherent assumption and extrapolation that these technologies will keep improving with time. Why do we think that? The approximate answer is because of **scaling laws** which suggest indefinite improvement for the current style of transformers with additional pre-training data and parameters. This blog post delves into the intricacies of these scaling laws and examines how they guide the development of more powerful and efficient LLMs. I will be as comprehensive as I can (with the math knowledge I have) including parts about the scaling law origins, recent finding and their implications.

First we will try to understand the basic variables involved in scaling large language models:

- **Parameters of the model**. We will be using it as a proxy for size and its a broad term that includes both the weights and biases of a model. The size of a neural network typically refers to the number of trainable parameters it contains.
  - Weights and biases are the values learned during the training process and they represent the “weight” of a connection between neurons of different layers.
  - Parameters and hyper parameters are different. Hyper parameters are your model config settings like learning rate, no. of epochs, batch size etc and aren’t learned from the data itself. They are set during time of training and are irrelevant to our discussion
- **Compute**. Usually represented in FLOPS(basically no. of arithmetic operations per second). Here, we use it to estimate training complexity of the neural net. While calculating FLOPs to dollars is not straightforward and will depend on hardware used and energy costs, we will use it as a proxy for money spent.
- **Tokens**. This is just a proxy for the size of the training dataset
- **Performance**. This is nothing but how the trained model performs on certain benchmarks designed to evaluate across axis like classification accuracy, generalization ability, efficiency and task specific metrics.
- **Compute Optimal**. Its basically a concept which determines how to extract the most performance out of your model given a constrained compute budget and model size.

There were three seminal publications in this field as listed below. This post will focus mainly on the Chinchilla paper

- [Kaplan Paper](https://arxiv.org/abs/2001.08361)
- [Chinchilla update to scaling laws](https://arxiv.org/pdf/2203.15556.pdf) (Mistral AI co-founder was one of the first authors)
- [OpenAI scaling laws](https://arxiv.org/pdf/2001.08361.pdf) (Kaplan is a co-founder at Anthropic)

_The first Kaplan paper basically showed that there is a power law relationship between the number of parameters in a LLM and its performance._ Kaplan paper suggests that to train larger models, increasing the number of parameters is 3x more important than increasing the size of the training set This implication basically led to larger and larger models getting trained expecting performance improvements. While the following Chinchilla paper comes to a similar conclusion, they estimate that large models should be trained for many more training tokens than recommended by the Kaplan paper. Training an optimal model requires about 20x more tokens than parameters.

![](https://rnikhil.com/assets/files/computexsize.png)

So in around late 2021, the Deepmind team went on to train about 400 models ranging from 70 million to 16 billion parameters on datasets ranging from 5 to 500 billion tokens. They did a bunch of experiments and found some interesting results. Specifically, given a 10× increase computational budget, Kaplan paper suggested that the size of the model should increase 5.5× while the number of training tokens should only increase 1.8×. Instead, Chinchilla states that model size and the number of training tokens should be scaled in equal proportions. To demonstrate this they trained a model (Chinchilla) which had better performance than comparative models for the same compute budget.

![](https://rnikhil.com/assets/files/chinchilla.png)

#### How did they find this?

The fundamental question they were trying to answer was _“Given a fixed FLOPs budget, how should one trade-off model size and the number of training tokens?”_ . Its basically an optimization problem where you fix one variable (FLOPs) and try to find the optimal values for parameters and tokens. However, every time they have to test a value for parameters/tokens they have to train a model which costs millions of dollars. For the paper, they trained over 400 models with varying values of parameters and tokens taking certain approaches. Lets look at them below:

- Approach 1: Fix the parameter variable and vary the size of the training tokens

![](https://rnikhil.com/assets/files/app.jpeg)

Here, they took a couple models with parameters ranging from 70M to 10B and trained them _each_ on four types of datasets (differentiated by size). Based on this training, they were able to estimate the model with minimum loss (we will use loss as proxy for model performance as far as this blog post is concerned) for a given compute budget. As you see above, they were able to determine the best model (parameters/token) for a given compute budget by looking at the loss value of every trained model.

![](https://rnikhil.com/assets/files/plot1.png)

- Approach 2: Fix the compute budget and vary the number of parameters of the neural network

In the first approach, they fixed the number of parameters of the model and trained them on multiple token sizes. Based on the compute used for each model, they were able to select the model with the ideal parameter/token size for a given budget. In this approach, they fix the amount of FLOPs for each model and vary the number of parameters for each model. According to this approach, Google would have had to train PaLM with about 14 trillion tokens to obtain the optimal loss for a 540B parameters model.

![](https://rnikhil.com/assets/files/app2.png)

- Approach 3: Take data from first two approaches and try to find a function for loss values

This approach was slightly mathematical in nature and I shall skip directly to the results. We find the model with the lowest loss value for a given compute budget and model size.

![](https://rnikhil.com/assets/files/app3.png)

Throughout the three approaches, the paper keeps referencing the Gopher model (which was earlier trained by Deepmind only) to try to demonstrate the optimal values for parameters and tokens given the compute size that was historically used. They find that the optimal model size given the Gopher budget to be a 67B model instead of the 280B they actually trained.

#### Conclusions

Modern large language models have been oversized unnecessarily. With no added performance, companies have been training massive models wasting resources. Here is a table showing optimal training FLOPs and training token for different model sizes.

![](https://rnikhil.com/assets/files/conc.png)

After training more than 400models to prove the above relationships, they train the Chinchilla model to drive the point across. The idea of this model was to take the above relationships and REDO Gopher. They used the same amount of computer budget as Gopher but used 70B parameters and 1.4T tokens to train Chinchilla and it ends up outperforming Gopher is a lot of benchmarks. For the same amount of money spent, they got a better model out basically. Moreover, its cheaper to run inference on smaller models leading to more cost savings over the long run.

Current models are extremely oversized for their performance. Going after parameters is inefficient. While AI labs have been going after larger and larger models, post Chinchilla era dictates that they should be going after massive training data as well. This requires research into more optimization steps and increases in batch sizes (which however has adverse impact on model performance after a point). The problem of maintaining training efficiency while increasing data size becomes very important to solve. We also might be running out of data as this [Lesswrong article](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications) implies.

###### [Emergent properties](https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/\#references)

I originally started writing this document to explain the Chinchilla results and ponder over certain emergent behavior to make an educated guess about AGI timelines. An amazing property of LLMs is the emergence of new capabilities as the size of the network increases. In other words, LLMs unpredictably learn to perform new tasks, without having been specifically trained to do so. The system becomes more complex than the sum of the parts. Here is a GIF from the Google PaLM paper showing the same.

![](https://rnikhil.com/assets/files/emergent.gif)

We currently don’t know at scale emergent behavior shows up and we can’t even estimate the level of ability or even the potential categories of such abilities. [This paper](https://arxiv.org/pdf/2206.07682.pdf) from Google shows that emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence also raises the question of whether additional scaling could potentially further expand the range of capabilities of language models or not. On one side, we have the Chinchilla paper showing us that the model performance keeps getting better with increasing parameter and token size. On another side, we have established that emergent behaviors keep popping up with increasing model scale. Ilya Sutskever uses the above to basically explain [why next-token prediction is enough for AGI?](https://www.youtube.com/watch?v=YEUclZdj_Sc). Maybe figuring out a relationship between next word prediction accuracy and reasoning abilities could be the way to make current gen LLMs truly intelligent.

The convergence of scaling laws and emergent abilities not only makes me excited for the future of AI but also brings in a new era where the unforeseen capabilities of AGI could revolutionize our understanding of intelligence itself.

November 28, 2023 · [scaling](https://rnikhil.com/tag/scaling), [ai](https://rnikhil.com/tag/ai), [chinchilla](https://rnikhil.com/tag/chinchilla), [llm](https://rnikhil.com/tag/llm), [openai](https://rnikhil.com/tag/openai)

## AI Coding Extension
## Building a chrome extension using only AI

I’ve been dabbling with generative AI tools for the last couple months and being a hobby programmer, checking out and tinkering with them is my favorite pass time(full time given that I am on a sabbatical). Like anybody else, I’ve been amazed by the recent developments in AI coding tools particularly. AI tools like [AlphaCode](https://deepmind.google/discover/blog/competitive-programming-with-alphacode/), a system for code generation achieved an average ranking in the top 54.3% on recent programming competitions on Codeforces. This is pretty impressive and [AlphaCode2](https://www.youtube.com/watch?v=LvGmVmHv69s) which was released last week pushes this up to 85%. These developments are fundamentally going to change software engineering in the next 5 years. Similarly, given that competitive programming questions are the primary ways candidates are also judged during interviews, we are going to see a new paradigm of evaluation come up for software engineers. Codebase onboarding for new employees, pair programming, debugging etc are all going to fundamentally change and the developer workflows 10yr down the line would be drastically different than when I started out.

I wanted to give these tools a try and see if its actually possible to build an end to end project with >95% code written by AI. To keep it simple I decided to build a simple chrome extension which takes an OpenAPI key as an input, and generates an image based on either a text prompt or text selected in the current webpage. The last chrome extension I built was some 8yrs ago and the only thing I remembered was that it has a `manifest.json` file which contains all the config. That was literally the only thing I remembered about building Chrome extensions and I did not reference the docs even once throughout this whole exercise.

My setup for building this was fairly simple. [Cursor.sh](https://cursor.sh/) along with my OpenAPI key was all I used. I simply loaded the extension manually into Chrome and used developer tools for inspecting any errors.

This was my first prompt I used

```
build a chrome extension to generate images using DALL E api based on the text selected on the browser or by inputting a custom text prompt.
The extension should take the API key from the user and generate images inside the popup. Generate all the files.
make me a popup.html page. it should have a text field to input and save an openai key, input for a text prompt, download button to download the generated images, regenerate button

```

After some to and fro, I got the basic wire frame ready for my extension. Loading the popup.html looked something like this:

![](https://rnikhil.com/assets/files/ext.png)

After this I followed up the following prompt:

```
include the dalle api interaction, the download logic for images,
also, after successfully saving the api key, show a small "saved" icon beside the "save" button.
Edit my popup.js and popup.html to make this work

```

This required some debugging on my end feeding the errors back to the AI. It helped debug a CORS issue where I missed adding the OpenAI domain permissions to the manifest file. I also had a type error due to improper handling of DALL E API response which was again handled by GPT4. Finally I asked it to beautify my popup.html with some spacings and unique colors for every button. Every single JS function worked flawlessly as intended despite me not even writing 2% of the code.

You can find the source for the extension [here](https://github.com/r-nikhil/imageGen-chromeExtension) on my Github. Overall I’ve been pretty impressed by its coding abilities and tools like these exponentially increase the productivity of hobbyist developers like me and I am really looking forward to coding more again.

November 30, 2023 · [ai](https://rnikhil.com/tag/ai), [coding](https://rnikhil.com/tag/coding), [cursor](https://rnikhil.com/tag/cursor), [extension](https://rnikhil.com/tag/extension), [llm](https://rnikhil.com/tag/llm)

## AI LLM Security
## LLM security - Introduction

Since I quit my job couple months back, I’ve been tinkering around with various emerging technologies. I have been pretty obsessed with the current AI evolution of large language models (LLMs) and their surprising text generation capabilities. Whether you are surprised or not, people have started integrating them into just about every software we interact with and after spending countless hours asking it to generate song lyrics, I eventually wanted to understand what was happening behind the scenes. I am no AI engineer and I barely remember the Machine learning/ Neural network courses I took in college, but given my computer security background, what better way to learn how these LLM’s work than by trying to break them? In this post, we look at the basics of AI security, current “known” attacks, common defenses and some CTF challenges. I’ve been meaning to write this post for a while but this field was moving so fast that keeping up latest publications is a full time job. Now that NeurIPS is over and things have calmed down, I finally got time to work on this.

![](https://rnikhil.com/assets/files/attacks.png)

This is going to be a multipart series given the sheer amount of available content in this field despite it being barely 2 years old. Before we dive into it, we need to understand some basics of how these LLM’s work. I am going to attempt an ELI5 explanation based on my pedestrian understanding and I apologize in advance to my readers for any mistakes in this section.

#### Text generation

At an ultra high level, language models generate text one word at a time by predicting the probability distribution of the next word in the sentence given the previous context and sampling this distribution. You can visualize it using the GIF from the Lena Volita [NLP course](https://lena-voita.github.io/nlp_course/language_modeling.html) below

![](https://rnikhil.com/assets/files/generation_example.gif)

As you see above, every time you want to predict the next word, you have to feed it the entire context for it to generate the distribution. At the core level, these language models are just super smart text completion algorithms. But how does this work in a chatbot setting? Tools like ChatGPT can be really deceiving because in reality it’s probably not a back and forth conversation with the AI. Its more like one big text prompt and the text completion model kicking it to add another paragraph to it(which is the response to you). Its been [manually tuned](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback) by humans to tailor the responses to make it seem like a back and forth conversation. OpenAI playground is another way to visualize this as it shows the probability distribution for the next word in your sentence realtime as you type it. Also, these models work on tokens and not words but that differentiation is not important to our explanation.

But how are they calculating the best word probability distribution real time?

#### Neural networks

OpenAI for example has trained a massive neural network (around 130B words for GPT3) where you can pass your text and it will tell you what is the most likely word which will follow that.

![](https://rnikhil.com/assets/files/neural.png)

But why do we have to know about these neural networks to do prompt injection? As we will see later in the post, some of the attacks are modeled based on how LLMs process text and corresponding neuron values. Some neurons track the [length](https://arxiv.org/abs/1506.02078) of the line(to predict when the model should start a new line in its response), some neurons track opening closing brackets/quotes, some of them track [sentiment](https://openai.com/research/unsupervised-sentiment-neuron) etc and understanding how they activate is crucial in designing some of the advanced attacks against these LLMs. Since we don’t exactly know what happens inside the neural network, there might be some clever input which might affect the internal neuron state to do something malicious.

#### What is prompt injection and why does it matter?

_Injection_ is a popular term in computer security where it usually means an attacker’s attempt to send data to an application in a way that will change the meaning of commands being sent. There are many kind of [injection attacks](https://www.acunetix.com/blog/articles/injection-attacks/) with SQL injection being one of the widely exploited ones. Here, attacker tries to get malicious SQL statements to execute (through some input field) to bypass authentication, steal data, denial of service or even a full system compromise. Prompts these days are nothing but instructions to the AI. Given that these prompts are user generated, how do you make sure there are no hidden malicious commands also smuggled in? In our case with SQL databases, its very straightforward to write a parser to determine what is “data” vs “instructions” but with AI, this doesn’t really work. Everything is just one big blob of text.

What is the thread model? Well, the LLMs works with a text prompt. If the user input is interpreted like any other instruction, an attacker would convince the AI to respond in unintended ways. How does it matter? We don’t know the full extent of that yet but here are some examples:

- Bypassing AI content moderation
- Extract data from personal assistant AIs running on top of your data.
- Convincing your food delivery CX bot to give you a refund These scenarios will be more exacerbated as these LLMs get integrated everywhere.

#### Different types of prompt injection

There is a lot of content online about various prompt hacking methods. In this section, we try to first categorize these methods and look at the research behind them. Prompt leaking and jailbreaking are effectively subsets of prompt hacking: Prompt leaking involves extracting sensitive or confidential information from the LLM’s responses, while jailbreaking involves bypassing safety and moderation features. We will also discuss specific offensive techniques as well as defensive techniques.

#### Attacking LLMs

- Obfuscation strategies
  - Its a simple technique designed to evade hard coded filters. Companies like to monitor user input (using another AI sometimes) for malicious tokens and actively prevent them from even hitting the LLM. Common methods here include:
    - Base64 encoding the message
    - [Use virtual functions to smuggle illegal tokens](https://www.reddit.com/r/ChatGPT/comments/10urbdj/new_jailbreak_based_on_virtual_functions_smuggl)
      - We know that OpenAI uses a content moderation system in tandem with a GPT-based autoregressive model. Further, RLHF-based learning has made it less prone to output inflammatory content.

![](https://rnikhil.com/assets/files/mask.png)

- The key attack vector is to first develop some internal computational modules. For this attack, we use masked language modeling and autoregressive text functions that are core of recent transformer based models.

![](https://rnikhil.com/assets/files/functions.png)

- Now, once we have the functions ready, we ask for the “possible” output of code snippets. (tried to use 4chan here). Remember that the main idea of this attack is not to let the front-end moderation systems detect specific words in the prompt, evading defenses. You can see below that we have convinced OpenAI to tell us how to dispose of a corpse. Not what I saw in Breaking Bad.

![](https://rnikhil.com/assets/files/out.png)

![](https://rnikhil.com/assets/files/outres.png)

- Code injection is an exploit where the attacker is able to get the LLM to run arbitrary code. This can occur in tool-augmented LLMs, where the LLM is able to send code to an interpreter, but it can also occur when the LLM itself is used to evaluate code. If you check this [example](https://atlas.mitre.org/studies/AML.CS0016/), people were able to extract the OpenAPI keys from a startup called MathGPT but just asking for it.

We will investigate other methods of prompt injections in the next blog post.

December 18, 2023 · [ai](https://rnikhil.com/tag/ai), [llm](https://rnikhil.com/tag/llm), [security](https://rnikhil.com/tag/security), [prompt](https://rnikhil.com/tag/prompt)

## LLM Security Strategies
## LLM security - Part 2

In the previous blog post, we gave an introduction to how LLMs work and started looking at various offensive measures that we use to break them. In this post, we will explore more offensive strategies, look at examples from the wild and also briefly touch upon the common defenses used by AI companies.

- Payload Splitting. This is just basically splitting the adversial input into multiple token. Common ways this is achieved is by
  - Separating all the letters with a comma
  - Defining a simple math function which will help add up the malicious input in real time
    - a is “Explain in detail” . b is “how to make a bomb”. Execute a + b to the LLM instead of sending them separately
- Exploiting nuances in common training datasets. Using strings like “tldr”, some emojis etc trick LLMs into giving out info which is generally protected
- Creating a fake dictionary. This is commonly used to bypass sandwich defenses where there is a system prompt before the user input AS WELL AS after the user input. Here is an example from [learnprompting](https://learnprompting.org/docs/prompt_hacking/offensive_measures/defined_dictionary) showcasing this.

![](https://rnikhil.com/assets/files/img1learn.png)

- The above is the defense and below we can see how to bypass it.

![](https://rnikhil.com/assets/files/img2learn.png)

- Poisoning the training data. Most LLMs these days are trained on the internet and buying up expired domains and loading them with malicious content would inadvertently poison the model as well. [Nicholas Carlini](https://nicholas.carlini.com/) shows how he bought expired domains corressponding to URLs in popular image datasets which gave him control over 0.01% of each of these datasets(LAION-400M). He is a researcher at Google Brain and he recently gave a talk on how the attack works, consequences and potential defenses. You can find the video below. I would also suggest you to visit his website to learn more about his work on AI security. He even has a paper demonstrating ways to extract the training data itself from language models which I thought was pretty cool.

Poisoning Web-Scale Training Datasets - Nicholas Carlini \| Stanford MLSys #75 - YouTube

Stanford MLSys Seminars

22.9K subscribers

[Poisoning Web-Scale Training Datasets - Nicholas Carlini \| Stanford MLSys #75](https://www.youtube.com/watch?v=h9jf1ikcGyk)

Stanford MLSys Seminars

Search

Watch later

Share

Copy link

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

Full screen is unavailable. [Learn More](https://support.google.com/youtube/answer/6276924)

More videos

## More videos

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

[Watch on](https://www.youtube.com/watch?v=h9jf1ikcGyk&embeds_referring_euri=https%3A%2F%2Frnikhil.com%2F)

0:00

0:00 / 58:07•Live

•

[Watch on YouTube](https://www.youtube.com/watch?v=h9jf1ikcGyk "Watch on YouTube")

Also, most LLMs today have browsing capabilities. Here, the adversarial instructions are introduced by a third party data source like a web search or API call. You can make the LLM go to a particular website and load your malicious instruction from here and this is especially more prevalent with ChatGPT plugins and the upcoming GPT Store.

![](https://rnikhil.com/assets/files/attackscheme.png)

- In another case of indirect injection, you can see below where they are able to extract private conversations with a GPT bot by making it visit a website. The [Embrace The Red](https://embracethered.com/blog/) has a ton of examples and tutorials demonstrating adversarial prompting methods. People have done the same thing with even [Youtube Transcripts](https://www.tomshardware.com/news/chatgpt-vulnerable-to-youtube-prompt-injection). You can find one more example [here](https://greshake.github.io/)

POC - ChatGPT Plugins: Indirect prompt injection leading to data exfiltration via images - YouTube

Embrace The Red

6.36K subscribers

[POC - ChatGPT Plugins: Indirect prompt injection leading to data exfiltration via images](https://www.youtube.com/watch?v=PIY5ZVktiGs)

Embrace The Red

Search

Watch later

Share

Copy link

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

Full screen is unavailable. [Learn More](https://support.google.com/youtube/answer/6276924)

More videos

## More videos

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

[Watch on](https://www.youtube.com/watch?v=PIY5ZVktiGs&embeds_referring_euri=https%3A%2F%2Frnikhil.com%2F)

0:00

0:00 / 1:31•Live

•

[Watch on YouTube](https://www.youtube.com/watch?v=PIY5ZVktiGs "Watch on YouTube")

- Dual LLM attack. These days most LLM chat providers uses two or more LLMs for moderation. Your input is first evaluated by an LLM which then passes on the output to the main model. Cracking this would involve sending prompt injecting the first LLM to ensure that its output **recursively** attacks the second one. There is a [paper](https://arxiv.org/abs/2302.05733) from Stanford which explains ways to overcome this.

- [Universal cheatcodes](https://llm-attacks.org/zou2023universal.pdf). This is by far the most interesting and research oriented method. The approach is to find suffix(the cheat code) that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer). However, instead of relying on manual engineering, the idea is to automatically produces these adversarial suffixes by a combination of greedy and gradient-based search techniques, and also improves over past automatic prompt generation methods. The code can be found [here](https://github.com/llm-attacks/llm-attacks)


![](https://rnikhil.com/assets/files/cheatcode.png)

- Use a second LLM to jailbreak the main LLM. The University of Pennsylvania folks came up with a system called PAIR - (Prompt Automatic Iterative Refinement). PAIR uses a separate attacker language model to generate jailbreaks on any target model. The attacker model receives a detailed system prompt, instructing it to operate as a red teaming assistant. PAIR utilizes in-context learning to iteratively refine the candidate prompt until a successful jailbreak by accumulating previous attempts and responses in the chat history. The attacker model also reflects upon the both prior prompt and target model’s response to generate an “improvement” as a form of chain-of-thought reasoning, allowing the attacker model to explain its approach, as a form of model interpretablility. You can find more details about this [here](https://jailbreaking-llms.github.io/)

In the next blog post, we will look at various defensive measures.

#### CTF games to practice prompt injection

- [Gandalf by Lakera AI](https://gandalf.lakera.ai/)
  - _Hint: The same prompt works for both Level 7 and the last level_
- [GPT Prompt attack](https://gpa.43z.one/)
  - This was the first one I attempted and I really love the gradual progression in difficulty. The author also has other similar challenges like
    - GPT Game: Write the shortest prompt to get the desired result
- [AI crowd challenge](https://www.aicrowd.com/challenges/hackaprompt-2023)
  - This was the hardest one I played and I still haven’t crack level 6 and 10 in this one. Figuring out the prompt injection vector is not enough to win the challenge but you are also scored on the number of token used in your prompt.
- [Double speak chat](https://doublespeak.chat/)
  - Didn’t enjoy playing this due to the high latency of the responses. They also have a handbook on LLM security which you should check out.
- [Automorphic Aegis challenge](https://automorphic.ai/challenge)
  - You get $50 for cracking this. It says $100 on the website but somebody has cracked it already once. Their defense is a self learning classifier model running on both ingress and egress
- [Tensortrust.ai](https://tensortrust.ai/)
  - You play both offense and defense crafting appropriate prompts

#### More resources and reading

- [OWASP Top 10 LLM apps](https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-2023-v1_1.pdf)
- [Latent space article on Reverse prompt engineering](https://www.latent.space/p/reverse-prompt-eng)
- [Preamble walkthough of a command injections](https://www.preamble.com/prompt-injection-a-critical-vulnerability-in-the-gpt-3-transformer-and-how-we-can-begin-to-solve-it?ref=hn)
- [Exploring Prompt Injection Attacks by NCC Group](https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/)
- [Kai Greshake paper on Prompt injection](https://arxiv.org/abs/2302.12173)
- [Awesome LLM security Github repo](https://github.com/corca-ai/awesome-llm-security)
- [The threat prompt newsletter](https://newsletter.threatprompt.com/)
- [Simon Willison Blog has a lot of details on prompt injection](https://simonwillison.net/)
- [Adversial attacks on LLMs by Lilian](https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/)
- [LLMsecurity.net](https://llmsecurity.net/)
- [Joseph Thacker Blog on AI hacking](https://josephthacker.com/category/ai.html)

December 22, 2023 · [ai](https://rnikhil.com/tag/ai), [llm](https://rnikhil.com/tag/llm), [security](https://rnikhil.com/tag/security), [prompt](https://rnikhil.com/tag/prompt)

## Poker Strategy Insights
## Counterfactual Regret Minimization or How I won any money in Poker?

[HN Discussion](https://news.ycombinator.com/item?id=38823240)

As most readers of my blog would know by now, I used to play Poker for a couple years as a full time endeavour. One of the main tools we used for learning the game were called “solvers”. This blog post is about these programs and how they work? An introductory understanding of Poker terminologies, betting sequences and basic conditional probability is required for this post.

![](https://rnikhil.com/assets/files/gametree.png)

#### Background

A lot of games have been used in the AI domain like chess, checkers, Go and Poker. Games like Poker are special because of the key element of imperfect information. Unlike Chess and Go where you have the entire board in front of you, in Poker you don’t know your opponent hole cards. Its harder to come up with an optimal strategy of play when you don’t have the entire information and its more interesting because its similar to a lot of real world decision making settings. We will not get into the details of Poker but rather try to understand how this game is “solved”, the methodologies used and real world implications.

University of Alberta has a [Poker research group](https://poker.cs.ualberta.ca/) and they have been working on solving the game before anybody else as far as I know. They were one of the earliest folks to build a Poker bot(called [Loki](https://poker.cs.ualberta.ca/publications/papp.msc.pdf)) which could fold/call/raise based on effective hand strength. However, the earliest research in the field I could trace back was to this seminal paper by John Von Neumann called “ [Theory of Games and Economic Behavior](https://en.wikipedia.org/wiki/Theory_of_Games_and_Economic_Behavior#)” where they discuss the concept of expected utility linking it to rational decision making.

#### Game theory in Poker

What does it mean to “solve” a poker game? When you find a [Nash Equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium) strategy (aka GTO strategy) for the game it means that the game is “solved”. By definition, if both players are playing this strategy, then neither would want to change to a different strategy since neither could do better with any other strategy (assuming that the opponent’s strategy stays fixed). However, GTO strategy is not always the best way to play the game. While GTO ensures that you are un-exploitable, this doesn’t mean you will be winning the maximum money. The best response strategy is the one that maximally exploits the opponent by always performing the highest [expected value](https://upswingpoker.com/expected-value-ev-poker/) play against their fixed strategy. In general, an exploitative strategy is one that exploits an opponent’s non-equilibrium play.

However, solvers have no idea what “Nash equilibrium” even means. So, how do they figure out the GTO play? At its core, solvers are simply EV-maximizing algorithms. Each agent in a solver represents a single player. That player a single goal of maximizing the money earned playing. The problem is the other agents play perfectly. When you force these agents to play against each other’s strategies, they iterate back and forth, exploiting each other’s strategies until they reach a point where neither can improve. This point is equilibrium which happens to be the Nash equilibrium we discussed above. GTO is achieved by making exploitative algorithms fight each other until neither can improve further.

Before we proceed further, we need to define, what is regret in Poker?

#### Regret

When you think of Regret in Poker, what is the first thing that comes to mind? Its usually us regretting calls or folds or bluffs which we did that didn’t work out (being results oriented here to explain the concept). On a very high level regret is defined as:

> Regret = (EV of your action) - (EV of the strategy)

Regret is a measure of how well you could have done compared to some alternative. Phrased differently, what you would have done in some situation instead. **Counterfactual regret** is how much we regret not playing some strategy. For example, if we fold and find out that calling was a way better strategy, then we “regret” not calling. Mathematically it measures the gain or loss of taking some action compared to our overall strategy with that hand at that decision point.

```
Minimizing regret is the basis of all GTO algorithms.

```

The most well-known algorithm is called CFR – counterfactual regret minimization. In fact, my entire process of studying Poker is one big algorithm. I used to play 10k hands, take it to my coach, get it reviewed against “correct” strategy and try to play more optimal next time. My whole studying process was to minimize regret in a way.

A common way to analyze regret is the [multi-armed bandit](https://en.wikipedia.org/wiki/Multi-armed_bandit) problem. The multi-armed bandit problem is a classic reinforcement learning problem that exemplifies the exploration–exploitation tradeoff dilemma. The setup is simple. You are a gambler sitting in front of a row of slot machines. Each machine can give out a positive or negative reward. How do you decide which machines to play, how many times to play each machine and in which order to play them? Bandits are a set of problems with repeated decisions and a fixed number of actions possible. This is related to reinforcement learning because the agent player updates its strategy based on what it learns from the feedback from the environment.

This reinforcement learning problem is related to Poker when played in the partial information setting. In the full information setting, the player can see the entire reward vector for each machine chosen and in the partial setting, sees only the reward that the machine has chosen for that particular play. There are multiple basic algorithms to attack this and a basic one is the greedy algo where you sample each machine once and then keep playing the machine with highest reward in sampling stage. There are other version of the greedy algo where you sometimes randomly explore another machine. The idea of usually picking the best arm and sometimes switching to a random one is the concept of exploration vs. exploitation. Think of this in the context of picking a travel destination or picking a restaurant. You are likely to get a very high “reward” by continuing to go to a favorite vacation spot or restaurant, but it’s also useful to explore other options that you could end up preferring.

Before we proceed further, we need to understand the concept called “Game Tree”.

#### What is a game tree?

In the concept of sequential games, a game tree is nothing but a pictorial representation of every possible game state. This can be used to measure the complexity of a game, as it represents how dense and massive a game can play out over the long run. Below is an image of a game tree for ONLY the first two actions of the Tic tac toe game. The first player has three choices of move: in the center, at the edge, or in the corner. The second player has two choices for the reply if the first player played in the center, otherwise five choices. And so on. The number of leaf nodes in the complete game tree is the number of possible different ways the game can be played.

![](https://rnikhil.com/assets/files/tictac.png)

For example, the game tree for tic-tac-toe has 255,168 leaf nodes. In comparison, a super simplified, 2 player, limit hold-em has 1,179,000,604,565,715,751 nodes. Now, remember in a real world poker setting there are 6-9 players playing, with each having infinite number of bet sizes(limit hold-em example has just 2 bet sizes). This means the actual game tree of Poker is infinitely massive and we need smart algorithms to distill a GTO strategy from it because we can’t go the final leaf node of every strategy (computationally impossible). There are more leaf nodes than the number of atoms in the universe. As you will read later, the secret sauce of [Pluribus](https://www.nytimes.com/2019/07/11/science/poker-robot-ai-artificial-intelligence.html) comes from one such algorithm/approach. Two popular algorithms Minimax and Monte carlo tree search(MCTS) are some approaches that people take to find the optimal move through simulation. MCTS allows us to determine the best optimal move from a game state without having to expand the entire tree like we had to do in the minimax algorithm.

Apart from the Poker game tree being infinitely large, we have another problem. Poker is an imperfect information game but games like chess/tic tac toe are perfect information games. With perfect information, each player knows exactly what node/state he is in in the game tree. With imperfect information, there is uncertainty about the state of the game because the other player’s cards are unknown.

#### How to solve the game?

We have already defined what a “correct” strategy looks like and the game tree. At its core, we need to find the parts of the game tree which when played out gives us the maximum utility. I don’t want to make the post technical by talking about equities, probabilities and EV of every node but rather will keep things abstract for easier consumption.

- **Step 1:** Assign each player/agent an uniform random strategy(each action at each decision point is equally likely)
  - This is the step where you define the game space. Things like the betting tree(you don’t solve ALL of poker in one go but rather in parts), required accuracy, starting pot values, stack sizes, board cards, starting ranges, any bucketing, rake, ICM are setup before the simulation starts. Remember, complexity grows our betting tree exponentially. If you want to solve 4-5x as many betting sizes, the tree would grow by 125x and becomes harder to solve. Funnily, this is still a major simplification of the true game space.
  - One of the most difficult problems with solvers is optimizing betting trees to produce solid strategies within the constraints of current technology. We can only make a tree so big before it becomes unsolvable due to its size. We can only make a tree so small before the solver starts exploiting the limitations of that tree.

![](https://rnikhil.com/assets/files/treesetup.png)

- **Step 2:** Compute the regret(EV loss against opponent move) for each action throughout the game tree
  - While we have defined regret earlier, we need to exactly define what is the solver calculating here. In the previous step, we have defined the game space(and the leaf nodes we are interested in calculating) and here we calculate EV of each node. Its nothing but probability\*value of the action.

![](https://rnikhil.com/assets/files/step2.png)

- **Step 3:** Slightly change one player strategy (keeping opponent moves fixed) to reduce the regret calculated in previous step
  - Once we have calculated the regret of our actions, how we figure out a new strategy. New Strategy = (Action Regret)/(Sum of positive regrets).
- **Step 4:** Repeat Steps 2 and 3 until you attain Nash equilibrium.
  - I have already defined what Nash equilibrium is in Poker. But how do we know this is the most optimal part of the game tree? We certainly didn’t go through the entire game tree and instead took an iterative approach. What if we are stuck in a local maximum? What if going 100x pot size allin is the best strategy and we never iterated over it? Its impossible to know before hand what game space to iterate on. Poker, in general, can be described as a “bilinear saddle point problem”. The payoff space looks something like this:

![](https://rnikhil.com/assets/files/payoffpoker.png)

- Each point on the x-axis and y-axis represents a strategy pair. Each strategy pair contains information about how both players play their entire range in every spot across every runout.
- The height (z-axis) represents the expected value of the strategy pair, with higher points representing an EV advantage for one player, and lower points representing a disadvantage

That’s it!. Almost all GTO solvers do the above 4 steps. They are aided with complex algorithms to simplify game trees, calculate regret faster, identifying which part of game tree is relevant. To ensure we aren’t stuck in a local maxima of the game tree, most solvers use a process called [Counterfactual Regret Minimization (CFR)](https://poker.cs.ualberta.ca/publications/NIPS07-cfr.pdf). This algorithm was first published in a 2007 paper from the University of Alberta and it proves that the CFR algorithm will not get stuck at some local maximum, and given enough time, will reach equilibrium.

#### What is [Counterfactual Regret Minimization (CFR)](http://modelai.gettysburg.edu/2013/cfr/index.html)?

Counterfactual means “relating to or expressing what has not happened or is not the case”. For example, if in reality I drank 4 red bulls and couldn’t sleep in the night, I could say counterfactually, “If I hadn’t drank red bulls, I would have slept well in the night”. Regret we previously touched on is a way to assign a value to the difference between a made decision and an optimal decision. Minimization refers to minimizing the difference between the made decision and the optimal decision.

In the paper, they basically introduce the notion of counterfactual regret, which exploits the degree of incomplete information in an extensive game. They show how minimizing counterfactual regret minimizes overall regret, and therefore in self-play can be used to compute a Nash equilibrium. CFR is a self play algorithm that learns by playing against itself repeatedly. It starts play with a uniform random strategy (each action at each decision point is equally likely) and iterates on these strategies to nudge closer to the game theory optimal Nash equilibrium strategy as the self play continues (the average of all strategies converges to the equilibrium strategy)

![](https://rnikhil.com/assets/files/cfr.png)

The concept of counterfactual value calculation involves determining the values of actions within a game state by hypothesizing that we reach that state with a certainty of 100%. In this process, only the probabilities associated with the opponent’s and chance’s moves leading to that state are considered.

Counterfactual values are derived by multiplying the likelihood of the opponent and chance arriving at a particular state, the odds of progressing from that state to the game’s conclusion, and the final value at the game tree’s end. Within each information set of the game tree, the algorithm maintains a tally of regret values for each potential action. Regret here refers to the extent to which the agent would have performed better had it consistently chosen a particular action, instead of an average strategy comprising a blend of all actions. A positive regret suggests that an action should have been chosen more often, while a negative regret indicates that avoiding the action would have been preferable.

Minimizing regret involves favoring actions that perform better, thereby elevating the average value for the game state. The algorithm adjusts its strategy after each round to favor actions proportional to their past regrets. This means that an action with previous success is more likely to be chosen in the future. Proportional play prevents drastic strategy shifts, which could be predictable and exploitable. It also allows under performing strategies to potentially bounce back and be selected again.

> The ultimate Nash equilibrium strategy, derived as an average of strategies across iterations, is deemed optimal. This strategy is expected not to incur losses and is theoretically sound, with neither player having a motive to deviate if both adopt an equilibrium strategy. This forms the basis of what is meant by “solving” a game like poker.

Reinforcement learning involves agents learning actions in an environment by considering past rewards, akin to the regret updates in Counterfactual Regret Minimization (CFR). Regrets in CFR resemble advantage functions, which compare the value of an action to a state’s value, as highlighted in recent studies like the Deep CFR paper. This concept parallels the idea of managing independent multiarm bandits at each decision point, learning from all simultaneously.

If CFR was invented long time back what was the breakthrough in 2019 which led to the building of Pluribus and the $1M prize game? They did Libratus first which was a 2 player version but a year later followed up with Pluribus which was a 6 player AI(exponentially harder to solve). The big breakthrough was the depth-limited search algorithm. This allowed them to shift a lot of the load from the blueprint computation to the online search algorithm, and the online search algorithm is relatively much more efficient. There were also advances in the blueprint computation itself, such as the use of linear CFR, but advances in the search algorithm were the biggest factor.

#### Where else is CFR useful?

Assuming Poker bots take over the online scene, where else can poker players and people building poker solvers get a job 🤣 ?

- Economic Modelling: CFR can be applied to model and analyze strategic interactions in markets, such as auctions and bargaining scenarios, where participants must make decisions with incomplete information about others’ strategies.
- Trading. Imagine a model which can show you ALL possible outcomes of the Russia-Ukraine conflicts impact on Oil prices and trade the highest EV stuff using that
- Decision support and negotiation: Running automated auctions(whats up crypto folks!), complex business strategy or even military planning
- Route optimization. Lot of the traffic routing algos use CFR and you can also model transportation logistics using this

Sources and Further reading:

- [Libratus science.org](https://www.science.org/doi/10.1126/science.aao1733)
- [Pluribus(elder brother of Libratus) wiki](https://en.wikipedia.org/wiki/Pluribus_(poker_bot))
- [Pio Solver](https://piosolver.com/) and [Monker solver](https://monkerware.com/solver.html)
- [Reddit AMA from Noam Brown who is the father of this field](https://www.reddit.com/r/MachineLearning/comments/ceece3/ama_we_are_noam_brown_and_tuomas_sandholm/?utm_source=reddit&utm_medium=usertext&utm_name=MachineLearning&utm_content=t5_2r3gv)
- [Solving Imperfect-Information Games via Discounted Regret Minimization](https://arxiv.org/pdf/1809.04040.pdf)
- [Using Neural networks to speed up CFR](https://proceedings.mlr.press/v97/brown19b.html)
- [Maths of Poker](https://aipokertutorial.com/what-is-solving/)
- [CFR in Poker. First paper on this](https://poker.cs.ualberta.ca/publications/AAMAS10.pdf)
- [Deepstack by the Google folks](https://www.deepstack.ai/)
- [How PhD people define all-in adjusted](https://poker.cs.ualberta.ca/publications/aaai18-burch-aivat.pdf)

December 31, 2023 · [ai](https://rnikhil.com/tag/ai), [cfr](https://rnikhil.com/tag/cfr), [poker](https://rnikhil.com/tag/poker), [solver](https://rnikhil.com/tag/solver)

## AI Alignment Insights
## AI Alignment - Weak-to-strong generalization (W2SG) explained

AI alignment is a broad topic of research to basically ponder over the question “How can AI systems be steered to accomplish the human intended goals and preferences?”. Simply put, how do we make sure that the AGI will listen to us? Currently, we use methods like [RLHF](https://wandb.ai/ayush-thakur/RLHF/reports/Understanding-Reinforcement-Learning-from-Human-Feedback-RLHF-Part-1--VmlldzoyODk5MTIx) to steer our large language models. However, future AI systems will be capable of extremely complex and creative behaviors that will make it hard for humans to reliably supervise them. They will be generating millions of lines of code or generating novels with thousands of words. Can we supervise a superhuman AI using only human supervisors We are currently uncertain about this and don’t exactly know if the current methods will scale to super human model. So, OpenAI decided to study an interesting analogy where they try to supervise(align) a larger model GPT-4 using a smaller model GPT-2. The GPT-2 is analogous to a human(a weak supervisor) and they experiment with a bunch of setups to see if it can reliably steer GPT-4. A direct fine tune is still the best approach possible(today for GPT-4 type model) but we will need to invent/explore new methodologies to steer potential AGI and this blog post is about that paper.

Before going further, lets first understand the setups used:

#### Weak supervisor

This is nothing but a base GPT-2 model fine tuned on certain ground truth labels like the Ethics datasets, Hellswag etc to create a fine tuned version of it. This fine tuned version(the weak supervisor) is then used to predict on a held-out set of examples on the ground truth dataset. This weak supervisor will then predict the labels and they are called “weak labels”.

![](https://rnikhil.com/assets/files/weaksup.png)

![](https://rnikhil.com/assets/files/weaklabel.png)

Now, we train a strong model (base GPT-4 which is not fine tuned) with these weak labels generated by our weak supervisor to create a final strong student model(fine tuned GPT-4).

![](https://rnikhil.com/assets/files/weaktostrong.png)

#### Strong Ceiling - The baseline for comparison

The above process is described further in the [code](https://github.com/openai/weak-to-strong/blob/main/train_weak_to_strong.py) they open sourced. They essentially do the following:

- Train a weak model on the first half of the dataset
- Train the strong model on the second of the training dataset with labels generated by the weak model
- **Baseline: Strong Ceiling** Train a strong model on the second half of the dataset

![](https://rnikhil.com/assets/files/strongceiling.png)

#### The new method - Auxillary confidence loss

The new method proposed in the paper is basically a way to encourage the strong model(created in the weak supervisor step) to be more confident - including confidently disagreeing with the weak supervisor if necessary. When they supervise GPT-4 with a GPT-2 level model using this method on NLP tasks, they find that the resultant model performs somewhere between GPT-3 and GPT-3.5. They were also able to recover much of the GPT-4 capabilities with much weaker supervision. They do this by having some auxillary confidence loss which forces the model to be more confident. Check section A.4 of the paper for a detailed description of the method used. I have left out the exact description due to its slightly more mathematical nature.

#### Can small models supervise larger models?

The answer is a mixed yes and a no. They were able to eke out GPT-3/3.5 level performance on NLP tasks as we see in the below graph but not so much on other tasks.

NLP benchmark using 4 different models (weak supervisor, naive fine tuning, their new method and strong ceiling) and performance is measured by looking at how different models perform on the same NLP task.

![](https://rnikhil.com/assets/files/w2sg.png)

![](https://rnikhil.com/assets/files/allperf.png)

#### Bootstrapping for chess puzzles

In the paper, they use the above methods and do the comparison on three different tasks. First is the NLP benchmarks which we discussed above, second is chess puzzles and finally ChatGPT Reward modeling. This section details the bootstrapping used for chess puzzles.

In the pre-training dataset they already had chess games but in the fine tuning dataset they now had chess puzzles. You basically are fed the board state as a text prompt and the model has to predict the best next move as a text label. Their experiment setup didn’t allow feeding images of the chess board.

However, they found out that naive fine tuning doesn’t really work well for chess puzzles and the gap between student and supervisor is too large. Thats why they introduce “Bootstrapping” to solve this problem. Bootstrapping is a long-standing idea in alignment where instead of directly aligning very superhuman models, you could first align an only slightly superhuman model, use that to align an even smarter model, and so on until you align the model you want for your experiment. They construct a sequence of model sizes M1 → M2 → . . . → Mn of increasing sizes. Then, they use the weak labels from M1 to fine tune M2, use M2 to generate new weak labels that you can use to fine tune the next model in the sequence, M3, and so on.

![](https://rnikhil.com/assets/files/bootstrap.png)

#### ChatGPT Reward Modeling

The standard approach to aligning models today is [reinforcement learning from human feedback (RLHF)](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback). A critical step of RLHF is to train a reward model (RM) to predict human preferences between model responses. Specifically, a reward model is trained on a dataset consisting of dialogs between a human and an assistant model. For each query, the humans compare multiple possible responses (completions) from the assistant, providing human preference data. Then, a reward model is trained to predict the results of pairwise comparisons between completions. Finally, the assistant model(the chatbot like ChatGPT) is trained by optimizing against the reward model with reinforcement learning (RL).

As we saw in the previous section, our strong ceiling model still outperforms our confidence boosted strong student model. How did they attempt to bridge this gap? To solve this they used **unsupervised generative fine tuning for the reward modeling.** Its just a way to increase the salience of a task without using ground truth labels. In this case they perform unsupervised fine tuning with data relevant to the task. They take the ChatGPT comparison data and they ignore the human preferences. What you are left with is just the prefix-completion pairs.

However, this poses an interesting question. Isn’t it cheating to use the ChatGPT comparison data instead of using a new supervision dataset? However, since they compare performance to the strong ceiling model which was also generatively fine tuned using the same dataset(ChatGPT comparison) its fine to do this. GPT-4 was first fine tuned with ChatGPT comparison data without human preferences and then was fine tuned with the dataset of human preferences. So, even comparing to this strong ceiling they were to able to recover the performance gap by about 10-20%.

#### Conclusion

As we see above, they used three techniques to achieve some sort of weak-to-strong generalization.

- Auxillary confidence loss
- Bootstrapping for chess puzzles
- Unsupervised generative fine tuning for reward modeling

However, none of the methods work for every situation. Collectively, their results suggest that naive human supervision—such as reinforcement learning from human feedback (RLHF)—could scale poorly to superhuman models without further work, but it is feasible to substantially improve weak-to-strong generalization. And they call out two problems which may arise if and when humans try to align super human models which they mention as “disanalogies”. They are:

- **Imitation Saliency:** Superhuman models may easily imitate weak errors from human supervisors but might have harder time imitating weak errors from AI supervisors. This is mainly because human errors are basically all over the pre-training data of current LLMs. More generally, the types of errors weak models make today may be different from the types of errors humans will make when attempting to supervise superhuman models. This makes generalization of the above methods much harder.

![](https://rnikhil.com/assets/files/leogao.png)

- **Pre-training leakage:** Superhuman knowledge may be latent and not observable. In the paper, they elicit knowledge from the strong model using certain tasks like SciQ NLP. However, its possible that these tasks are already part of the pre-training data but just framed differently. This will overall make weak-to-strong generalization easier for strong models and make results look better than they are. However, in the future we might have models which are entirely built through self-supervised learning or reinforcement learning (rather than through imitation learning) but we don’t such an AI just yet.

If you liked my post, let me know on [Twitter](https://twitter.com/rnikhilcom). Other posts on AI:

- [Counterfactual Regret Minimization](https://rnikhil.com/2023/12/31/ai-cfr-solver-poker.html)
- [LLM scaling laws explained](https://rnikhil.com/2023/11/28/llm-scaling.html)
- [Intro to LLM security](https://rnikhil.com/2023/12/18/ai-llm-security-part1.html)

Further reading and sources:

- [Combining W2SG with other alignment techniques](https://aligned.substack.com/p/combining-w2sg-with-scalable-oversight)
- [W2SG paper](https://cdn.openai.com/papers/weak-to-strong-generalization.pdf) and the [Github repo](https://github.com/openai/weak-to-strong)
- [AI Alignment Forum](https://www.alignmentforum.org/) and the relevant [post](https://www.alignmentforum.org/posts/hw2tGSsvLLyjFoLFS/scalable-oversight-and-weak-to-strong-generalization) detailing other approaches to solve the same problem
- [Lesswrong discussion on the paper](https://www.lesswrong.com/posts/9W8roCAeEccSa3Chz/weak-to-strong-generalization-eliciting-strong-capabilities)

January 4, 2024 · [ai](https://rnikhil.com/tag/ai), [alignment](https://rnikhil.com/tag/alignment), [llm](https://rnikhil.com/tag/llm), [openai](https://rnikhil.com/tag/openai)

## Neural Network Attacks
## Attacks on machine learning models

[HN discussion](https://news.ycombinator.com/item?id=38904963)

With all the hype surrounding machine learning whether its with self driving cars or LLMs, there is a big elephant in the room which not a lot of people are talking about. Its not the danger of ChatGPT taking your jobs or deepfakes or the singularity. Its instead about how neural networks can be attacked. This blog post is my attempt to throw some light on the topic. By the end of the post, you would have understood that neural network attacks are not just limited to adversarial examples and that they are just as susceptible to attacks like other systems. If you are deploying machine learning systems in production, I think its worth paying attention to this topic.

#### Adversarial attacks

The first thing that pops into your mind when you think of attacking neural networks is adversarial examples. On a high level, it involves adding a tiny bit of calculated noise to your input which causes your neural network to misbehave. Adversarial attacks are inputs that trigger the model to output something undesired. Much early literature focused on classification tasks, while recent effort have started to investigate the outputs of generative models. Prompt injection for example specifically targets language models by carefully crafting inputs (prompts) that include hidden commands or subtle suggestions. These can mislead the model into generating responses that are out of context, biased, or otherwise different from what a straightforward interpretation of the prompt would suggest. I have catalogued a bunch of LLM related attacks previously in my blog [here](https://rnikhil.com/2023/12/18/ai-llm-security-part1.html) and [here](https://rnikhil.com/2023/12/22/ai-llm-security-part2.html) . For a more mathematical interpretation of the LLM attacks, I would suggest you to read this blog post [here](https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm) by the head of safety at OpenAI.

Attacks on image classifiers have been historically way more popular given their widespread applications. One of the popular attack as described in this [paper](https://arxiv.org/pdf/1412.6572.pdf) is the Fast Gradient Sign Method(FGSM). Gradient based attacks are white-box attacks(you need the model weights, architecture, etc) which rely on gradient signals to work. Gradients are how you determine which direction to nudge your weights to reduce the loss value. However, instead of calculating gradient w.r.t weights, you calculate it w.r.t pixels of the image and use it to _maximize_ the loss value. [Here](https://neptune.ai/blog/adversarial-attacks-on-neural-networks-exploring-the-fast-gradient-sign-method) is a tutorial with code showing you how to implement this attack.

![](https://rnikhil.com/assets/files/pandagibbon.png)

![](https://rnikhil.com/assets/files/bananapatch.png)

FGSM is by no means the only type of attacks on image classifiers. For a bigger list you can check this [page](https://viso.ai/deep-learning/adversarial-machine-learning/). Neural networks and humans process images in very different ways. While humans too have adversarial examples(like optical illusions), neural networks analyze the image from raw pixels bottom-up. They start with simple edges, bright spots, etc to then complex stuff like shapes and faces. Each layer of the neural net processes them in a sequential manner. For example, adding a couple bright spots near a human cheek might set of the “whisker” neuron in an earlier step which would then cascade through the network and make it misclassify the human as a dog. The earliest mention of this attack is from this [paper](https://arxiv.org/pdf/1312.6199.pdf)(first author is co-founder of [xAI](https://x.ai/)) back in 2013 and attacks have gotten super good since then. Nowadays, just adding [one single pixel](https://arxiv.org/pdf/1710.08864.pdf) to an image could throw of the neural network. This attack vector is further exacerbated by multi-modal neural networks where putting a [small piece of text](https://arxiv.org/pdf/2103.10480.pdf) on an image could lead to its misclassification.

Moreover, images are not the only thing where neural net classifiers are used. For example, anti virus software regularly use neural nets to classify PE files(portable executables). [Here](https://securelist.com/how-to-confuse-antimalware-neural-networks-adversarial-attacks-and-protection/102949/) is a white-box attack tutorial showing how you can trick such a neural net into believing that your file is harmless. In the speech to text domain, adding a little bit of noise to the voice sample throws off the entire transcription completely. [Nicholas Carlini](https://nicholas.carlini.com/) (who I had mentioned in a different post earlier for his data poisoning attacks on LLMs) wrote a [paper](https://arxiv.org/pdf/1801.01944.pdf) on this which you should check out. For NLP models which work at a character level, here is another one where changing a [single character](https://aclanthology.org/P18-2006.pdf) leads to misclassification of the text.

![](https://rnikhil.com/assets/files/voicefool.png)

As you can see adversarial examples are basically a cat and mouse game where the attacker keeps getting better and defenses have to keep improving.

#### Data Poisoning and backdoor attacks

Given that machine learning models rely on training data, if you attack the training data itself you can degrade the performance of the model. I have touched upon it briefly earlier in the context of LLMs which you can read [here](https://rnikhil.com/2023/12/22/ai-llm-security-part2.html).

![](https://rnikhil.com/assets/files/backdoor.png)

[Backdoor](https://www.malwarebytes.com/backdoor) from the POV of traditional security is nothing but sort of implementing a code vulnerability which can later be used to get access to the system. With ML systems, its not just the code that is vulnerable but the data as well. Backdoor attacks are a special kind of data poisoning attack where you provide data which will make the model behave in a certain way when it sees a certain (hidden) feature. The hard thing about backdoor attacks is that the ML model will work perfectly fine in all other scenarios until it sees the backdoor pixel/feature. For example, in face recognition systems, the training data could be primed in a way to detect a certain pattern which can then be used (worn on a cap for example) to misclassify a burglar as an security guard or employee. I have linked some papers on this topic in the further reading section.

#### Membership Inference attacks

Instead of tricking the model to misbehave, this are sort of attacks which compromises the privacy of a machine learning model. The attacker here basically wants to know whether a given data point was included in the training data and its associated labels. For example, lets assume you are in a dataset which is used to train a model which predicts whether you have have a certain disease. If a health insurance company gets access to such a model and does a membership inference attack on it, they can basically find out whether you have the disease or not.

So how does this work? **This entire attack is based on the simple fact that machine learning models perform better on examples they have seen compared to unknown or random examples.** At its core, you train another machine learning model which takes two inputs, a model and a data point. It then returns a classification on whether that data point was in the input model or not.

![](https://rnikhil.com/assets/files/shadowmodel.png)

To perform membership inference against a target model, you make adversarial use of machine learning and train your own inference model to recognize differences in the target model’s predictions on the inputs that it trained on versus the inputs that it did not train on.

In this [paper](https://www.researchgate.net/publication/317002535_Membership_Inference_Attacks_Against_Machine_Learning_Models) they empirically evaluate the inference techniques on classification models trained by commercial “machine learning as a service” providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, they show that these models can be vulnerable to membership inference attacks.

![](https://rnikhil.com/assets/files/attackmodel.png)

This attack basically uses machine learning models to attack another machine learning model. LLMs are also susceptible to this and I’ve linked some relevant papers in the further reading section.

#### Model Extraction attack

This is an attack on the model itself where the attacker is trying to steal the machine learning model from the owner. This can be pretty lucrative especially these days where the technical moat of certain $100B companies entirely depend on them having the best machine learning model.

This [paper](https://arxiv.org/pdf/1910.12366.pdf) studies the attack in which an adversary with only query access to a victim model attempts to reconstruct a local copy. Assuming that both the adversary and victim model fine-tune a large pretrained language model such as BERT they show that the adversary does not need any real training data to successfully mount the attack.

![](https://rnikhil.com/assets/files/modelextract.png)

In fact, the attacker need not even use grammatical or semantically meaningful queries: they show that random sequences of words coupled with task-specific heuristics form effective queries for model extraction on a diverse set of NLP tasks, including natural language inference and question answering.

#### Fairwashing

This kind of attack doesn’t attack the model itself but targets the explanation methods.It refers to an attack where explanations are used to create the illusion of fairness in machine learning models, even when the models may still be biased or unfair. This term is a play on “whitewashing,” implying that something undesirable (in this case, unfairness or bias) is being covered up. This is an attack on the domain of model interoperability where the entire focus of the field is to figure out explanations of model behavior. The attack tries to fool the statistical notion of fairness(like [LIME](https://arxiv.org/pdf/1602.04938.pdf) and [SHAP](https://papers.nips.cc/paper_files/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf)) but unfortunately the concepts were a bit too mathematical for for me to explain it here. In this [paper](https://arxiv.org/pdf/1911.02508.pdf), they propose a scaffolding technique that effectively hides the biases of any given classifier by allowing an adversarial entity to craft an arbitrary desired explanation. Apparently their approach can be used scaffold any biased classifier in a manner that its predictions on the inputs remain biased but post hoc explanations come across as fair.

#### Other attacks on ML models

- You can DoS a ML system by giving it certain sponge examples as part of your input. In this [paper](https://arxiv.org/abs/2006.03463) they find that you can increase the energy consumption(and thereby latency in responses) by 10x-200x by just crafting certain malicious sponge inputs which exploit certain GPU optimization techniques. This attack is particularly scary in the context of self driving cars. Imagine a sign board with such an example which causes a delay in response leading to life threating accidents.

- You can degrade a model performance by just changing the order in which you present the training data. In this [paper](https://arxiv.org/abs/2104.09667) they find that an attacker can either prevent the model from learning, or poison it to learn behaviors specified by the attacker. Apparently even a single adversarially-ordered training run can be enough to slow down model learning, or even to reset all of the learning progress.


#### Conclusion

- While ML systems are just like any other systems and are exploitable, they are extra hard to protect given there are both code vulnerabilities as well as data vulnerabilities.
- Current defenses against adversarial examples are whack-a-mole and real fixes might need massive changes to model development itself rather than pattern matching for attacks. As long as we are pattern matching, these attacks can never be truly prevented. [You can’t solve AI security problems with more AI](https://simonwillison.net/2022/Sep/17/prompt-injection-more-ai/)
- High stake decisions and mission critical instances should involve human in the loop along with predictions from machine learning models

Further reading:

- [LLM security content/research/papers/news](https://llmsecurity.net/)
- [Survey on practical adversarial examples for malware classifiers](https://arxiv.org/pdf/2011.05973.pdf)
- [Blind backdoors in Deep Learning Models](https://arxiv.org/pdf/2005.03823.pdf)
- [Hidden trigger backdoor attacks](https://arxiv.org/pdf/1910.00033.pdf)
- [Security and Privacy Issues in Deep Learning](https://arxiv.org/pdf/1807.11655.pdf)
- [Privacy in federated learning(survey paper)](https://arxiv.org/pdf/2011.05411.pdf)
- [Membership inference in masked language models](https://arxiv.org/pdf/2203.03929.pdf)
- [Extracting Training Data from Large Language Models](https://arxiv.org/pdf/2012.07805.pdf)
- [Fairwashing: the risk of rationalization](https://arxiv.org/pdf/1901.09749.pdf)

January 7, 2024 · [ai](https://rnikhil.com/tag/ai), [llm](https://rnikhil.com/tag/llm), [security](https://rnikhil.com/tag/security), [prompt](https://rnikhil.com/tag/prompt), [adversarial](https://rnikhil.com/tag/adversarial)

## Reasons for Writing
## Why do I write?

Over the last week, 4-5 folks have asked me why I write or why do I maintain this blog? This post attempts to answer the question and ensures I don’t have to repeat myself again.

- It’s very important to write well than most people realize. Writing doesn’t just communicate ideas; it generates them. If you’re bad at writing and don’t like to do it, you’ll miss out on most of the ideas writing would have generated. [\[1\]](https://www.paulgraham.com/writing44.html) I publish it online because an audience makes you write more and therefore generate more ideas.

  - The best post on this site according to me is [“How to bundle games?”](https://rnikhil.com/2023/04/09/multi-vs-single-gaming.html). The idea behind that post was brewing in my head for a couple months but it took serious sitting down at a keyboard to put them into words. Even after pondering over it for a while, 80% of the ideas in that post happened after I started writing it.
  - While talking about your ideas is a good way to develop them, you will almost always discover new things when you sit down to write. Putting ideas into words is a severe test [\[2\]](https://www.paulgraham.com/words.html)
- A lot of my posts are just personal notes slightly face lifted with some diagrams for publication. It doesn’t cost me a lot of time and maintaining this blog is a way to ensure I don’t lose them when I inevitably switch computers or note taking apps. I really regret not writing as much back in 2015-2020 and I genuinely wish I wrote more when I was learning about computer security.

- Sometimes, I write about my experiences which are unique and could be certainly useful to people who are in a similar situation in their life. My most popular blog post [“Downsides of a professional poker career”](https://rnikhil.com/2023/11/12/quitting-fulltime-poker.html) which got about 180k views was written entirely on a whim while waiting for my flight on a late Sunday night. I got a bunch of inbound saying that the post was insightful.
  - Useful writing tells people something true and important that they didn’t already know, and tells them as unequivocally as possible. Any insight I may have will probably have already been had by at least one of the world’s 7.5 billion people. But it’s sufficient if an idea is novel to a lot of readers.
- Sometimes, I write because I want to voice my opinion on a particular topic. My post on [online privacy and tornado cash](https://rnikhil.com/2022/08/09/tornado-cash-block.html) sparked a ton of new discussion on a lot of forums. I unquestionably care about those topics and this blog is a way for me to speak up and add my two cents.

- You do a lot of research when you write a post. Writing in a way forces structure into my research and I learn a lot more about a topic when I write about it than just reading couple articles and papers. For example, I have been teaching myself LLM security for the last 6 months. However, when I decided to start writing about them, it forced me to do a ton of new research and I learnt a lot of new stuff along the way.

- And finally, here is one of my [comment](https://news.ycombinator.com/item?id=35936828#35967811) on HN about 7 months ago on writing. Its a thread about the British art critic [David Sylvester](https://en.wikipedia.org/wiki/David_Sylvester)

![](https://rnikhil.com/assets/files/hnquote.png)

- I also write publicly because I hate repeating myself and I can just point folks to a post - like this one.

January 7, 2024 · [opinion](https://rnikhil.com/tag/opinion), [blog](https://rnikhil.com/tag/blog)

## Testing LLMs for Data Leakage
## Testing LLMs for Data Leakage Vulnerabilities

* * *

This post was cowritten by me and was originally published on [Dynamo AI’s blog](https://dynamo.ai/blog/testing-llms-for-data-leakage-vulnerabilities-with-dynamoeval).

![](https://rnikhil.com/assets/files/dataleak1.png)

[Recent](https://arxiv.org/abs/2012.07805) [studies](https://arxiv.org/abs/2302.04460) [highlight](https://arxiv.org/abs/2311.17035) a critical issue: large language models (LLMs) can memorize and reproduce text verbatim from their training data when prompted.

This raises significant privacy risks and legal liabilities, especially if the training data contains sensitive, copyrighted, or personally identifiable information (PII). Real-world cases of commercial AI systems generating copyrighted or non-distributable data have already resulted in [legal action](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html).

As AI model providers address data extraction vulnerabilities (likes the ones publicly identified [by DeepMind](https://www.zdnet.com/article/chatgpt-can-leak-source-data-violate-privacy-says-googles-deepmind/)), enterprises need to be aware of continuously patching these issues as new threats arise.

Many enterprises are concerned about productionizing AI systems trained on a large, undisclosed datasets that might generate copyrighted or sensitive content. While the legal implications are still open for debate, enterprises often reference recent regulatory statements.

For instance, the [White House Executive Order](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/) has tasked the US Copyright Office to “issue recommendations to the President on potential executive actions relating to copyright and A Similarly, others refer to the [FTC warning](https://www.ftc.gov/system/files/ftc_gov/pdf/p241200_ftc_comment_to_copyright_office.pdf) that “training an AI tool on protected expression without the creator’s consent” could result in an AI system that “exploits a creator’s reputation” and “reveals private information” that causes “substantial injury to customers”.

Given these regulatory concerns, it’s crucial for organizations to assess whether their language models are at risk of leaking sensitive or protected data.

## Addressing emerging risks in language models

Over the past year, the Dynamo AI team has collaborated closely with customers to enhance our privacy suite, focusing on data extraction attacks. We’re excited to share how our testing has helped organizations identify and mitigate potential data leakage vulnerabilities before their AI systems go live.

**Key features and benefits:**

- **Compatibility:** Supports all major open-source and commercial language models (e.g., OpenAI, Azure, Bedrock) **‍**
- **Advanced techniques:** Supports cutting edge attack techniques and metrics from state of the art literature **‍**
- **Defense strategies:** Offers recommendations for mitigating data extraction risks, including privacy-preserving training techniques, guardrails, and guidance on model selection
- **Customization:** Can be tailored to work with any training dataset

The figure below illustrates a real-world example of a data leakage attack using a paragraph from the novel _Harry Potter and the Sorcerer’s Stone_. We input the first 22 words of the paragraph (the prefix) into the Llama 2 13B language model, and ask it to complete the paragraph. The model is able to generate 40 words that match the original text (highlighted in red), which suggests that it has seen this paragraph in its training corpus.

![](https://rnikhil.com/assets/files/dataleak2.png)

## Evaluating data extraction attacks on AI models

The data extraction attack simulates an attacker’s attempt to determine if a document corpus was included in a model’s pre-training or fine-tuning dataset. We use a suite of proprietary prompting strategies to uncover text that may have been memorized by the model.

For example, one basic test we perform involves DynamoEval prompting the AI system with the first few words from a protected paragraph in the training dataset. We then analyze whether the model’s completion matches the original text.

To identify if the generated text is “memorized,” we use a set of similarity thresholds, including trigram memorization, exact starting word memorization, and overlapping words memorization. This approach assumes the adversary has black-box access to the model, allowing them to observe the generated text in response to specific prompts.

![](https://rnikhil.com/assets/files/dataleak3.png)

## Running data extraction tests on the Dynamo AI platform

You can easily run a data extraction attack using either our SDK or the Dynamo AI dashboard. The figure below illustrates how to run a test using the SDK.

```
dfl = DynamoFL(DYNAMOFL_API_KEY, host=DYNAMOFL_HOST)

test = dfl.data_extraction_test(
    name = "Data Extraction - Llama 2 - Harry Potter",
    model_key = model.key,
    dataset_id = dataset.id,
    gpu = GPUConfig(gpu_type = GPUType.V100, gpu_count = 1),
    memorization_granularity = "paragraph",
    sampling_rate = 1000,
    grid = [\
        {\
            'prompt_length': [256, 512],\
            'temperature': [0, 0.5, 0.7, 1.0]\
        }\
    ]
)

```

- `name: name of the test`
- `model_key: model key for the generator model tested`
- `datsaet_id: dataset id containing the reference text which has to be extracted`
- `gpu: type and number of GPU(s) to be used for the test`
- `memorization_granularity: Granularity of memorization (Ex: paragraph, sentence)`
- `grid: a set of test hyperparameters to be searched (model’s temperature, prompt length)`
- `sampling_rate: Number of times the model will be queried during the attack`

## Effective mitigation measures for data leakage

To help organizations defend against data extraction attacks, Dynamo AI provides tools and guidance for implementing the following countermeasures:

1. **Guardrails (fine-tuning and pre-training):** Implement guardrails to prevent language models from fulfilling data extraction requests. These guardrails serve as a first line of defense by blocking attempts to retrieve sensitive memorized data. Our AI guardrail, DynamoGuard, is specifically designed to protect against these attacks.
2. **Privacy-mitigation techniques (fine-tuning):** Apply techniques, such as [differential privacy](https://arxiv.org/abs/2110.05679) and [deduplication,](https://arxiv.org/abs/2107.06499) during fine-tuning. Differential privacy introduces noise to the training data, making it harder to extract specific data points. Deduplication removes exact copies of sensitive data from the training set, reducing the risk of memorization. [DynamoEnhance](https://dynamo.ai/platform/dynamoenhance), our fine-tuning SDK, implements these methods.
3. **Smaller models (fine-tuning):** [Research](https://arxiv.org/pdf/2202.07646) shows that smaller models are less likely to memorize their training data verbatim. Use [DynamoEval](https://dynamo.ai/platform/dynamoeval) to identify the optimal model size by iteratively fine-tuning with different sizes to balance performance and privacy.

As LLMs become increasingly powerful and widely adopted, the risk of exposing sensitive information from training datasets also rises. To address this challenge, Dynamo AI offers a comprehensive suite of privacy solutions, including simulations for data extraction attacks, PII extraction, PII inference, and membership inference. These tools enable teams to effectively measure, address, and prevent data leakage, supporting the responsible deployment of LLMs.

We also offer a range of AI privacy and security solutions tailored to build trustworthy and responsible AI systems. For more information about how Dynamo AI can help you evaluate and improve your RAG models, or to explore our AI privacy and security offerings, please reach out to us to [schedule a demo.](https://dynamo.ai/request-a-demo)

July 31, 2024 · [ai](https://rnikhil.com/tag/ai), [llms](https://rnikhil.com/tag/llms), [eval](https://rnikhil.com/tag/eval), [data](https://rnikhil.com/tag/data), [leakage](https://rnikhil.com/tag/leakage), [memorization](https://rnikhil.com/tag/memorization)

## LLM Data Leakage Testing
## Integrating Explainable LLM Data Leakage Testing into your CI/CD Pipeline

* * *

This post was cowritten by me and was originally published on [Dynamo AI’s blog](https://dynamo.ai/blog/integrate-explainable-llm-data-leakage-testing-into-your-ci-cd-pipeline-with-dynamoeval).

![](https://rnikhil.com/assets/files/piimain.png)

Generative AI (GenAI) introduces new challenges in data privacy, including the potential risk of large language models (LLMs) memorizing and leaking personally identifiable information (PII) or copyrighted data in training datasets. Although this technology is still emerging, enterprises using or deploying GenAI still need to meet the existing laws and regulations on data privacy.

[Research in machine learning](https://arxiv.org/abs/2202.07646) has long highlighted privacy vulnerabilities associated with model training, such as data leakage in LLMs. These vulnerabilities can lead to significant compliance, financial, and reputational consequences. Regulators stress the importance of using explainable red-teaming techniques and implementing effective controls to manage these risks.

[DynamoEval](https://dynamo.ai/platform/dynamoeval)’s privacy testing suite goes beyond simple PII detection. It generates reports detailing the conditions that make applications susceptible to data leakage. This post will show how to integrate DynamoEval’s tests into a CI/CD pipeline with [DynamoEnhance](https://dynamo.ai/platform/dynamoenhance), facilitating rapid deployment and testing of compensating controls and risk mitigation strategies like differential privacy.

At Dynamo AI, we lead in [privacy research](https://arxiv.org/abs/2307.16382), quickly integrating the latest techniques into DynamoEval. Our tool red-teams models for vulnerabilities, employing attacks such as Membership Inference, PII Extraction, and Data Extraction. It also provides automated reports, dashboards, and detailed analyses to identify and address these risks.

Below, we explore how DynamoEval uses explainable testing to address PII extraction and membership inference vulnerabilities in LLMs. This walkthrough includes simulating a privacy attack as described by [Lukas et al](https://arxiv.org/abs/2302.00539). from Microsoft Research, demonstrating how enterprises can enhance data privacy in their machine learning applications.

## Evaluating model vulnerability to PII extraction and membership inference

**PII extraction attacks** and **membership Inference attacks** are two types of privacy attacks that can expose sensitive information in machine learning models. We demonstrate how to evaluate models against these attacks and interpret the results.

- In a **PII extraction attack** setting **,** an adversary attempts to extract sensitive pieces of information (e.g., names, addresses, phone numbers) that the model might have memorized during fine-tuning or training.
- In a **membership inference attack** setting, the adversary tries to infer whether or not an already-known data point was used for training.

With DynamoEval, we evaluate our models against these attacks by simulating an adversary with access to the model and a set of data records. DynamoEval runs multiple iterations of an attack using different splits of the data and hyperparameter settings. We then provide detailed metrics, like ROC curves, AUC scores, PII extraction, Precision, and Recall to quantify the model’s vulnerability to these attacks.

## Evaluating PII extraction attacks

A PII extraction attack assesses the risk of PII being extracted by attackers who have various levels of knowledge about the training dataset. This attack involves prompting the model with a series of inputs and analyzing whether PII is present in the model’s outputs.

During a PII extraction attack, three key metrics are reported: **‍**

- **PII Extracted:** The number of PII successfully extracted from the model responses
- **Recall**: The percentage of actual PII that was successfully extracted (out of the training dataset)
- **Precision**: The proportion of identified PII instances that are true positives

![](https://rnikhil.com/assets/files/piiextract.png)

## Membership inference attacks

The goal of a membership inference attack is to determine whether specific data records can be inferred as part of the model’s training dataset. It is conducted by simulating an attacker with access to the model and a dataset, with some records being part of the training data.

We simulate the attacker building a classifier that predicts whether a data record was part of the training dataset. The performance of this classifier indicates how much information about the training data is exposed, revealing its susceptibility to membership inference attacks.

- **True positive rate (TPR):** In this attack, the true positive rate (TPR) represents the percentage of data records correctly predicted to be members of the training dataset. We evaluate the TPR at various low false positive rates (FPRs) to determine the attacker’s success in high-confidence scenarios.
- **ROC-AUC**: In this attack, the Receiver Operating Characteristic (ROC) curve can also be used to to define vulnerability, which demonstrates the performance of the attack as a tradeoff between the TPR and FPR at various thresholds. We can then use the Area Under the ROC Curve (AUC) to measure the aggregate performance across all thresholds. [Recent research](https://arxiv.org/abs/2112.03570) also suggests evaluating the attack’s TPR in the low FPR regime (the three percentages shown at the top) to characterize whether the attack can confidently identify members of the training set.

![](https://rnikhil.com/assets/files/meminf.png)

## DynamoEval UI walkthrough

In this section, we provide a step-by-step guide to using the DynamoEval product:

#### 1\. Curate a train/test dataset

First, select the training and test datasets for evaluating the model’s privacy vulnerabilities. Specify which column contains the text data. Datasets are uploaded in CSV format.

For PII extraction and membership inference attacks, this dataset is usually the one used for fine-tuning the model.

#### 2\. Upload model and dataset to Dynamo AI

Upload both your trained model and the dataset to the Dynamo AI platform. Make sure to specify any relevant files, such as LoRA adapter configurations, if applicable.

![](https://rnikhil.com/assets/files/upload.png)

#### 3\. Choose tests

Select the specific attack you want to run, such as PII Extraction or Membership Inference. The screenshot below displays the range of privacy attacks available on our platform.

![](https://rnikhil.com/assets/files/testcat.png)

#### 4\. Analyze results

After the tests are complete, we analyze the results to understand the model’s vulnerability to the attacks.

In the ROC curve example below, the straight, gray line where X = Y indicates a random guessing baseline. The AUC is a measure of the performance of a binary classifier, ranging from 0 to 1. An AUC of 1.0 indicates perfect classification, while an AUC of 0.5 would indicate random guessing.

In this case, the AUC is 0.77, revealing that the attacker was able to differentiate between members and non-members of the dataset with a high success rate.

![](https://rnikhil.com/assets/files/miipii.png)

Below, the FPR represents the percentage of records falsely identified as being members of the training dataset, and the TPR represents the percentage of records correctly identified as being members of the training dataset.

We provide three different TPR rates for clarity. You can also review the prompts and responses used in the attack in our deep dive section. Additionally, any PII extracted from the model during the attack is tagged and included in the response.

![](https://rnikhil.com/assets/files/deepdive.png)

We can also review the loss distribution plots to gain insights into the model’s behavior on both training and testing data. [Research](https://arxiv.org/abs/1906.00389) shows that a high degree of separation in these distributions suggests the model is less generalized and more vulnerable to membership inference and data leakage.

![](https://rnikhil.com/assets/files/plotmii.png)

#### 5\. Generate test reports

After the tests are completed, we generate PDF reports that provide detailed information on the attack methodology, results, and recommendations for improving the models.

![](https://rnikhil.com/assets/files/testreport.png)

## DynamoEval SDK walkthrough

#### 1\. Initiation

Start by installing the public Dynamo AI SDK. import the required libraries and specify the required environment variables. Create a Dynamo AI instance using your API token and host.

If you do not have an API token, log into [app.dynamofl.com](http://app.dynamofl.com/) with your credentials to generate one. This API token will enable you to programmatically connect to the DynamoFL server, create projects, and evaluate models. (Note that if you generate multiple API tokens, only your most recent one will be valid.)

```

from dynamofl import DynamoFL, GPUConfig, GPUType

API_KEY = "" # Add your API key here
API_HOST = "https://api.dynamofl.com" # DFL or custom API host here

dfl = DynamoFL(API_KEY, host=API_HOST)

```

#### 2\. Create a model and dataset object

Next, create a local model object. This object specifies the model on which privacy tests will be run using the ‘create\_test’ method. Dynamo AI currently supports two types of model objects: local models and remote model API endpoints. In this example, we will focus on local models.

A local model object can be used to upload a custom model and run penetration tests. Creating a local model object requires specifying the model file path and architecture. Currently, Dynamo AI supports penetration testing on uploaded models with ‘.pt’ and ‘.bin’ file formats. (Please confirm that your provided model file fits this formatting.) For model architectures, provide any valid HuggingFaceHub model id.

In this example, we use a local model that has been fine-tuned using Low-Rank Adaptation (LoRA). LoRA is a technique that “freezes” the majority of parameters in a pre-trained LLM, while fine-tuning a small subset of additional parameters. This reduces training time, compute usage, and storage costs.

When working with a model fine-tuned with LoRA or parameter-efficient fine-tuning (PEFT), you must also provide the file path to the PEFT adapter configuration.

To run a privacy evaluation test, specify the dataset used for fine-tuning the model. Create a dataset object by providing the dataset file path and assign it a unique key and identifying name.

```

model_path_dir = "<path_to_your_trained_model_file>"

# using a PEFT LoRA adapter for a lightweight model upload

model_file_path = os.path.join(model_path_dir, "adapter_model.bin")
peft_config_path = os.path.join(model_path_dir, "adapter_config.json")
model_architecture = "dynamofl-sandbox/sheared-llama-1b3"

# Creating a local model referring to a fine-tuned LLaMA 1.3B
model = dfl.create_model(
    name="Sheared LLama DP",
    model_file_path=model_file_path,
    architecture=model_architecture,
    peft_config_path=peft_config_path,
    architecture_hf_token="hf_***",
)
print(f"Model successfully uploaded with key {model.key}.")

# Upload dataset
dataset = dfl.create_dataset(
    key="dataset_pii_extraction",
    file_path="<path_to_your_training_dataset_file>",
    name="Finetuning Dataset"
)
# dataset id
print(f"Dataset successfully uploaded with key {dataset.key}.")

```

#### 3\. Test parameters

When configuring a test, you can configure various parameters to customize the test to your needs. Key parameters include:

- The column name from the dataset to create prompts
- The types of PII to detect for leakage
- The model temperature for running tests

These test configuration parameters should be provided to the `create_pii_extraction_test` method. Additionally, it’s required to provide the dataset column names in the test parameters when creating a test.

##### PII classes and entities

When configuring a PII extraction or inference attack, one of the most important hyperparameters is the `pii_classes` parameter. This parameter defines which types of PII the extraction attack will target.

In addition to the predefined PII classes, you can also detect leakage for custom-defined regex entities. To do this, define a dictionary mapping entity names to the valid Python regex expression in the `regex_expressions` parameter.

```
pii_entities = ["PERSON", "DATE_TIME", "ORGANIZATION", "EMAIL_ADDRESS"]
regex_expressions = {
    "USERNAME": r"([a-zA-Z]+_[a-zA-Z0-9]+)",
}

test_info = dfl.create_pii_extraction_test(
    name="privacy_test_pii_extraction",
    model_key=model.key, # previously created model identifier key
    dataset_id=dataset._id, # previously created dataset id
    pii_ref_column="text", # column name containing text to be evaluated
    gpu=GPUConfig(gpu_type=GPUType.V100, gpu_count=1), # default GPU parameters
    sampling_rate=1024,
    pii_classes=pii_entities,
    regex_expressions=regex_expressions,
    grid=[{\
        "temperature": [0.5, 1.0, 1.5]\
    }], # test configurations
)

attack_info = dfl.get_attack_info(attack_id)
print("Attack status: {}.".format(attack_info))

```

#### 4\. Run the test

To run a membership inference privacy evaluation test, call the `create_membership_inference_test` method. This will submit the test to your cloud machine-learning platform, where it will be run.

Dynamo AI currently has four types of privacy tests to assess whether a fine-tuned model has memorized data from the training set.

- **PII Extraction:** Checks if PII can be extracted by prompting the model naively, simulating an attacker with no knowledge of the training dataset
- **PII Inference:** Tests whether a model can re-fill PII into sentences from a fine-tuned dataset, where PII has been redacted, assuming an attacker with knowledge of the concepts and potential PII in the dataset
- **Data Extraction:** Evaluates whether the model can be prompted to reveal training data verbatim in its responses
- **Membership Inference:** Determines whether specific data records can be identified as part of the model’s training dataset

After creating your tests, go to the model dashboard page in the Dynamo AI UI. You will see that your model and dataset have been created and your test is running.

Once the test is complete, a report file will be generated which you can download for a detailed analysis of the results.

```
# Upload dataset
dataset_mia = dfl.create_dataset(
    key="dataset_mia",
    file_path="<path_to_your_training_dataset_file>",
    test_file_path="<path_to_your_test_dataset_file>",
    name="Finetuning Dataset"
)

# dataset id
print(f"Dataset successfully uploaded with key {dataset_mia.key}.")

test_info_mia = dfl.create_membership_inference_test(
    name="privacy_test_mia",
    model_key=model.key, # previously created model identifier key
    dataset_id=dataset_mia._id, # previously created dataset id
    input_column="text",
    gpu=GPUConfig(gpu_type=GPUType.A10G, gpu_count=1), # another GPU configuration
    pii_classes=pii_entities,
    regex_expressions=regex_expressions,
    base_model=model_args.model_name_or_path,
)

```

#### Integrating DynamoEval into your CI/CD pipelines

Ensuring data privacy and security in machine learning models is critical, and real-time monitoring plays an important role in the process.

By integrating DynamoEval into your development and deployment process, you can conduct comprehensive testing for privacy and security vulnerabilities.

**Integration areas:**

- **Post-training checks:** Incorporating DynamoEval in your post-training checks allows you to scan models after training or fine-tuning to detect any privacy leaks or compliance issues that may have arisen during the training phase.
- **Scans in CI/CD pipeline:** Automate DynamoEval scans within your CI/CD pipeline to include them in the release phase, ensuring that models are evaluated for vulnerabilities before they are staged for deployment.
- **Final privacy check:** Conduct a final privacy check during the deployment phase to safeguard against deploying models with vulnerabilities.

Making DynamoEval scans a routine part of the CI/CD pipelines enables you to proactively safeguard your models against privacy risks, ensuring trust and compliance throughout your operations.

#### Actionable insights and mitigation strategies

DynamoEval not only identifies potential privacy vulnerabilities, it also provides actionable insights to mitigate these risks. Based on the evaluation results, the platform offers recommendations for improving the model’s privacy protection.

For instance, given the AUC score of 0.77 in our example, which indicates a significant vulnerability to membership inference attacks, the next step would be to remediate this risk. Implementing techniques such as [differential privacy](https://arxiv.org/abs/1607.00133) during model training can effectively reduc this vulnerability. Our evaluation shows that applying differential private effectively lowers the AUC, underscoring its effectiveness in improving privacy protection.

In addition, employing non-aggressive PII scrubbing techniques that preserve data relationships and uniqueness while minimizing leakage risk can further strengthen privacy protection efforts.

Finally, leveraging [DynamoGuard](https://dynamo.ai/platform/dynamoguard), our privacy guardrail product, can provide additional security by detecting and redacting PII in real time. Combining both model-level and infrastructure-level privacy measures can substantially enhance the overall privacy posture of machine learning applications.

As LLMs become more powerful and prevalent, the risk of exposing sensitive information from training datasets increases. With Dynamo AI’s comprehensive privacy solutions, teams can effectively measure, address, and prevent data leakage, ensuring the responsible deployment and use of LLMs while protecting sensitive information.

**Learn more about Dynamo AI and our AI privacy and security solutions by** [**scheduling a demo.**](https://dynamo.ai/request-a-demo)

August 30, 2024 · [ai](https://rnikhil.com/tag/ai), [llms](https://rnikhil.com/tag/llms), [pii](https://rnikhil.com/tag/pii), [data](https://rnikhil.com/tag/data), [leakge](https://rnikhil.com/tag/leakge), [membership](https://rnikhil.com/tag/membership), [security](https://rnikhil.com/tag/security)

## Differential Privacy for LLMs
## Unlocking Differential Privacy for >7B Parameter LLMs

* * *

This post was cowritten by me and was originally published on [Dynamo AI’s blog](https://dynamo.ai/blog/unlocking-differential-privacy-for-llms).

![](https://rnikhil.com/assets/files/dpmain.png)

Recent research shows that large language models (LLMs) are often prone to memorizing their training and fine-tuning datasets. This is a vulnerability that can be exploited by adversarial attacks, where malicious actors craft specific prompts to [extract sensitive information](https://arxiv.org/abs/2311.17035) from these models.

For organizations developing and deploying LLMs, this presents a significant risk to data security and privacy. Differential privacy (DP) helps mitigate this risk by strategically injecting statistical noise during the training process. This technique controls the risk of data memorization, while balancing privacy and performance.

Given its effectiveness, differential privacy is being closely examined by federal agencies as a key defense against adversarial attacks and data leakage in LLMs. The National Institute of Standards and Technology (NIST), which developed the widely used NIST AI Risk Management Framework, endorsed [differential privacy](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-226.ipd.pdf) as the most reliable method for ensuring robust privacy protection against both known and future attacks, even with multiple data releases.

Other government organizations, like the [U.S. Census Bureau](https://www.census.gov/programs-surveys/decennial-census/decade/2020/planning-management/process/disclosure-avoidance/differential-privacy.html), are starting to adopt differential privacy as core component of their data protection strategies. To expand the use of privacy-preserving machine learning, it’s crucial to develop differential privacy solutions that can efficiently handle large datasets and complex applications.

‍

> “Differential privacy is currently the best known method for providing robust privacy protection against known and future attacks, even in the face of multiple data releases.” — The National Institute of Standards and Technology (NIST)

![](https://rnikhil.com/assets/files/dynaproc.png)

## **Challenges in adopting differential privacy for LLMs**

Despite its promise for safeguarding LLMs, differential privacy adoption has faced significant challenges. The sheer magnitude of LLMs, some of which have trillions of parameters, poses significant hurdles for engineers.

The traditional Differentially-Private Stochastic Gradient Descent ( [DP-SGD](https://arxiv.org/abs/1607.00133)), which [computes individual, per-sample gradients](https://arxiv.org/pdf/2010.09063), significantly slows down training compared to standard neural network methods. This is because DP-SGD loses the parallel processing benefits of GPUs, resulting in longer training times and higher GPU memory requirements.

The previous state-of-the-art in differentially private fine-tuning struggled with models exceeding approximately 1.5 billion parameters. Practitioners faced challenges with limited throughput and extremely long training durations. The memory constraints of these methods made it challenging to train on anything other than high-end GPUs, like the A100 (40GB, 80GB), resulting in costly and complex implementation.

Moreover, current differential privacy frameworks, such as the Opacus library, aren’t well-stuied for large LLM workloads. While Opacus supports Distributed Data Parallel (DDP) training, it lacks model sharding capabilities.

DDP replicates the entire model on each GPU, which can lead to memory constraints when handling large models. This limitation made it difficult or nearly impossible to train LLMs with billions of parameters efficiently across multiple GPUs. As a result, the lack of model sharding in Opacus has hindered the scalability and practicality of differentially private training for large-scale deep learning models.

![](https://rnikhil.com/assets/files/dp1.png)

![](https://rnikhil.com/assets/files/dp2.png)

## **Apply differential privacy at scale with DynamoEnhance**

[Bu _et al._](https://arxiv.org/abs/2311.11822) developed a new approach called DP-ZeRO to enable large-scale differentially private deep learning using the DeepSpeed library. DeepSpeed, known for its Zero Redundancy Optimizer (ZeRO), enhances training speed and reduces memory usage when working with large models across multiple GPUs. The researchers have extended DeepSpeed to support differentially private training, proving that effective privacy injection is achievable with the right techniques.

DP-ZeRO opens up exciting opportunities for Dynamo AI to build upon the work and integrate scalable differential privacy in [DynamoEnhance](https://dynamo.ai/platform/dynamoenhance). By leveraging DeepSpeed’s multi-GPU model sharding capabilities and incorporating differential privacy into the distributed training process, DynamoEnhance offers enhanced data protection and privacy without sacrificing the power of large-scale models.

This is where we come in. DynamoEnhance’s MultiGPU privacy framework, built on the DeepSpeed library, seamlessly integrates differential privacy. It features user-friendly Trainers inspired by popular transformers and TRL (Transformer Reinforcement library) libraries, making advanced privacy protection accessible while optimizing model performance.

```
from dynamofl.privacy import DPTrainer, PrivacyArguments

# model, tokenizer = ...
# train_dataset, eval_dataset = ...

privacy_args = PrivacyArguments(target_epsilon=1.0)
trainer = DPTrainer(
    model=model,
    tokenizer=tokenizer,
    args=train_args,
    privacy_args=privacy_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset
)
trainer.train()

```

In the above example, we set the target epsilon value in our `PrivacyArguments`, where `Epsilon` represents the “privacy budget.” A lower epsilon value indicates less privacy expenditure, resulting in more noise being added to the gradients. Conversely, a higher epsilon value means a larger privacy budget and less noice to the gradients, offering reduced privacy protection.

By leveraging DeepSpeed and incorporating innovative techniques, DynamoEnhance enables efficient, scalable training of LLMs while maintaining robust privacy guarantees and accommodating larger batch sizes.

This cutting-edge approach differentiates our solution by providing enterprise customers with an effective and easy-to-use approach to safeguarding sensitive data with differential privacy, while harnessing the power of LLMs.

Our technology supports MultiGPU model sharding in ways not previously achievable with existing differential privacy libraries. The DynamoEnhance MultiGPU Differential Privacy SDK is compatible with popular training libraries and methods, including Hugging Face, mixed precision, quantized training like BitsAndBytes, Mixture of Quantization (MoQ), LoRA fine-tuning, flash attention, and accelerate. We support leading LLMs such as Llama-70B, Mistral-8x7B, and more.

## **Empowering enterprise customers with differential privacy**

At Dynamo AI, our mission is to empower enterprise customers with the tools and knowledge necessary to unlock the potential of differential privacy. We offer comprehensive documentation and QuickStart guides that enable users to effortlessly experiment with differential privacy fine-tuning of LLMs, regardless of their technical expertise.

By prioritizing accessibility and usability, we aim to make privacy-enhancing technologies available to a broader audience, beyond just those with a formal background in privacy-preserving machine learning.

As LLMs become more powerful and prevalent, the risk of exposing sensitive information from training datasets increases. [Dynamo AI](https://dynamo.ai/) provides comprehensive privacy solutions that help teams effectively measure, address, and prevent data leakage, ensuring the responsible deployment and use of LLMs while protecting sensitive information.

We also offer a range of AI privacy and security solutions to help you build trustworthy and responsible AI systems. To learn more about Dynamo AI and to explore our privacy and security offerings, [request a demo today.](https://dynamo.ai/request-a-demo)

September 22, 2024 · [ai](https://rnikhil.com/tag/ai), [llms](https://rnikhil.com/tag/llms), [pii](https://rnikhil.com/tag/pii), [differential](https://rnikhil.com/tag/differential), [privacy](https://rnikhil.com/tag/privacy), [pii](https://rnikhil.com/tag/pii), [security](https://rnikhil.com/tag/security)

## RAG Hallucination Evaluation
## Tackling the Explainability Gap in RAG Hallucination Evals

* * *

This post was cowritten by me and was originally published on [Dynamo AI’s blog](https://dynamo.ai/blog/tackling-the-explainability-gap-in-open-source-hallucination-evals).

![](https://rnikhil.com/assets/files/rag1.png)

As many of our enterprise customers move from PoC to production LLM deployment, we find that enterprises need to demonstrate robust reliability testing of their AI systems. The tendency for LLMs to “hallucinate” incorrect or inconsistent outputs remains a major challenge for enterprises at this stage.

In a recent example, [Air Canada’s chatbot](https://www.bbc.com/travel/article/20240222-air-canada-chatbot-misinformation-what-travellers-should-know) hallucinated information about refunds and discounts, leading to significant confusion and complaints. Moreover, for highly-regulated enterprises such as financial institutions, regulators like the Consumer Financial Protection Bureau have highlighted that “deficient chatbots” can lead to a “risk of noncompliance with federal consumer financial laws.”

Specifically, the [CFPB states](https://www.consumerfinance.gov/data-research/research-reports/chatbots-in-consumer-finance/chatbots-in-consumer-finance/) that a chatbot “providing inaccurate information regarding a consumer financial product or service, for example, could be catastrophic. It could lead to the assessment of inappropriate fees, which in turn could lead to worse outcomes such as default, resulting in the customer selecting an inferior option or consumer financial product, or other harms.”

While retrieval-augmented generation (RAG) aims to reduce hallucinations by grounding outputs in retrieved passages, enterprises deploying RAG still typically see high degrees of hallucinations during their testing. To safely deploy LLMs, enterprises are beginning to widely integrate routine hallucination evaluators to measure and trace the root causes of hallucinations in their RAG pipelines.

While open-source LLM evaluators have played an important role in the evolution of this space, we find that regulated enterprises that are moving LLMs into real production environments require an enterprise-grade solution that includes more explainable metrics and alignment with regulatory standards for comprehensive red-teaming. For example, most of our customers who have experimented with open-source LLM evaluators are still left with key unresolved questions such as:

1. Without an interpretable hallucination risk score, what is an acceptable “threshold score” for deploying LLMs into production?
2. If my AI system is not meeting a satisfactory hallucination risk score, what actionable steps can I take to mitigate hallucinations?
3. How can I explain the testing I’ve performed to regulators and meaningfully explain residual risk that may exist?

In this post, we’ll explore the challenges enterprises face in tackling RAG hallucinations, the limitations of existing tools, and introduce Dynamo AI’s comprehensive solution for measuring and tracking these issues.

## Limitation of existing tools

While many tools exist for evaluating the degree of hallucination for RAG applications, major limitations include the following:

- _Less interpretable metrics._ Usually, evaluation metrics will simply output a score value between 0 and 1. Oftentimes, these scores may not be well-calibrated or can be too difficult to understand. For instance, one prominent metric for measuring text relevance is embedding similarity, which uses the cosine distance of two embedded texts. While the range of this distance value is normalized to be between 0 and 1, it is generally unclear how to interpret these scores and what range of scores is considered good or bad.
- _Lack of fine-grained, actionable analysis for model improvements._ Usually, the evaluation stops at the point where the evaluation scores are computed. Further analysis of detailed error cases that can lead to potential improvements of the system is not present in most of the tools.
  - It’s not clear which part of the RAG pipeline, the retriever or the response generator, needs to be improved based on the metrics and diving deeper into a topic level analysis is also not straightforward.

## Dynamo AI’s RAG hallucination evaluation

Dynamo AI provides a comprehensive RAG evaluation solution that assesses model performance across multiple metrics:

1. **Retrieval relevance:** Represents the relevance of the documents retrieved from the vector database using the embedding model for each query.
2. **Faithfulness:** Evaluates whether the generated response is consistent with the retrieved documents.
3. **Response relevance:** Determines if the generated response adequately addresses the given query.

Dynamo AI leverages purpose-built models for each evaluation task, ensuring cost-efficiency and enabling in-depth analysis. Further, the platform offers actionable insights by identifying topic clusters where the RAG pipeline underperforms and categorizing errors by issue type for in-depth analysis. To demonstrate our solution, we ran our RAG hallucination tests against the MultiDoc2Dial dataset and compared the results with [RAGAS](https://docs.ragas.io/en/latest/index.html) for reference.

### Accurate and interpretable performance metrics

In a head-to-head comparison, DynamoEval’s RAG hallucination suite outperformed RAGAS in a classification task of identifying good/bad context/responses given a query. We measured accuracy and area under the receiver operating characteristic (AUROC) across the following metrics: Retrieval Relevance, Faithfulness, and Response Relevance. The following improvements in performance have been achieved through additional prompt optimizations and the use of performant task-specific models.

![](https://rnikhil.com/assets/files/rag2.png)

[DynamoEval](https://dynamo.ai/platform/dynamoeval), unlike RAGAS, returns both the relevance/faithfulness scores and binary labels (good/bad). Test results with only the scores tend to be more ambiguous due to the difficulties associated with drawing a clear threshold demarcating good and bad.

The receiver operating characteristic (ROC) curves and the resulting AUROC values shown below demonstrate that the relevance/faithfulness scores from DyamoEval are more accurate in diagnosing Retrieval Relevance, Faithfulness, and Response Relevance.

![](https://rnikhil.com/assets/files/rag3.png)

![](https://rnikhil.com/assets/files/rag4.png)

Easier interpretation of Response Relevance test results

![](https://cdn.prod.website-files.com/66030bc3057ae1e90ac956b7/66b694054e7371362faee8f8_66294456ae6ed9a24e4a9b71_Retrieval%2520Relevance.png)

Easy interpretation of Retrieval Relevance test results

### Investigate sources of error using topic level clustering

DynamoEval does not stop at generating classification labels and scores for each metrics, but further clusters the input queries based on different topics to provide additional insights for sources of errors and improvements. Analyzing hallucination metrics at a topic-level enables targeted data augmentation and model fine-tuning to address weak areas.

The results explored below are based on the aforementioned test between DynamoEval and RAGAS, wherein we constructed a binary classification dataset from Multidoc2dial, evaluated RAGAS and DynamoEval using accuracy and AUROC, and compared their performance. We also analyzed individual topics for their RAG metrics to dive deeper into specific areas of performance within the RAG pipeline.

For the “student scholarship” topic, Retrieval Relevance is low at **0% (0% of tested queries in this topic retrieved the correct document chunk).** This suggests that there may be opportunities for improvements in the retrieval mechanism. One possible reason for the low Retrieval Relevance score could be that the vector database used in the test lacks sufficient information on student scholarships, which could be improved through the injection of additional scholarship-topic related documents to the vector database.

Another possible reason for the low Retrieval Relevance score could be that the embedding model used as part of the retriever is not performant enough to identify the correct scholarship-topic related documents, in which case additional fine-tuning of the embedding model may be necessary.

![](https://rnikhil.com/assets/files/rag6.png)

Faithfulness is also relatively low for the “disability eligibility” topic at 9%, indicating that the generator model struggles to produce information consistent with the retrieved documents, even if they are relevant. Augmenting the training data with more ground-truth, question-context-answer pairs related to disabilities could help fine-tune the generator to be more faithful.

![](https://rnikhil.com/assets/files/rag7.png)

Using the labels from the above section, we can drill deeper into our topic-specific metrics to find out whether any poor-performance metric was related to either a generator or retriever related problem. The analysis looks at combinations of Retrieval Relevance, Faithfulness, and Response Relevance to pinpoint issues.

For example, if Retrieval Relevance and Response Relevance are both high but Faithfulness is low, it may suggest that the generator is not leveraging the retrieved information properly; or if Retrieval Relevance is low but Faithfulness and Response Relevance are high, the retriever may be the source of the problem (see the example below).

![](https://rnikhil.com/assets/files/rag8.png)

In conclusion, Dynamo AI’s evaluation suite for RAG addresses two major limitations in existing tools:

1. A lack of interpretable metrics, which is addressed via more intuitive and accurate set of classification labels and scores
2. A lack of fine-grained, detailed analysis of the errors for actionable improvements, which is addressed with topic-level clustering and error type analysis

### Comparison methodology with RAGAS

- Dynamo AI took the Multidoc2dial [dataset](https://doc2dial.github.io/multidoc2dial/) as the base dataset and constructed a classification dataset with binary labels
  - Positive data points were taken directly from the original dataset.
  - Negative data points were taken by perturbing the context and answers from the original dataset.
- Dynamo AI then ran RAGAS and DynamoEval on both positive and negative data points to compare their classification performance.
- The performance metrics used were Accuracy and AUROC. AUROC computes the area under the [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic), plotting the true positive rate (i.e., probability of positive classification given the positive example) against the false positive rate (i.e., probability of positive classification given the negative example) for various thresholds. Bigger values that are closer to 1 are considered better.
- To compute accuracy, Dynamo AI chose the threshold that maximized the F1 score for RAGAS to binarize the generated scores into labels, and directly used the labels generated by DynamoEval.

### Running a DynamoEval RAG hallucination test from the SDK

Dynamo AI provides an easily configurable SDK method to set up and run the RAG hallucination test by specifying the following parameters:

![](https://rnikhil.com/assets/files/rag9.png)

- `name`: name of the test
- `model_key`: model key for the generator model tested
- `datsaet_id`: dataset id containing queries for the RAG
- `input_column`: column name from the dataset that contains queries for the RAG
- `prompt_template`: prompt template used to synthesize the retrieved contexts and the query.
- `vector_db`: configuration of the vector database
- `rag_hallucination_metrics`: metrics used for the test (Retrieval elevance, Response elevance, Faithfulness)
- `topic_list`: list of topics that could be used for clustering the input queries for better error analysis. If not provided, it will cluster and automatically detect representative topical keywords from each cluster to show.
- `grid`: a set of test hyperparameters to be searched (model’s temperature, generated sequence length, and number of top-k contexts to be retrieved)
- `gpu`: type and number of GPU(s) to be used for the test

‍

## How Dynamo AI can help

At Dynamo AI, we are committed to helping organizations measure and mitigate RAG hallucination effectively. Our comprehensive RAG evaluation offering provides deep insights into model performance, enabling teams to identify and address weaknesses in their RAG pipelines.

We also offer a range of AI privacy and security solutions to help you build trustworthy and responsible AI systems. To learn more about how Dynamo AI can help you evaluate and improve your RAG models, or to explore our AI privacy and security offerings, [please request a demo](https://dynamo.ai/platform/dynamoeval).

September 22, 2024 · [ai](https://rnikhil.com/tag/ai), [llms](https://rnikhil.com/tag/llms), [rag](https://rnikhil.com/tag/rag), [hallucination](https://rnikhil.com/tag/hallucination), [eval](https://rnikhil.com/tag/eval)

## Evaluating RAG Systems
## How to (Accurately) Evaluate RAG Systems on Tabular Data

* * *

This post was cowritten by me and was originally published on [Dynamo AI’s blog](https://dynamo.ai/blog/rag-evals-on-embedded-tables).

![](https://rnikhil.com/assets/files/raga1.png)

In our [previous](https://dynamo.ai/blog/tackling-the-explainability-gap-in-open-source-hallucination-evals) post, we explored how retrieval-augmented generation (RAG) systems can face hallucination issues and how DynamoEval can accurately and effectively diagnose these errors.

When RAG systems generate responses, the retrieved document may be in plain text format or a different format. Tables, in particular, post a challenge for large language models (LLMs) due to their complex structure and the computational demands of tabular queries.

For instance, the state-of-the-art model exhibits an [error rate of 32.69%](https://arxiv.org/pdf/2401.04398) on the [WikiTableQuestion (WTQ)](https://huggingface.co/datasets/wikitablequestions) dataset, a standardized benchmark for tabular question-answering. Despite these significant errors, there’s a lack of dedicated RAG evaluation solutions focused on assessing pipelines that involve tabular data. We built DynamoEval to address this gap, as a comprehensive solution designed specifically to assess and enhance RAG systems dealing with tabular data.

In this post, we explore how to evaluate RAG systems when the retrieved document is a table and the response requires logical or computational reasoning. An example of this is a RAG system working with tabular financial documents, such as the consolidated balance sheets from [Apple’s 10-K report.](https://d18rn0p25nwr6d.cloudfront.net/CIK-0000320193/faab4555-c69b-438a-aaf7-e09305f87ca3.pdf)

Users may query the system with simple look-up questions, like “What is the total current asset of AAPL at the end of September, 2023? Respond in millions.” Or, they may use operation-focused queries, such as “By what percentage did the deferred revenue increase/decrease in September, 2023 compared to September, 2022? Round to the first decimal place.”

Accurate and faithful responses would be “$143,566 million” or “Increased by 1.9%,” respectively. However, if the system provides “$135,405 million” or “Increased by 1.3%”, these responses should be be flagged as incorrect and unfaithful.

[DynamoEval](https://dynamo.ai/platform/dynamoeval) excels in evaluating such responses by accurately assessing the correctness and faithfulness of the answers, addressing gaps left by existing evaluation solutions.

![](https://rnikhil.com/assets/files/raga2.png)

In the following sections, we explore methods to enhance the evaluation capabilities of two critical aspects:

1. **Assessing the relevance of the table:** This involves determining whether the table retrieved by the RAG system contains the necessary information to accurately answer the given query.
2. **Evaluating response correctness and faithfulness:** This focuses on verifying whether the RAG system’s output is both accurate and faithful to the information in the retrieved table and the query.

DynamoEval addresses these key areas to improve the diagnosis of RAG systems handling tabular data. Throughout the post, we use a series of test datasets, modified from a standard [Tabular QA dataset WikiTableQuestion (WTQ)](https://huggingface.co/datasets/wikitablequestions), with some manual cleaning, curation, and augmentation. These curated datasets include queries, contexts, responses, and ground-truth binary labels indicating the quality (good/bad) of the contexts and responses for retrieval and faithfulness evaluation. The evaluators will classify these contexts and responses, and performance will be measured using accuracy, precision, and recall based on the ground-truth labels.

## Findings: Enhancing evaluation through improved prompting

It turns out that refining how we prompt an LLM can lead to substantial improvements. To evaluate this, we tested DynamoEval against leading retrieval-augmented generation (RAG) evaluation tools — [RAGAS](https://docs.ragas.io/en/stable/), [LlamaIndex Evaluators](https://docs.llamaindex.ai/en/stable/module_guides/evaluating/), and [Tonic Validate](https://www.tonic.ai/validate?utm_medium=ppc&utm_term=tonic%20validate&utm_campaign=GenAI&utm_source=adwords&hsa_kw=tonic%20validate&hsa_cam=20916301117&hsa_ver=3&hsa_acc=9042438892&hsa_ad=686479083592&hsa_grp=158208323718&hsa_src=g&hsa_mt=p&hsa_tgt=kwd-2268085454349&hsa_net=adwords&gad_source=1&gclid=CjwKCAjww_iwBhApEiwAuG6ccGMKAlal3ZVewVTfGdtj8qat2_Ol_iCfOC8b4DbMUUBYTt1Yd9RqXhoCO18QAvD_BwE) — with the goal of assessing effectiveness in retrieval relevance and response faithfulness.

Additionally, we explore a multimodal evaluation approach. Instead of providing table content as text, we convert it into images and used a vision-language model (VLM), such as GPT-4 Vision, as an alternative to text-based table inputs.

We also test a multimodal evaluation approach using image inputs as a baseline. Instead of providing table content as text, we converted the table into an image and fed it to a vision-language model (VLM), like GPT-4 Vision. These alternative methods provide insights into the effectiveness of different evaluation strategies.

![](https://rnikhil.com/assets/files/raga3.png)

![](https://rnikhil.com/assets/files/raga4.png)

Because existing RAG evaluation solutions are primarily designed for evaluating textual data, we observe that they are not well-suited for tasks involving tables when used out-of-the-box, despite utilizing the same base model, such as GPT-4. However, DynamoEval demonstrates that significant performance improvements can be achieved through prompt optimizations. Some key factors contributing to this enhancement include:

1. Instruction prompts for role assignment: By providing specific instructions to the model, particularly assigning it a well-defined role, the model can better understand its task and focus on the relevant aspects of the evaluation process.
2. Chain of Thought (CoT) prompting: Encouraging the model to outline the steps taken to reach a conclusion enables a more structured and transparent evaluation process. This approach allows for a clearer understanding of the model’s reasoning and decision-making process.
3. Response structure optimization: Instructing the model to state its decision at the end of the response, after generating a step-by-step explanation, promotes a more correct decision. This structure ensures that the model’s conclusion is well-conditioned on the explanations.
4. Binary decision output: Instead of generating scores, prompting the model to output a binary decision (e.g., correct or incorrect) simplifies the evaluation process and provides a clear-cut assessment of the RAG system’s performance.

By incorporating these prompt optimization techniques, DynamoEval showcases its ability to significantly enhance the evaluation of RAG systems when dealing with tabular data, surpassing the limitations of existing solutions.

## The choice of base model for evaluation matters

We have observed that the performance of the evaluation process varies significantly depending on the choice of the base LLM, even when using the same optimized prompts. The plot below illustrates the performance of GPT (3.5) and Mistral (small) models on faithfulness evaluation using different versions of prompts:

1. Vanilla: Vanilla prompting (no Chain of Thought), with the decision stated _before_ the explanation
2. CoT: Chain of Thought prompting, with the decision stated _before_ the explanation
3. CoT + Optimized: Chain of Thought prompting, with the decision stated _after_ the explanation

![](https://rnikhil.com/assets/files/raga5.png)

![](https://rnikhil.com/assets/files/raga6.png)

The results demonstrate that CoT prompting and stating the decision after the explanation provides a greater benefit to the GPT model compared to the Mistral model. However, both models ultimately exhibit lower performance compared to the GPT-4 model discussed earlier.

## More on operation-heavy queries

When working with tabular data, it is common to encounter queries that demand more complex operations or logical reasoning over the contents of the table. To better understand how models perform in this scenario, we manually created a dataset based on the WikiTableQuestion (WTQ) dataset, specifically focusing on queries that heavily rely on operations. We evaluate the faithfulness performance on a set of questions that involves various types of operations, including addition, subtraction, variance, standard deviation, counting, averaging and percentage calculations.

By assessing the models’ performance on this curated dataset, we aim to gain insights into their capabilities and limitations when dealing with more complex queries involving tabular data. The below figure demonstrates DynamoEval’s performance compared to other RAG evaluation solutions.

![](https://rnikhil.com/assets/files/raga7.png)

While DynamoEval shows a slightly lower performance compared to the previous set of “easier” queries, it is still able to significantly outperform existing solutions. We describe some preliminary patterns from the failure cases, which will be useful to further investigate and categorize the types of queries/tables the evaluator model is particularly weak at:

### Operation involving a long list of entries

- It is more likely to fail when the table is long and therefore requires more entries to consider for operations. In the examples below, the model failed to identify the given responses as accurate and faithful, by failing to carry out calculations from a long list of entries or miscounting the entries from a long table.

#### Example 1

![](https://rnikhil.com/assets/files/raga8.png)

#### Example 2

![](https://rnikhil.com/assets/files/raga9.png)

### Errors in filtering the correct entries

- There were occasional errors for smaller tables in filtering the correct entries to consider. In the examples below, the model failed to identify the given responses as accurate and faithful by incorrectly considering the rows that did not satisfy the conditions set by the query.

#### Example 1

![](https://rnikhil.com/assets/files/raga10.png)

#### Example 2

![](https://rnikhil.com/assets/files/raga11.png)

‍

Evaluating the performance of RAG systems involving table data presents unique challenges due to the inherent differences between tabular and textual content. Our findings demonstrate that DynamoEval, with its optimized prompting techniques, significantly outperforms existing RAG evaluation solutions in assessing the relevance of retrieved tables and the faithfulness of generated responses. Through our curated datasets based on the WikiTableQuestion (WTQ) benchmark, we have identified key areas where the evaluator models may struggle, particularly when dealing with complex queries involving lengthy tables or multiple logical operations. By further understanding these limitations, we can focus our efforts on developing more robust and reliable diagnostics for RAG systems that can handle a wider range of tabular data and query types.

## How Dynamo AI can help

At Dynamo AI, we’re committed to helping organizations measure and mitigate RAG hallucination effectively. Our comprehensive RAG evaluation offering provides deep insights into model performance, enabling teams to identify and address weaknesses in their RAG pipelines.

We also offer a range of AI privacy and security solutions to help you build trustworthy and responsible AI systems. To learn more about how Dynamo AI can help you evaluate and improve your RAG pipelines, or to explore our AI privacy and security offerings, please request a demo [here](https://dynamo.ai/platform/dynamoeval).

September 22, 2024 · [ai](https://rnikhil.com/tag/ai), [llms](https://rnikhil.com/tag/llms), [eval](https://rnikhil.com/tag/eval), [rag](https://rnikhil.com/tag/rag), [tabular](https://rnikhil.com/tag/tabular), [hallucination](https://rnikhil.com/tag/hallucination)

## Prediction Markets Insights
## No, You can't bet on everything (and that's okay)

> Prediction markets, despite their theoretical promise and success in sports ($330B US betting volume) and elections ($40B in 2024), are unlikely to become mainstream for all future events due to fundamental demand and liquidity constraints. The core issue isn’t regulation or technology - it’s that none of the three key market participants find prediction markets appealing: gamblers want quick resolutions (42% of 2020 election volume traded in final week), long-term investors prefer growing wealth in traditional assets, and market makers can’t operate without consistent retail flow (there is no demand for betting on topics except elections and sports).

> This creates a structural chicken-and-egg problem where lack of demand and participations prevents reliable pricing, which in turn discourages serious folks. Due to these unfortunate structural issues, these markets only work in certain niches and in events with high public interest and pre-existing communities, immediate resolutions and natural gambling appeal.

I’ve been using prediction markets for various purposes over the last couple years, from speculating on sports to more recently the US elections and the F1 season. These products are pretty popular. Americans legally bet over $330 billion on sports in 2023, while the 2024 US presidential elections saw about $40 billion in wagers. Polymarket alone saw over $2 billion in volume just in October 2024. Looking at this explosive growth, it’s easy to get excited about the future of prediction markets.

![](https://rnikhil.com/assets/files/preda2.png)

This is the premise: harness the wisdom of crowds through financial incentives to predict future events. Put your money where your mouth is, and the market will aggregate everyone’s knowledge into probability estimates. At their core, prediction markets are betting markets where people can wager on the outcome of future events. The market price represents the crowd’s collective estimate. If shares are trading at $0.60, the market thinks there’s a 60% chance of that outcome happening. Curious about whether who is going to be the next NBA champion? There is a [market for that](https://polymarket.com/event/nba-champion-2024-2025). Wonder whether Tiktok will get banned in 2025 in US? There is a [market for that](https://polymarket.com/event/tiktok-banned-in-the-us-before-may-2025). The dream is “prediction markets on everything”, where you are able to bet on every possible thing that can happen in the future.

![](https://rnikhil.com/assets/files/preda3.png)

But after diving deep into how these markets actually work and analyzing real usage data, I think I was wrong about their potential to become mainstream products. While they may excel in niches like sports and elections, they may not become ubiquitous. Even in places where regulations are favourable (Betfair and UK), prediction markets have been unable to grow in volume beyond some categories. The reality is more nuanced and the challenges more fundamental than people realize. Let me explain why.

### How do prediction markets work?

Proponents(Vitalik calls it [info finance](https://vitalik.eth.limo/general/2024/11/09/infofinance.html)) argue that prediction markets harness the “wisdom of crowds” and there are some famous examples of this working:

- In 1906, a crowd at a [livestock exhibition](https://www.nature.com/articles/075450a0.pdf) collectively guessed an ox’s weight within 1% accuracy by averaging their estimates
- In 1968, the US Navy [found a missing submarine](https://books.google.co.uk/books?redir_esc=y&id=_t2KDQAAQBAJ&q) using collective expert predictions that were just 220 yards off

The theory makes sense. Prediction markets get people to bring information into the open by effectively paying them for revealing it. The market aggregates all this information into a single price that represents the collective estimate of that event happening.

Prediction markets aren’t new though. Italian city-states [had markets](https://users.wfu.edu/strumpks/papers/Int_Election_Betting_Formatted_FINAL_NoComments.pdf) for papal elections in the 16th century. The US has had [political betting markets](https://users.wfu.edu/strumpks/papers/Int_Election_Betting_Formatted_FINAL_NoComments.pdf) since its founding. But what makes them powerful is how they incentivize information sharing. If you know something the market doesn’t, you can profit by betting and moving the price to reflect that information.

There was a lot of hype around Polymarket this cycle where people claimed that it was able to predict the results more accurately(and ahead in time) than the polls(and even mainstream media). This is because polls ask for “Who will you vote for?” whereas prediction markets ask “Who do you think will win?” with financial incentives for accurate predictions, regardless of personal preferences. These don’t align often because one is your personal perspective and another is your personal preference(or intent). This combined with possibility of hedging (I will bet on Harris as a hedge because my crypto bags will any go up if Trump gets elected) explains the divergence.

While there are different types of prediction markets (binary,continuous, etc) and different mechanisms to match the trades, most of the technical details are irrelevant to this particular blog. You can read more about prediction markets on this [Lesswrong post](https://www.lesswrong.com/posts/GxmfqKjs6ruxNxhqr/prediction-markets-explained#Subsidizing_Liquidity) or about order matching systems in [this article](https://www.paradigm.xyz/2024/11/pm-amm). In practice, most successful prediction markets are hybrids. Polymarket, for instance, does order matching off-chain but settles everything on the blockchain. This gives you the best of both worlds - fast trading but transparent settlement.

One key thing to discuss here is about liquidity in prediction markets. When a new market is started, its generally not +EV for market makers to provide liquidity (unless such markets exist somewhere else and you have an idea of the probabilities) which means somebody has to **subsidize** or provide incentives for putting up the initial money. This is usually done by providing some sort of kickbacks or yield on the money which is locked up.

So, if the theory is sound, why am I not seeing prediction markets where I can bet on Bangalore weather?

### The problem with Prediction Markets

![](https://rnikhil.com/assets/files/preda7.png)

Despite their theoretical promise, prediction markets today face some limitations. The most obivous and repeating pattern is the crazy concentration of liquidity in short-term events and in certain niches. In India, crypto and cricket is responsible for about 80% of the volume on platforms like Probo, Winzo and MPL. On platforms like Polymarket, markets expiring within days or weeks see much higher trading volumes than longer-dated ones. This mirrors behavior in options markets, where short dated options have much higher OI compared to ones expiring next month.

![](https://rnikhil.com/assets/files/preda4.png)

Globally, volumes are dominated by elections and sports betting. The contrast becomes starker when looking at other types of markets like ones focused on scientific discoveries, CEO replacements, AI predictions, economic indicators, or technological developments. They often struggle to attract meaningful participation. Polymarket’s data shows this clearly - while their election markets saw daily volumes exceeding $350 million during peak periods, most other markets struggle to maintain consistent daily volumes above $1 million.

To understand why prediction markets struggle to scale beyond a few high-profile events, we need to look at the three key types of participants in any financial market:

1. **Speculators/Gamblers**: They’re in it for the thrill and don’t necessarily have an edge. Think retail options traders or meme coin enthusiasts. They generally make -EV bets. They usually bet on events which the general population is interested in. They prefer to have quick resolutions and not wait weeks/months for the bet to resolve

2. **Long-term Investors**: They’re trying to build wealth over time through appreciating assets like stocks. (Ex: an average SIP investor)

3. **Market Makers/Sharks**: The sophisticated players who provide liquidity and try to profit from pricing inefficiencies. (Ex: SIG, Jane street, etc) They usually make +EV bets and are very PnL consious


The problem? None of these groups find most prediction markets particularly appealing. Prediction markets have a major demand side problem

### Why Current Prediction Markets Struggle

Let’s break it down by user type:

**Speculators/Gamblers** only care about quick resolution:

- Notice how 99% of prediction market volume happens right before the event. Majority of the Polymarket election betting volume was on October. Short dated options have way more volume than long dated options.
- They want immediate feedback loops and gratification
- Long-term predictions are boring for them

![](https://rnikhil.com/assets/files/preda6.png)

**Long-term Investors** have zero interest in locking up money in prediction markets because:

- The capital doesn’t generate returns while waiting for event resolution
- They can invest in stocks/bonds instead and actually grow their wealth
- This is why responsible people have their savings in stocks and real estate, rather than a diversified portfolio of sportsbooks

**Market Makers/Sharks** can’t operate effectively because:

- There’s not enough retail flow and liquidity to trade against and they don’t want to trade mostly against other professionals. It’s like showing up to a poker table and finding out all the other players are poker pros. You’d much rather have a table of tourists. In regular markets, there is a constant flow of long term investors wanting to grow their wealth.
  - Counter point: [Kalshi](https://kalshi.com/) announced in April 2024 that Susquehanna International Group, a quantitative firm, had joined the platform as a market maker. But, in my view, markets are held back by the lack of long term investors and gamblers, rather than folks like SIG, Jane street, etc.
- Market size for 90% of the markets is too small to justify sophisticated analysis.
- Even these people don’t want to lock up the capital in long term bets because of the opportunity cost

![](https://rnikhil.com/assets/files/preda1.png)

This leads to a chicken/egg problem. Without gamblers and long term investors providing liquidity, market makers won’t participate. Without them making markets efficient, the prices aren’t reliable enough to attract serious investment. And 99% of the markets are too small to justify professionals spending time researching them. If people actually wanted to bet on random things, financial insitutions would have dumbed it down for retail customers (like they did with stock options, futures etc)

### When Do Prediction Markets Actually Work?

Markets based on sports have some very nice qualities. They repeat predictably (lot of data points for market makers), are short-dated (conclude fast) and are generally very communal events with massive particiaption from the general public. This quick resolution is critical for attracting gamblers, who strongly prefer immediate results. Elections, while less frequent, generate similar dynamics because they attract massive public interest and thereby liquidity. The social element is crucial too. People are already fans of teams and political candidates, creating natural communities. This built-in audience provides the baseline liquidity for markets to function and scale up.

To put it simply, not enough people in the world care about random topics like whether the LK-99 superconductor paper can be replicated or whether we will make contact with aliens by 2030. I’ve intentionally ignored various subsidy mechanisms which bootstrap multiple prediction market contracts because they aren’t super relevant to the discussion.

To summarise, these markets they work when:

1. Events resolve quickly (sports, short term politics)
2. There’s massive public interest driving volume
3. The underlying event recurs frequently enough to maintain engagement

### So what now?

I think a general way these platforms wil grow is when they:

1. Focus on niches with natural gambling appeal(massive public interest) and quick resolution.
2. Improve the core betting mechanics and not get distracted by fancy formats (video interfaces, blockchain, etc.)
3. Design for small, repeatable betting loops that maintain engagement. Micro betting(what happens in the next ball?) volumes are much bigger than full game outcomes (who will win this match?)

Prediction markets might be most valuable as an additional signal alongside other prediction methods, rather than trying to replace them entirely. They excel at aggregating information for events that people naturally want to bet on, and perhaps that’s exactly where they should stay. Not everything needs a prediction market - and that’s okay.

December 18, 2024 · [prediction](https://rnikhil.com/tag/prediction), [markets](https://rnikhil.com/tag/markets), [trading](https://rnikhil.com/tag/trading), [finance](https://rnikhil.com/tag/finance)

## Consistent Cold Coffee
## How to make consistent cold coffees?

I make 1-2 cups of cold coffee daily and sometimes for my SO and small inconsistencies have started driving us crazy. Some days it would be perfectly cold and creamy and other days a watery sludge. After months of trying various things and drinking a lot of coffee, I’ve discovered that making consistently great cold coffee comes down to understanding a few key things.

Success criteria for my coffee:

- Must stay icecold for around 15min. I usually finish it by then
- Thick, creamy texture throughout and shouldn’t turn watery like cold brew after sitting on my table for 10min
- Should take less than 1 min to make

Here is what I’ve learnt from my super scientific and rigorous experimentation 😂 :

- _Shake it, don’t stir it_
  - Stirring is useless. What takes 15 seconds of shaking needs like 2 minutes of violent stirring to achieve the same results
  - Shaking also mixes the drink more uniformly. Stirring always leaves some coffee/sugar at the bottom of the cup
  - Shaking also aerates the coffee with micro bubbles giving it a foamy texture (which stirring doesn’t)
  - I don’t seem to observe any benefit in over shaking(things seem to plateau after like 20sec of shaking) or how intensive/vigorous I do it (thankfully so)
- _You need lots of ice_
  - There is no problem with using too much ice as they stop affecting temperature or dilution beyond the equilibrium point. So, always ensure to have more ice than needed when you start. I use roughly 200g of ice for 100ml of coffee. It seems excessive but actually achieves ideal temp and dilution
    - If you have very little ice, it will result in poor chilling and will end up over diluting your coffee. This is sometimes counter intuitive. **_You actually want to use more ice, not less, to prevent over-dilution._** More ice equals faster chilling because you have more thermal mass to absorb heat quickly, reaching the target temp before too much of it melts.
- _Size of the ice cube matters (sometimes)_
  - Ice cube size does matter if you are planning to let your coffee sit on your table for more than 20min. Bigger ice cubes are better because they have smaller surface area per gram and thereby melt slower which has an added benefit of diluting your coffee slower over time
  - The size of the ice cubes doesn’t seem to matter for shaking (you end up with similar temp and dilution after 20sec) although theoretically smaller ice cubes chills marginally faster due to more surface area but I haven’t noticed this

All in all, it personally takes me less than a min to assemble all this and the results are fairly consistent

December 19, 2024 · [coffee](https://rnikhil.com/tag/coffee), [ice](https://rnikhil.com/tag/ice)

## Tolstoy's Lesson on Greed
## How much does a man need?

> I am so enamoured by the last chapter in Alok Sama’s book - [Money trap](https://www.goodreads.com/book/show/203578944-the-money-trap), that I have decided to repost Tolstoy’s short story on my blog. I think my readers will benefit from reading it.

An elder sister came to visit her younger sister in the country. The elder was married to a tradesman in town, the younger to a peasant in the village. As the sisters sat over their tea talking, the elder began to boast of the advantages of town life: saying how comfortably they lived there, how well they dressed, what fine clothes her children wore, what good things they ate and drank, and how she went to the theater, promenades, and entertainments.

The younger sister was piqued, and in turn disparaged the life of a tradesman, and stood up for that of a peasant.

‘I would not change my way of life for yours,’ said she. ‘We may live roughly, but at least we are free from anxiety. You live in better style than we do, but though you often earn more than you need, you are very likely to lose all you have. You know the proverb, “Loss and gain are brothers twain.” It often happens that people who are wealthy one day are begging their bread the next. Our way is safer. Though a peasant’s life is not a fat one, it is a long one. We shall never grow rich, but we shall always have enough to eat.’

The elder sister said sneeringly:

‘Enough? Yes, if you like to share with the pigs and the calves! What do you know of elegance or manners! However much your good man may slave, ​you will die as you are living—on a dung heap—and your children the same.’

‘Well, what of that?’ replied the younger. ‘Of course our work is rough and coarse. But, on the other hand, it is sure; and we need not bow to any one. But you, in your towns, are surrounded by temptations; to-day all may be right, but to-morrow the Evil One may tempt your husband with cards, wine, or women, and all will go to ruin. Don’t such things happen often enough?’

Pahóm, the master of the house, was lying on the top of the oven, and he listened to the women’s chatter.

‘It is perfectly true,’ thought he. ‘Busy as we are from childhood tilling mother earth, we peasants have no time to let any nonsense settle in our heads. Our only trouble is that we haven’t land enough. If I had plenty of land, I shouldn’t fear the Devil himself!’

The women finished their tea, chatted a while about dress, and then cleared away the tea-things and lay down to sleep.

But the Devil had been sitting behind the oven, and had heard all that was said. He was pleased that the peasant’s wife had led her husband into boasting, and that he had said that if he had plenty of land he would not fear the Devil himself.

‘All right,’ thought the Devil. ‘We will have a tussle. I’ll give you land enough; and by means of that land I will get you into my power.’

Close to the village there lived a lady, a small landowner, who had an estate of about three hundred acres\[1\]. She had always lived on good terms with the peasants, until she engaged as her steward an old soldier, who took to burdening the people with fines. However careful Pahóm tried to be, it happened again and again that now a horse of his got among the lady’s oats, ​now a cow strayed into her garden, now his calves found their way into her meadows—and he always had to pay a fine.

Pahóm paid, but grumbled, and, going home in a temper, was rough with his family. All through that summer, Pahóm had much trouble because of this steward; and he was even glad when winter came and the cattle had to be stabled. Though he grudged the fodder when they could no longer graze on the pasture-land, at least he was free from anxiety about them.

In the winter the news got about that the lady was going to sell her land, and that the keeper of the inn on the high road was bargaining for it. When the peasants heard this they were very much alarmed.

‘Well,’ thought they, ‘if the innkeeper gets the land, he will worry us with fines worse than the lady’s steward. We all depend on that estate.’

So the peasants went on behalf of their Commune, and asked the lady not to sell the land to the innkeeper; offering her a better price for it themselves. The lady agreed to let them have it. Then the peasants tried to arrange for the Commune to buy the whole estate, so that it might be held by all in common. They met twice to discuss it, but could not settle the matter; the Evil One sowed discord among them, and they could not agree. So they decided to buy the land individually, each according to his means; and the lady agreed to this plan as she had to the other.

Presently Pahóm heard that a neighbor of his was buying fifty acres, and that the lady had consented to accept one half in cash and to wait a year for the other half. Pahóm felt envious.

‘Look at that,’ thought he, ‘the land is all being sold, and I shall get none of it.’ So he spoke to his wife.

‘Other people are buying,’ said he, ‘and we must also buy twenty acres or so. Life is becoming impossible. That steward is simply crushing us with his fines.’

So they put their heads together and considered ​how they could manage to buy it. They had one hundred rubles laid by. They sold a colt, and one half of their bees; hired out one of their sons as a laborer, and took his wages in advance; borrowed the rest from a brother-in-law, and so scraped together half the purchase money.

Having done this, Pahóm chose out a farm of forty acres, some of it wooded, and went to the lady to bargain for it. They came to an agreement, and he shook hands with her upon it, and paid her a deposit in advance. Then they went to town and signed the deeds; he paying half the price down, and undertaking to pay the remainder within two years.

So now Pahóm had land of his own. He borrowed seed, and sowed it on the land he had bought. The harvest was a good one, and within a year he had managed to pay off his debts both to the lady and to his brother-in-law. So he became a landowner, plowing and sowing his own land, making hay on his own land, cutting his own trees, and feeding his cattle on his own pasture. When he went out to plow his fields, or to look at his growing corn, or at his grass-meadows, his heart would fill with joy. The grass that grew and the flowers that bloomed there, seemed to him unlike any that grew elsewhere. Formerly, when he had passed by that land, it had appeared the same as any other land, but now it seemed quite different.

So Pahóm was well contented, and everything would have been right if the neighboring peasants would only not have trespassed on his corn-fields and meadows. He appealed to them most civilly, but they still went on: now the Communal herdsmen would let the village cows stray into his meadows; then horses from the night pasture would get among his corn. Pahóm turned them out again and again, and forgave their owners, and for a long time he forbore from prosecuting any one. But at last he lost patience and complained ​to the District Court. He knew it was the peasants’ want of land, and no evil intent on their part, that caused the trouble; but he thought:

‘I cannot go on overlooking it, or they will destroy all I have. They must be taught a lesson.’

So he had them up, gave them one lesson, and then another, and two or three of the peasants were fined. After a time Pahóm’s neighbors began to bear him a grudge for this, and would now and then let their cattle on to his land on purpose. One peasant even got into Pahóm’s wood at night and cut down five young lime trees for their bark. Pahóm passing through the wood one day noticed something white. He came nearer, and saw the stripped trunks lying on the ground, and close by stood the stumps, where the tree had been. Pahóm was furious.

‘If he had only cut one here and there it would have been bad enough,’ thought Pahóm, ‘but the rascal has actually cut down a whole clump. If I could only find out who did this, I would pay him out.’

He racked his brains as to who it could be. Finally he decided: ‘It must be Simon-no one else could have done it.’ So he went to Simon’s homestead to have a look round, but he found nothing, and only had an angry scene. However, he now felt more certain than ever that Simon had done it, and he lodged a complaint. Simon was summoned. The case was tried, and re-tried, and at the end of it all Simon was acquitted, there being no evidence against him. Pahóm felt still more aggrieved, and let his anger loose upon the Elder and the Judges.

‘You let thieves grease your palms,’ said he. ‘If you were honest folk yourselves, you would not let a thief go free.’

So Pahóm quarreled with the Judges and with his neighbors. Threats to burn his building began to be uttered. So though Pahóm had more land, his place in the Commune was much worse than before.

About this time a rumor got about that many people were moving to new parts.

​’There’s no need for me to leave my land,’ thought Pahóm. ‘But some of the others might leave our village, and then there would be more room for us. I would take over their land myself, and make my estate a bit bigger. I could then live more at ease. As it is, I am still too cramped to be comfortable.’

One day Pahóm was sitting at home, when a peasant passing through the village, happened to call in. He was allowed to stay the night, and supper was given him. Pahóm had a talk with this peasant and asked him where he came from. The stranger answered that he came from beyond the Volga, where he had been working. One word led to another, and the man went on to say that many people were settling in those parts. He told how some people from his village had settled there. They had joined the Commune, and had had twenty-five acres per man granted them. The land was so good, he said, that the rye sown on it grew as high as a horse, and so thick that five cuts of a sickle made a sheaf. One peasant, he said, had brought nothing with him but his bare hands, and now he had six horses and two cows of his own.

Pahóm’s heart kindled with desire. He thought:

‘Why should I suffer in this narrow hole, if one can live so well elsewhere? I will sell my land and my homestead here, and with the money I will start afresh over there and get everything new. In this crowded place one is always having trouble. But I must first go and find out all about it myself.’

Towards summer he got ready and started. He went down the Volga on a steamer to Samára, then walked another three hundred miles on foot, and at last reached the place. It was just as the stranger had said. The peasants had plenty of land: every man had twenty-five acres of Communal land given him for his use, and any one who had money could buy, besides, at two shillings an acre\[2\] as much good freehold land as he wanted.

​Having found out all he wished to know, Pahóm returned home as autumn came on, and began selling off his belongings. He sold his land at a profit, sold his homestead and all his cattle, and withdrew from membership of the Commune. He only waited till the spring, and then started with his family for the new settlement.

As soon as Pahóm and his family arrived at their new abode, he applied for admission into the Commune of a large village. He stood treat to the Elders, and obtained the necessary documents. Five shares of Communal land were given him for his own and his sons’ use: that is to say—125 acres (not all together, but in different fields) besides the use of the Communal pasture. Pahóm put up the buildings he needed, and bought cattle. Of the Communal land alone he had three times as much as at his former home, and the land was good corn-land. He was ten times better off than he had been. He had plenty of arable land and pasturage, and could keep as many head of cattle as he liked.

At first, in the bustle of building and settling down, Pahóm was pleased with it all, but when he got used to it he began to think that even here he had not enough land. The first year, he sowed wheat on his share of the Communal land, and had a good crop. He wanted to go on sowing wheat, but had not enough Communal land for the purpose, and what he had already used was not available; for in those parts wheat is only sown on virgin soil or on fallow land. It is sown for one or two years, and then the land lies fallow till it is again overgrown with prairie grass. There were many who wanted such land, and there was not enough for all; so that people quarreled about it. Those who were better off, wanted it for growing wheat, and those who were poor, wanted it to let to dealers, so that they might raise money to pay their taxes. Pahóm wanted to sow more wheat; so he ​rented land from a dealer for a year. He sowed much wheat and had a fine crop, but the land was too far from the village—the wheat had to be carted more than ten miles. After a time Pahóm noticed that some peasant-dealers were living on separate farms, and were growing wealthy; and he thought:

‘If I were to buy some freehold land, and have a homestead on it, it would be a different thing, altogether. Then it would all be nice and compact.’

The question of buying freehold land recurred to him again and again.

He went on in the same way for three years; renting land and sowing wheat. The seasons turned out well and the crops were good, so that he began to lay money by. He might have gone on living contentedly, but he grew tired of having to rent other people’s land every year, and having to scramble for it. Wherever there was good land to be had, the peasants would rush for it and it was taken up at once, so that unless you were sharp about it you got none. It happened in the third year that he and a dealer together rented a piece of pasture land from some peasants; and they had already plowed it up, when there was some dispute, and the peasants went to law about it, and things fell out so that the labor was all lost.

‘If it were my own land,’ thought Pahóm, ‘I should be independent, and there would not be all this unpleasantness.’

So Pahóm began looking out for land which he could buy; and he came across a peasant who had bought thirteen hundred acres, but having got into difficulties was willing to sell again cheap. Pahóm bargained and haggled with him, and at last they settled the price at 1,500 rubles, part in cash and part to be paid later. They had all but clinched the matter, when a passing dealer happened to stop at Pahóm’s one day to get a feed for his horse. He drank tea with Pahóm, and they had a talk. The dealer said that he was just returning from the land of the Bashkírs, far away, where he had bought thirteen thousand ​acres of land all for 1,000 rubles. Pahóm questioned him further, and the tradesman said:

‘All one need do is to make friends with the chiefs. I gave away about one hundred rubles’ worth of dressing-gowns and carpets, besides a case of tea, and I gave wine to those who would drink it; and I got the land for less than twopence an acre\[3\]. And he showed Pahóm the title-deeds, saying:

‘The land lies near a river, and the whole prairie is virgin soil.’

Pahóm plied him with questions, and the tradesman said:

‘There is more land there than you could cover if you walked a year, and it all belongs to the Bashkírs. They are as simple as sheep, and land can be got almost for nothing.’

‘There now,’ thought Pahóm, ‘with my one thousand rubles, why should I get only thirteen hundred acres, and saddle myself with a debt besides? If I take it out there, I can get more than ten times as much for the money.’

Pahóm inquired how to get to the place, and as soon as the tradesman had left him, he prepared to go there himself. He left his wife to look after the homestead, and started on his journey taking his man with him. They stopped at a town on their way, and bought a case of tea, some wine, and other presents, as the tradesman had advised. On and on they went until they had gone more than three hundred miles, and on the seventh day they came to a place where the Bashkírs had pitched their tents. It was all just as the tradesman had said. The people lived on the steppes, by a river, in felt-covered tents\[4\]. They neither tilled the ground, nor ate bread. Their cattle and horses grazed in herds on the steppe. The colts were tethered ​behind the tents, and the mares were driven to them twice a day. The mares were milked, and from the milk kumiss was made. It was the women who prepared kumiss, and they also made cheese. As far as the men were concerned, drinking kumiss and tea, eating mutton, and playing on their pipes, was all they cared about. They were all stout and merry, and all the summer long they never thought of doing any work. They were quite ignorant, and knew no Russian, but were good-natured enough.

As soon as they saw Pahóm, they came out of their tents and gathered round their visitor. An interpreter was found, and Pahóm told them he had come about some land. The Bashkírs seemed very glad; they took Pahóm and led him into one of the best tents, where they made him sit on some down cushions placed on a carpet, while they sat round him. They gave him tea and kumiss, and had a sheep killed, and gave him mutton to eat. Pahóm took presents out of his cart and distributed them among the Bashkírs, and divided among them the tea. The Bashkírs were delighted. They talked a great deal among themselves, and then told the interpreter to translate.

‘They wish to tell you,’ said the interpreter, ‘that they like you, and that it is our custom to do all we can to please a guest and to repay him for his gifts. You have given us presents, now tell us which of the things we possess please you best, that we may present them to you.’

‘What pleases me best here,’ answered Pahóm, ‘is your land. Our land is crowded, and the soil is exhausted; but you have plenty of land and it is good land. I never saw the like of it.’

The interpreter translated. The Bashkírs talked among themselves for a while. Pahóm could not understand what they were saying, but saw that they were much amused, and that they shouted and laughed. Then they were silent and looked at Pahóm while the interpreter said:

‘They wish me to tell you that in return for your ​presents they will gladly give you as much land as you want. You have only to point it out with your hand and it is yours.’

The Bashkírs talked again for a while and began to dispute. Pahóm asked what they were disputing about, and the interpreter told him that some of them thought they ought to ask their Chief about the land and not act in his absence, while others thought there was no need to wait for his return.

While the Bashkírs were disputing, a man in a large fox-fur cap appeared on the scene. They all became silent and rose to their feet. The interpreter said, ‘This is our Chief himself.’

Pahóm immediately fetched the best dressing-gown and five pounds of tea, and offered these to the Chief. The Chief accepted them, and seated himself in the place of honor. The Bashkírs at once began telling him something. The Chief listened for a while, then made a sign with his head for them to be silent, and addressing himself to Pahóm, said in Russian:

‘Well, let it be so. Choose whatever piece of land you like; we have plenty of it.’

‘How can I take as much as I like?’ thought Pahóm. ‘I must get a deed to make it secure, or else they may say, “It is yours,” and afterwards may take it away again.’

‘Thank you for your kind words,’ he said aloud. ‘You have much land, and I only want a little. But I should like to be sure which bit is mine. Could it not be measured and made over to me? Life and death are in God’s hands. You good people give it to me, but your children might wish to take it away again.’

‘You are quite right,’ said the Chief. ‘We will make it over to you.’

‘I heard that a dealer had been here,’ continued Pahóm, ‘and that you gave him a little land, too, and ​signed title-deeds to that effect. I should like to have it done in the same way.’

The Chief understood.

‘Yes,’ replied he, ‘that can be done quite easily. We have a scribe, and we will go to town with you and have the deed properly sealed.’

‘And what will be the price?’ asked Pahóm.

‘Our price is always the same: one thousand rubles a day.’

Pahóm did not understand.

‘A day? What measure is that? How many acres would that be?’

‘We do not know how to reckon it out,’ said the Chief. ‘We sell it by the day. As much as you can go round on your feet in a day is yours, and the price is one thousand rubles a day.’

Pahóm was surprised.

‘But in a day you can get round a large tract of land,’ he said.

The Chief laughed.

‘It will all be yours!’ said he. ‘But there is one condition: If you don’t return on the same day to the spot whence you started, your money is lost.’

‘But how am I to mark the way that I have gone?’

‘Why, we shall go to any spot you like, and stay there. You must start from that spot and make your round, taking a spade with you. Wherever you think necessary, make a mark. At every turning, dig a hole and pile up the turf; then afterwards we will go round with a plow from hole to hole. You may make as large a circuit as you please, but before the sun sets you must return to the place you started from. All the land you cover will be yours.’

Pahóm was delighted. It was decided to start early next morning. They talked a while, and after drinking some more kumiss and eating some more mutton, they had tea again, and then the night came on. They gave Pahóm a feather-bed to sleep on, and the Bashkírs dispersed for the night, promising to assemble the next ​morning at daybreak and ride out before sunrise to the appointed spot.

Pahóm lay on the feather-bed, but could not sleep. He kept thinking about the land.

‘What a large tract I will mark off!’ thought he. ‘I can easily do thirty-five miles in a day. The days are long now, and within a circuit of thirty-five miles what a lot of land there will be! I will sell the poorer land, or let it to peasants, but I’ll pick out the best and farm it. I will buy two ox-teams, and hire two more laborers. About a hundred and fifty acres shall be plow-land, and I will pasture cattle on the rest.’

Pahóm lay awake all night, and dozed off only just before dawn. Hardly were his eyes closed when he had a dream. He thought he was lying in that same tent, and heard somebody chuckling outside. He wondered who it could be, and rose and went out, and he saw the Bashkír Chief sitting in front of the tent holding his side and rolling about with laughter. Going nearer to the Chief, Pahóm asked: ‘What are you laughing at?’ But he saw that it was no longer the Chief, but the dealer who had recently stopped at his house and had told him about the land. Just as Pahóm was going to ask, ‘Have you been here long?’ he saw that it was not the dealer, but the peasant who had come up from the Volga, long ago, to Pahóm’s old home. Then he saw that it was not the peasant either, but the Devil himself with hoofs and horns, sitting there and chuckling, and before him lay a man barefoot, prostrate on the ground, with only trousers and a shirt on. And Pahóm dreamed that he looked more attentively to see what sort of a man it was lying there, and he saw that the man was dead, and that it was himself! He awoke horror-struck.

‘What things one does dream,’ thought he.

Looking round he saw through the open door that the dawn was breaking.

​’It’s time to wake them up,’ thought he. ‘We ought to be starting.’

He got up, roused his man (who was sleeping in his cart), bade him harness; and went to call the Bashkírs.

‘It’s time to go to the steppe to measure the land,’ he said.

The Bashkírs rose and assembled, and the Chief came, too. Then they began drinking kumiss again, and offered Pahóm some tea, but he would not wait.

‘If we are to go, let us go. It is high time,’ said he.

The Bashkírs got ready and they all started: some mounted on horses, and some in carts. Pahóm drove in his own small cart with his servant, and took a spade with him. When they reached the steppe, the morning red was beginning to kindle. They ascended a hillock (called by the Bashkírs a shikhan) and dismounting from their carts and their horses, gathered in one spot. The Chief came up to Pahóm and stretched out his arm towards the plain:

‘See,’ said he, ‘all this, as far as your eye can reach, is ours. You may have any part of it you like.’

Pahóm’s eyes glistened: it was all virgin soil, as flat as the palm of your hand, as black as the seed of a poppy, and in the hollows different kinds of grasses grew breast high.

The Chief took off his fox-fur cap, placed it on the ground and said:

‘This will be the mark. Start from here, and return here again. All the land you go round shall be yours.’

Pahóm took out his money and put it on the cap. Then he took off his outer coat, remaining in his sleeveless under coat. He unfastened his girdle and tied it tight below his stomach, put a little bag of bread into the breast of his coat, and tying a flask of water to his girdle, he drew up the tops of his boots, ​took the spade from his man, and stood ready to start. He considered for some moments which way he had better go—it was tempting everywhere.

‘No matter,’ he concluded, ‘I will go towards the rising sun.’

He turned his face to the east, stretched himself, and waited for the sun to appear above the rim.

‘I must lose no time,’ he thought, ‘and it is easier walking while it is still cool.’

The sun’s rays had hardly flashed above the horizon, before Pahóm, carrying the spade over his shoulder, went down into the steppe.

Pahóm started walking neither slowly nor quickly. After having gone a thousand yards he stopped, dug a hole, and placed pieces of turf one on another to make it more visible. Then he went on; and now that he had walked off his stiffness he quickened his pace. After a while he dug another hole.

Pahóm looked back. The hillock could be distinctly seen in the sunlight, with the people on it, and the glittering tires of the cartwheels. At a rough guess Pahóm concluded that he had walked three miles. It was growing warmer; he took off his under-coat, flung it across his shoulder, and went on again. It had grown quite warm now; he looked at the sun, it was time to think of breakfast.

‘The first shift is done, but there are four in a day, and it is too soon yet to turn. But I will just take off my boots,’ said he to himself.

He sat down, took off his boots, stuck them into his girdle, and went on. It was easy walking now.

‘I will go on for another three miles,’ thought he, ‘and then turn to the left. The spot is so fine, that it would be a pity to lose it. The further one goes, the better the land seems.’

He went straight on for a while, and when he looked round, the hillock was scarcely visible and the people on it looked like black ants, and he could just see something glistening there in the sun.

‘Ah,’ thought Pahóm, ‘I have gone far enough in ​this direction, it is time to turn. Besides I am in a regular sweat, and very thirsty.’

He stopped, dug a large hole, and heaped up pieces of turf. Next he untied his flask, had a drink, and then turned sharply to the left. He went on and on; the grass was high, and it was very hot.

Pahóm began to grow tired: he looked at the sun and saw that it was noon.

‘Well,’ he thought, ‘I must have a rest.’

He sat down, and ate some bread and drank some water; but he did not lie down, thinking that if he did he might fall asleep. After sitting a little while, he went on again. At first he walked easily: the food had strengthened him; but it had become terribly hot, and he felt sleepy; still he went on, thinking: ‘An hour to suffer, a life-time to live.’

He went a long way in this direction also, and was about to turn to the left again, when he perceived a damp hollow: ‘It would be a pity to leave that out,’ he thought. ‘Flax would do well there.’ So he went on past the hollow, and dug a hole on the other side of it before he turned the corner. Pahóm looked towards the hillock. The heat made the air hazy: it seemed to be quivering, and through the haze the people on the hillock could scarcely be seen.

‘Ah!’ thought Pahóm, ‘I have made the sides too long; I must make this one shorter.’ And he went along the third side, stepping faster. He looked at the sun: it was nearly half way to the horizon, and he had not yet done two miles of the third side of the square. He was still ten miles from the goal.

‘No,’ he thought, ‘though it will make my land lop-sided, I must hurry back in a straight line now. I might go too far, and as it is I have a great deal of land.’

So Pahóm hurriedly dug a hole, and turned straight towards the hillock.

​ Pahóm went straight towards the hillock, but he now walked with difficulty. He was done up with the heat, his bare feet were cut and bruised, and his legs began to fail. He longed to rest, but it was impossible if he meant to get back before sunset. The sun waits for no man, and it was sinking lower and lower.

‘Oh dear,’ he thought, ‘if only I have not blundered trying for too much! What if I am too late?’

He looked towards the hillock and at the sun. He was still far from his goal, and the sun was already near the rim.

Pahóm walked on and on; it was very hard walking, but he went quicker and quicker. He pressed on, but was still far from the place. He began running, threw away his coat, his boots, his flask, and his cap, and kept only the spade which he used as a support.

‘What shall I do,’ he thought again, ‘I have grasped too much, and ruined the whole affair. I can’t get there before the sun sets.’

And this fear made him still more breathless. Pahóm went on running, his soaking shirt and trousers stuck to him, and his mouth was parched. His breast was working like a blacksmith’s bellows, his heart was beating like a hammer, and his legs were giving way as if they did not belong to him. Pahóm was seized with terror lest he should die of the strain.

Though afraid of death, he could not stop. ‘After having run all that way they will call me a fool if I stop now,’ thought he. And he ran on and on, and drew near and heard the Bashkírs yelling and shouting to him, and their cries inflamed his heart still more. He gathered his last strength and ran on.

The sun was close to the rim, and cloaked in mist looked large, and red as blood. Now, yes now, it was about to set! The sun was quite low, but he was also quite near his aim. Pahóm could already see the people on the hillock waving their arms to hurry him up. He could see the fox-fur cap on the ground, and ​the money on it, and the Chief sitting on the ground holding his sides. And Pahóm remembered his dream.

‘There is plenty of land,’ thought he, ‘but will God let me live on it? I have lost my life, I have lost my life! I shall never reach that spot!’

Pahóm looked at the sun, which had reached the earth: one side of it had already disappeared. With all his remaining strength he rushed on, bending his body forward so that his legs could hardly follow fast enough to keep him from falling. Just as he reached the hillock it suddenly grew dark. He looked up—the sun had already set. He gave a cry: ‘All my labor has been in vain,’ thought he, and was about to stop, but he heard the Bashkírs still shouting, and remembered that though to him, from below, the sun seemed to have set, they on the hillock could still see it. He took a long breath and ran up the hillock. It was still light there. He reached the top and saw the cap. Before it sat the Chief laughing and holding his sides. Again Pahóm remembered his dream, and he uttered a cry: his legs gave way beneath him, he fell forward and reached the cap with his hands.

‘Ah, what a fine fellow!’ exclaimed the Chief. ‘He has gained much land!’

Pahóm’s servant came running up and tried to raise him, but he saw that blood was flowing from his mouth. Pahóm was dead!

The Bashkírs clicked their tongues to show their pity.

His servant picked up the spade and dug a grave long enough for Pahóm to lie in, and buried him in it. Six feet from his head to his heels was all he needed.

February 18, 2025 · [coffee](https://rnikhil.com/tag/coffee), [ice](https://rnikhil.com/tag/ice)

## Evaluating AI Agents
## Quick thoughts on evaluating agents

I recently encountered some companies which are in the due diligence and report generation space. They all use a multitude of AI agents to plan and do the research and this made me wonder how these agent stacks are evaluated.

Primarily we can simplify AI agents to be nothing but LLMs + tool use + some logic flows which might be controlled by an LLM. While evaluating these agents, we are primarily concerned about:

- Are they saying the right things?
- Are they acting the right way?

Do they say the right thing? - What does it mean?

- This is primarily evaluating the textual output of the systems. I have written a lot about evaluating LLM outputs for safety, consistency, hallucinations(RAG and otherwise), compliance and any custom policies. This is a fairly well known topic and you can refer to my older blogs for that.
- Do bear in mind that some of these agents could be running in a loop and we will also have to think about evaluating a multi-turn agent too. Here we have to consider things like
  - Conversation consistency - is the agent keeping up with relevance scores in a multi turn conversation? Is it consistent with the facts used across all the turns? Is it adhering to the topic and is it reasoning well? You will basically have to construct a compound metric from the single turn step to measure this.

Are they acting the right way? - What does that mean?

- Are they following the instruction loop and logic related to the usecase?
- Are they using the right parameters and inputs for calling the tools? Are they selecting the correct tool consistently and accurately? How is it handling errors with tool calling(ex: structure/format issues) and instruction loops? Does it fail gracefully?
- Multi step considerations:
  - Is the agent breaking down the task sensibly? Is each individual task progressing and helping the agent achieve the goal? Is the plan devised by the agent of high quality and aligns with the use case?

**Real life evaluation considerations:**

- First, you need to break down your AI application into logical components and define metrics to measure the items mentioned above. While there are a lot of pre-defined metrics available for the first part (how does the LLM talk), you need to come up with internal task-specific and tool-specific metrics for the second part. Ultimately, evaluating agents are very similar to evaluating any LLM system. All the outputs must be grounded in reality and compliant. Every action of the LLM system must be accurate and the ultimate metrics of this agent system will be its goal completing rate.
- Set up a tracing/debugging stack to observe the inputs/outputs of each LLM component. Make sure error management is baked in. Lot of the agent stacks have a “replay” feature which will help run simulations of your agent stack.
- Start thinking about cost and latencies too. You want to serve your stack as fast as possible and as cheaply as possible. While this won’t matter in the early days, this will definitely start rearing its ugly face as soon as you scale.

February 27, 2025 · [LLMs](https://rnikhil.com/tag/LLMs), [evals](https://rnikhil.com/tag/evals), [AI](https://rnikhil.com/tag/AI), [agents](https://rnikhil.com/tag/agents)

## Diffusion Models Overview
## Diffusion models are interesting

> [HN Discussion](https://news.ycombinator.com/item?id=43285726)

I stumbled across [this](https://x.com/InceptionAILabs/status/1894847919624462794) tweet a week or so back where this company called Inception Labs released a Diffusion LLM (dLLM). Instead of being autoregressive and predicting tokens left to right, here you start all at once and then gradually come up with sensible words simultaneously (start/finish/middle etc. all at once). Something which worked historically for image and video models is now outperforming similar-sized LLMs in code generation.

- The company also claims 5-10x improvement across speed and efficiency

![](https://rnikhil.com/assets/files/inceptionlabs.png)

### Why are they interesting to me?

After spending the better part of the last 2 years reading, writing, and working in LLM evaluation, I see some obvious first-hand benefits for this paradigm:

**Traditional LLMs hallucinate.** It’s like they are confidently spitballing text while actually making up facts on the go. This is why they start sentences super confidently sometimes only to suggest something stupid in the end. dLLMs can generate certain important portions first, validate it, and then continue the rest of the generation.

- Ex: A CX chatbot would first generate the policy version number, validate it before advising a customer about a potentially hallucinated policy.

**Agents might get better.** Multi-step agentic workflows may not get stuck in loops using dLLMs. Planning, reasoning, and self-correction are a crucial part of agent flows, and we might currently be [bottlenecked](https://x.com/ylecun/status/1702027572077326505) due to the LLM architecture. dLLMs could solve for this by ensuring that the entire plan top to bottom stays coherent. It’s like seeing ahead in the future for a little bit (based on whatever context you have) and then ensuring you don’t get stuck.

Here is a look at a more recent [model](https://arxiv.org/abs/2502.09992) responding to the prompt “Explain Game theory” to me. You can notice the last part of the sentences are generated before the middle. It’s quite fun to run some queries and see which words get generated first.

![](https://rnikhil.com/assets/files/hfgif.gif)

You can try it yourself here on [HF](https://huggingface.co/spaces/multimodalart/LLaDA).

March 6, 2025 · [Diffusion](https://rnikhil.com/tag/Diffusion), [evals](https://rnikhil.com/tag/evals), [dLLMs](https://rnikhil.com/tag/dLLMs), [agents](https://rnikhil.com/tag/agents), [hallucination](https://rnikhil.com/tag/hallucination)

## Investing in Tech Cycles
## Quick thoughts on investing during tech cycles

> I was recently asked to put together a thesis on the AI agent tooling space. While I was researching the sector, talking to some VCs and looking at approaches taken by various companies, I decided to take a step back and question myself on whether the tooling+infra space is investable today in the first place. This short post is the result of that pondering.

Generally for any tech cycle, we can categorize all the companies into one of the three buckets below. They are either making the tech or building around the tech to monetize it or using/applying the tech for real world use cases.

**Foundation companies**

These are the companies which lay the foundation for the tech wave. This would be semi-conductors or network switch hardware or foundational models in case of AI or even L1 chains in case of crypto. Companies here are usually very capital intensive, needs heavy technical expertise and generally takes a long time to pan out. While its debatable on whether these companies would get commoditized, they certainly delivery big venture outcomes and are generally good bets if your fund can afford it.

**Builder companies**

These are companies which are building the tooling and infrastructure around the tech wave. This could be something like an observability/monitoring layer or low-code AI agent builders or evaluation tools or inference clouds. This is the so called picks and shovels of the gold rush and investing in this space gets you directional exposure to the tech cycle without getting you into investments which rely upon a particular way the tech cycle will pan out (maybe good for risk-averse investors).

My biggest concern with investing in this space is that these companies are building on a tech cycle which hasn’t stabilized. The application stack hasn’t yet figured out all the use cases for the technology and the foundation companies are innovating and putting out new tech everyday. Sometimes, entire building paradigms change overnight. (Imagine hallucinations get solved and AI models become interpretable and are no longer black boxes. All LLM eval tooling companies would have a bad time)

**Application companies**

These are companies which actually use the technology to solve pain points for customers. I think there are two types of companies which will emerge here. Existing companies which adopt the tech into their products and new companies which use this tech to delivery experiences which weren’t possible before.

For this cycle, existing note taking apps, CRM tools, project management tools, HR SaaS etc (by Google or Freshdesk) are going to supercharge their products with AI and they would win or retain the lead in most categories given they have the distribution and data already. It not that hard for Rippling or Salesforce to put an LLM behind all user interactions. What is interesting to me here are companies which are enabling entirely new experiences (not just powered by AI) which without AI wasn’t possible earlier. (like replacing a Mckinsey consultant or a paralegal at a law firm or sending $10k to a friend without banks getting involved). I am extremely bullish on the latter type of companies and quite excited to see what pans out.

March 10, 2025 · [investing](https://rnikhil.com/tag/investing), [vc](https://rnikhil.com/tag/vc), [markets](https://rnikhil.com/tag/markets)

## Introduction to AI Agents
## Introduction to AI agents

> This is the first couple pages of a report I worked on about AI agents.

### What are “AI Agents”?

In this section, we try to define what an agentic system is. Automation software(like email to calendar booking tools) are generally oversold as agentic systems and it’s important to ensure we all have the same understanding of the lingo used in this space.

Peter Norvig in his popular [book](https://www.amazon.in/Artificial-Intelligence-Modern-Approach-Prentice/dp/0136042597) defines an agent as anything that can perceive its environment and act upon that environment. A thermostat is an agent. A motion sensor light or smoke detector is also an agent. However, these are all dumb agents. We are more interested in building intelligent agents with LLM/AI as its core controller.

Interestingly, the definition of the term “AI agents” is [hotly](https://x.com/NickADobos/status/1714065139878482030) contested. Most of the common ones involve some version of putting LLMs + tools in a loop. Rather than looking at LLM systems in a binary way, it’s more useful to think of them to be agent-like to a different degree. The degree of control given to the LLM in guiding an application’s flow allows for varying levels of autonomy, which we shall call agentic. This helps us move away from the binary classification of systems and look at them as part of a spectrum. Ultimately, you want to give it a task and the AI is agentic enough to go and accomplish it.

![](https://rnikhil.com/assets/files/agentspectrum.png)

### What are the different types of AI agents?

Since we have established that all LLM+tool powered systems are agentic on some level, we need to first classify the different types of agents. Borrowing the definition from \[Anthropic\](https://www.anthropic.com/research/building-effective-agents, we have two types of agentic systems.

Workflow agents are systems which are built by chaining together LLMs and tools which then are orchestrated through pre-defined code paths

Types of workflow agents:

- **Prompt chaining**, e.g. generating a document and then translating it to a separate language as a second LLM call. Real-world applications include marketing (drafting then localizing content), content creation (outlining then writing) or basic data analysis (cleaning then visualizing)
- **Routing**, where an initial LLM call decides which model or call should be used next (sending easy tasks to Haiku and harder tasks to Sonnet, for example). Can be used in customer service (sending different query types to specialized handlers)
- **Parallelization**, where a task is broken up and run in parallel (e.g. image-to-text on multiple document pages at once) or processed by some kind of voting mechanism. Parallelization is effective when the divided subtasks can be parallelized for speed, or when multiple perspectives or attempts are needed for higher confidence results
- **Orchestrator-workers**, where a orchestrator triggers multiple LLM calls that are then synthesized together, for example running searches against multiple sources and combining the results or in coding tools where the agent is making changes to multiple files at the same time
- **Evaluator-optimizer**, where one model checks the work of another in a loop and starts a feedback loop. This architecture is useful in scenarios where you need a second LLM to ensure the response is complete and correct

![](https://rnikhil.com/assets/files/workflowagent.png)

Autonomous agents are systems where the LLM dynamically directs the execution path and tool usage and maintain full ownership on how they accomplish the task. They have no predefined paths to take. They start their flow from a simple command or conversation with the user, plan the task and use tools to accomplish the task. They might choose to ask humans for feedback or when encountering blockers and automatically terminate themselves when the task is completed.

![](https://rnikhil.com/assets/files/autoagent.png)

They are particularly useful for open-ended tasks where it’s hard to predict beforehand the number of steps required and where you can’t really hard code a fixed path. Some real world applications include CX agents which, based on the user conversation, automatically decide to access customer data and perform actions like issuing refunds and updating ticket statuses. In software development, coding autonomous agents are excellent because the solutions are verifiable, agents can iterate based on feedback from automated tests and the problem space is well defined

Workflow agents in general are more predictive, consistent, cheap and fast whereas the autonomous agents generally excel in complex tasks where you need flexibility at scale.

### Architecture of autonomous agents

Before we jump into the tooling and infrastructure world for AI agents, it’s imperative to understand what exactly they are made of. While the LLM functions as the core brain, its complemented with some key components:

- **Planning and reasoning:** Breaking down tasks into subtasks, self reflecting on the progress, and iteratively improving the action plan
- **Memory:** Both short term memory (in context learning frameworks like MemGPT) and long term memory like a vector store
- **Tool use:** The LLM is trained to call external tools for tasks it can’t do by itself like pulling up current information or executing code

![](https://rnikhil.com/assets/files/archagent.png)

#### Why did they blow up in 2024?

The LLM functions as the agent’s brain and agents typically require much powerful and bigger models compared to non-agentic use cases. This is because mistakes in multi step tasks get compounded. If an LLM is accurate, say 90% on a single step, this accuracy drops to 35% over 10 steps(0.9^10) and 12% over 20 steps. Smaller LLMs (and LLMs not trained on agentic flows) are simply unfeasible for these use cases.

Lot of core frameworks for agent planning were invented in 2022 and 2023. [CoT](https://arxiv.org/abs/2201.11903) or [Tree of thoughts](https://arxiv.org/abs/2305.10601) for example are standard prompting techniques for enhancing model performance on complex tasks. This forces the model to spend more test time compute in thinking step by step and break down big tasks into multiple smaller subtasks. Even self reflection frameworks (like [ReACT](https://arxiv.org/abs/2210.03629)) were invented in 2023 which help the LLM improve iteratively by refining past actions and correcting previous mistakes.

#### An action sequence of a simple multi step agent

Lets consider a scenario where you ask your AI data analytics agent this question - “Analyze customer churn rates for our app subscribers”. This might make it go and perform the following:

- Reason about how to accomplish this task. It might decide that to analyze churn, it first needs historical subscriber data.
- Invoke data retrieval to get subscriber counts over the past year. (Text to SQL)
- Invoke data processing to calculate monthly retention and churn percentages. (Code execution)
- Reason about the initial findings and determine that user engagement metrics might provide valuable context for why customers are churning.
- Invoke additional data retrieval to obtain app usage frequency and session duration. (Text to SQL)
- Invoke statistical analysis to identify relationships between usage patterns and churn.(Code execution)
- Generate visualizations and insights about churn trends, highlighting key segments with highest churn risk. (Code execution)
- Reason that the task has been successfully completed with actionable recommendations to reduce churn.

### When and where are AI agents used?

The value add for agents is clear. Copilot was [40% of github revenue](https://virtualizationreview.com/Articles/2024/07/31/copilot-numbers.aspx) last year. Klarna AI agent handles 65% of the CX queries end-to-end. In this section, we look at ideal use cases and tasks for deploying AI agents.

While we have briefly looked at which agent architecture works for which kind of flows, we should also define what makes a task agentic vs non-agentic.

![](https://rnikhil.com/assets/files/agenttask.png)

A market map from [Felicis](https://www.felicis.com/) showing some early winners in the AI agents space

![](https://rnikhil.com/assets/files/marketmapagents.png)

- Customer service
  - AI agents analyze call data, manage chatbots, and handle complete support workflows autonomously from greeting to resolution, including processing refunds by checking orders and updating inventory without human intervention.
  - Ex: [Decagon](https://decagon.ai/), [Sierra](https://sierra.ai/) , [Maven AGI](https://www.mavenagi.com/), [DevRev](https://devrev.ai/) and [Gradient Labs](https://gradient-labs.ai/)
- Software development
  - AI agents assist developers by automating code generation, debugging, quality assurance, and documentation creation. They can analyze codebases to identify potential bugs, suggest optimizations, generate unit tests, and maintain documentation as code evolves
  - Ex: [Factory AI](https://www.factory.ai/) and [Cognition](https://www.cognition.ai/)
- Research & Knowledge Work
  - Agents gather information from trusted sources, summarize findings, format citations, and produce detailed reports
  - Ex: DeepResearch from OpenAI, [Reflections](https://www.reflection.ai/) , [Sema4](https://sema4.ai/) for financial back office work, [NormAI](https://www.norm.ai/) for compliance reporting
- Agent platforms are also performing well in other industries; ex: [11x](https://www.11x.ai/) is augmenting SDRs with better lead-gen, [Jasper](https://www.jasper.ai/) is solving for marketing/copyright use cases, [Mercor](https://mercor.com/) is solving the match problem in recruiting, [Abridge](https://www.abridge.com/) in healthcare, [Harvey](https://www.harvey.ai/) for legal workloads, or [Crescendo](https://crescendo.ai/) for contact centers.

March 14, 2025 · [ai](https://rnikhil.com/tag/ai), [agents](https://rnikhil.com/tag/agents)

## MCP Standard Overview
## Will MCP stay for the long term?

[MCP](https://modelcontextprotocol.io/introduction) is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools. Based on the context, AI agents can decide which tools to use, in what order, and how to chain them together to accomplish a task. MCP also introduced a human-in-the-loop capabilities for humans to provide additional data and approve execution. With the right set of MCP servers, users can turn every MCP client into an “everything app.”

![](https://rnikhil.com/assets/files/mcp.jpg)

MCP took inspiration from the Language Server Protocol (LSP), where typing in an editor can trigger the editor to query the language server(usually an extension) for autocomplete suggestions, function definitions or linting. MCP is more LLM centric and execution focused for agents. LSP is mostly reactive(server only reacts to inputs) whereas MCP is designed for multi-step autonomous workflows (automatically decide which tools to use and the sequence of usage).

Another way to look at MCP is as a TCP/IP layer for agent communication. It replaces custom API connectors with a uniform MCP standard and enables you to connect your LLM to anything. It reduces development effort (write custom code for each API vs Connect to pre-built MCP servers), helps in context Management(manually maintain context between calls vs protocol maintains session context automatically) and error Handling (handle each API’s unique error patterns vs standardized error handling across services). This post is about whether MCP as a standard will stay and whether dev tools companies will build around it.

I see two kind of worlds. An Apple like closed ecosystem where there are proprietary ways for AI agents to interact with tools/resources (which OpenAI is pursuing) and an Android type situation where you have open standards (which the tools/apps etc will support) and everybody builds on top. I believe both of them will co-exist but we are mainly concerned with whether MCP will exist in the latter world.

The biggest bull case for MCP is the adoption momentum today. The spec is evolving super fast, it came with 100s of example implementations by the AI labs itself and its super easy to implement (basic HTTP rest api types and its just a standard for the explanation of the parameters and tools for any client ), so we have crazy developer engagement. Its also one of the first LLM specific API standard. First mover matters in standards (ex: we are still stuck with BGP for internet routing depsite its numerious flaws)

#### What do we need for MCP to win?

- Discovery and a central registry. One of the biggest value add is being able to auto discover all possible tools (within one api) by just asking in english and dynamically load them (instead of predefining/loading) at runtime. This doesn’t exist yet but people are building them (like composio/agentr.dev etc). There are talks about an “Official MCP registry API” but its just on the roadmap now. There are 10s of independent server aggregators though. This will also give rise to MCP gateways which manage authentication, authorization, traffic management, and tool selectionm, similar to API gateways.

- I think hosted MCP companies make more sense than self hosting. Else, you will have to implement the MCP middleman and then also manage server executions/functions. At that point, you might as well implement the custom api yourself.

- Composability through MCP-MCP interactions. (there is an active github issue where people are working on this). Not very realistic today because multi step agent behavior is still hard to get right. MCP’s error handling and propagation should improve in this direction. \*\*There is no concept of a state model to manage multi step executions. \*\*

- Enterprise adoption is sketchy. Servers haven’t been tested at scale yet. Authentication/rbac isn’t standardised(but there is an oauth implementation) and the protocol is still adding support for them. There is no defined way to do observability/logging either and you need to come up with your own implementation. MCP server companies primarily differentiate in how opinionated they implement these things.

- MCP needs better support for multi-tenant architectures where many users access a shared server. Currently there is a one-to-many relationship between clients and servers but this has to evolve into many-to-many for enterprise adoption.

- Authorization states aren’t baked into the protocol. There is no concept of a permission model and access control is usually at a session level.


![](https://rnikhil.com/assets/files/mcp1.jpg)

#### Bottomline

- Standards generally win only because some dev tools company adopts it and becomes successful. MCP is winning only because Anthropic nailed the claude fine tune to do multi step agent calls. Today you can ask claude something ( like analyse churn) and it will automatically execute sequential tool calls and return final result. This UX just wasn't possible before(without coding it yourself)
- It’s like openapi(which is for REST apis) but specialized for ai agents. While there is a lot of overlap, after looking at the basic filesystem mcp server implementation, I think they made it a little more LLM specific. (Ex: server broadcasts in “English” what the tools do and how to call them)
- I personally use the MCP servers because it lets me do more with a $20 subscription(like tool use inside claude). Earlier I needed an api key(which is more expensive ) and custom code. I download mcp servers like from an app store and make my claude desktop agentic (without writing any code)
- MCP doesn’t make sense in closed systems. (like openai)
- MCP needs hosted MCP server companies to win. Else, its just adds more complexity
- Composability(due to standardization) and discovery are the biggest value adds. Composability isnt unique to it but a MCP registry for discovery will be interesting. Appstore for LLMs sort of thing.

#### Future predictions for the MCP stack

- If every software is basically AI powered, then every software potentially becomes a MCP client.
- Interactions go from being API-centric to task-centric. Instead of hard coding tools into control flows, we will see tools become higher abstractions that make sense for agents at execution time
- I expect a lot of MCP servers getting [spawned](https://mintlify.com/blog/generate-mcp-servers-for-your-docs) from documentation of tools. Docs will become super important
- Pricing models for tools might change. If agent picks dynamically based on speed, cost, and relevance, how do you ensure your tool gets adoption in the marketplace? This will be super interesting to watch

March 26, 2025 · [ai](https://rnikhil.com/tag/ai), [agents](https://rnikhil.com/tag/agents), [MCP](https://rnikhil.com/tag/MCP), [protocol](https://rnikhil.com/tag/protocol)

## GSoC 2016 Proposal
# Google Summer of Code 2016 Proposal LabLua

Name: Nikhil. R Email: [rnikhil96@outlook.com](mailto:rnikhil96@outlook.com) , [rnikhil2751996@gmail.com](mailto:rnikhil2751996@gmail.com)

# BASICS

# 1) What is your preferred e-mail address?

E-mail 1: [rnikhil96@outlook.com](mailto:rnikhil96@outlook.com) E-mail 2: [rnikhil2751996@gmail.com](mailto:rnikhil2751996@gmail.com)

# 2) What is your web page / blog / GitHub?

Blog: [http://rnikhil275.github.io/](http://rnikhil275.github.io/)

Resume: [http://rnikhil275.github.io/assets/Nikhil.%20R-%20Resume.pdf](http://rnikhil275.github.io/assets/Nikhil.%20R-%20Resume.pdf) GitHub: [https://github.com/rnikhil275/](https://github.com/rnikhil275/)

StackOverflow: [http://stackoverflow.com/users/4379159/rnikhil275](http://stackoverflow.com/users/4379159/rnikhil275) The blog is still under construction. Will start posting once GSoc starts.

# 3) What is your academic background?

Third year undergraduate at Birla Institute of Technology and Science Pilani, Pilani Campus, India studying Dual degree in M.Sc (Hons.) Economics and B.E Manufacturing Engineering

4. What other time commitments, such as school work, another job (GSoC is a full-time activity!), or planned vacations will you have during the period of GSoC?

I'm completely free from May 23 to August 23. I have no other commitments/jobs. I may take one or two day break which will be informed ahead in time. I will work every day and hence can easily target about 50 hours a week.

# Experience

1. What programming languages are you fluent in? Which tools do you normally use for development?

I am quite proficient in PHP, Python, Lua, JavaScript, and C. I can also program in Ruby and Erlang but would require some googling. I use Ubuntu (15.10) with LXDE on top as my main OS but I also boot into windows for domain specific work. I work in terminal most of the time and my preferred choice of text editor is Sublime Text with minor edits done using nano. I use Git for version control.

# 2) Are you familiar with the Lua programming language? Have you developed any projects using Lua?

Yes, I am familiar with Lua programming language. I can use most of the features of the language like tables, metatables effectively. I am new to the community and I have started work on the following projects:

Sailor-admin center: [https://github.com/rnikhil275/sailor-admin](https://github.com/rnikhil275/sailor-admin) Luagoogle: [https://github.com/rnikhil275/luagoogle](https://github.com/rnikhil275/luagoogle) Sailor: [https://github.com/rnikhil275/sailor](https://github.com/rnikhil275/sailor)

I am also trying to contribute to the Sailor project by solving issues. Apart from this, I have also written a few scripts for my campus $\\mathsf{D C}++$ client.

# 3) Have you developed software in a team environment before? Any projects with actual users?

Yes, I have lot of experience developing software in teams before. I was part of an organization called SSMS (Student Society for Mess Services) in my second year and we were responsible for managing the mess accounts of 4500 students. I was also part of a startup (as the backend developer). I also interned at Vedanta Resources last summer where we worked on automating a bunch of data collection and logging system. These projects have actual users.

1. What kinds of projects/software have you worked on previously? (Anything larger than a class project: academic research, internships, freelance, hobby projects, etc.)

# SSMS Portal : ( [https://github.com/SSMS-Pilani](https://github.com/SSMS-Pilani) )

It’s a government registered organization responsible for development and maintenance of Billing and Inventory Management System used in all the BITS Pilani messes and all night canteen. I co-wrote the backend and the web interface for the website and also helped in the development of the software run on messes itself. All billing through the ID card system are managed on this portal and every month end this data is organized and sent to the institute for processing. The website is live on our intranet. Tech Used: PHP, MySQL

It the backend for a telemedicine startup which I built. It’s a doctor patient management system with features like appointment booking, video call etc. The backend is a REST API which interacts with the Angularjs frontend using JSON. I used SlimPHP for the routing, MySQL for the database, Redbeans for the ORM layer and Apache for the server. It also has a signaling server for the WebRTC module which is written in Erlang.

# Protocol Development (CEERI Pilani) : (Code not on the internet)

I worked under Mr. Solomon Raju, a scientist in Central Electronics Engineering Research Institute to develop a function for the MAC layer of the protocol stack they are developing. I wrote a CSMS/CA (Carrier Sense multiple access with collision avoidance) function to send data from various nodes to the main node. It checks whether the main node is active (not in “rest” mode), not busy transferring data from other nodes and then starts sending data to the node. It also makes sure there is no packet loss. I wrote code on a simulator which then converts it to the architecture/assembly set of the underlying bread board and microprocessor.

StarMash : ( [https://github.com/rnikhil275/StarMash](https://github.com/rnikhil275/StarMash) )It’s similar to FaceMash (From “The Social Network” Movie) It was a fun project which scraps a bunch of photos from IMDB and pairs them up randomly for to be rated by the user. It uses Elo rating system and I used this algorithm ( [http://stackoverflow.com/questions/3848004/facemash-algorithm](http://stackoverflow.com/questions/3848004/facemash-algorithm) ). The site hosted from my laptop got around 1000 unique IP hits in 24 hours. The entire site is built in PHP hosted on an nginx server.

# Vedanta Resources : (Internship)

Vedanta Resouces ( [https://en.wikipedia.org/wiki/Vedanta\_Resources](https://en.wikipedia.org/wiki/Vedanta_Resources) ) is an aluminum/ power manufacturing company and it’s one of the biggest in the world. I interned with them during last summer as part of my institute’s Practice school program. I analyzed and automated a lot of internal review, data reporting and logging systems. Saved around 80 hours of manual labour monthly for the organization by setting up various cron jobs to collect data and assemble them in proper format. The entire code was written in Python with Flask and Python-excel packages like openpyxl, xlutils, etc.

I have done a bunch of other personal projects also which can found on my GitHub profile ( [https://github.com/rnikhil275/](https://github.com/rnikhil275/) )

2. ​In particular, are you (or have you been) involved with any open source development project? If so, briefly describe the project and the scope of your involvement.

Some of the projects above are open source. I haven’t contributed to any big open source organization but I do contribute to some small ones as seen on my GitHub profile.

# Project

1. Did you select a project from our list? If yes, which project did you select? Why did you choose this project? If you are proposing a project, give a description of your proposal, including the expected results.

Yes & No. I did not select Luagoogle and the admin center from the list but the integration of Sailor and Elasticsearch was selected from the list.

The reasons for selecting the projects are below. I decided to work on the Admin Center because it was the most beginner friendly project I found on the Sailor To Do list. I thought it would give me a decent understanding of working of the internals of Sailor framework.

I decided to work on the elasticsearch integration with sailor is because I found this to be a very realistic project which I found myself using in the future. The concepts of storing relational data in a search index effectively for faster searching can be taken further for the web applications I would be writing in the future. I felt I can learn the most by doing this and found it to be fun.

Luagoogle would be my first package in luarocks. Though it does a niche job, maintaining it with all the API changes, publishing it, would give me a experience which can be taken ahead for more complex projects in the future. I would learn about luarocks packaging, writing rockspecs, dependency management etc.

I found the Sailor community a good match for me and decided to work with them. They were quite helpful from the beginning and I would love to work with them on the project.

Sailor Project: [https://github.com/sailorproject/sailor](https://github.com/sailorproject/sailor) [http://sailorproject.org/](http://sailorproject.org/)

I have decided to do a three things and I will be explaining each one in detail

# A) Admin Center for the Sailor MVC framework.

I shall be referring to this as the base URL (base): [https://github.com/sailorproject/sailor/tree/master/src](https://github.com/sailorproject/sailor/tree/master/src)

Right now, there are a bunch of auto generator functions inside base/sailor/autogen.lua. They can be used after changing a setting in the conf file. At present this autogen function (after enabling it), given a table name generates the model and controller code for CRUD operations. They can later be accessed under $/?\\r=$ (controller name) route.

I want to build an entire admin app which encompasses these autogen functions inside it and also another feature for changing stuff in the configuration file itself.

First it will be another controller named admin in base/sailor/blank-app. There will also be corresponding models and views. This entire module would be disabled by default and the user must enter the admin username and password to enable it.

The access module will be used for the authentication purposes for the admin center. The session state would be maintained using the same module.( A future edit maybe be necessary after successful solving of [https://github.com/sailorproject/sailor/issues/58](https://github.com/sailorproject/sailor/issues/58) ). A user has to manually enable the admin module and set a password too. The access module’s hashing function would be used and the password would be authorized and verified. There would be all kind of standard checks during authorization. The username and password should not be same (like user: admin pass: admin), there would be checking for weak password. All this would be done before hashing and storing the password.

After authentication it will redirect to the dashboard where there would be options for making models and CRUD code. There would also be an option for editing the configuration file though it would require a restart of the server for changes to take effect. A logout option will also be available. The Web interface would be bootstrap using the signin class. It will look something like this ​ [https://getbootstrap.com/examples/signin/](https://getbootstrap.com/examples/signin/) . The data would be sent as a post request to the backend. The session state is maintained using the access module. Once logged in there would be HTML form for inputting the table name so that the corresponding model can be generated. The table has to be made beforehand. Once the model has been generated the CRUD functions can also be generated for the corresponding model. The code for all this is already available inside base/sailor/autogen.lua.

All these functions will be edited to check for auth so that they cannot be used by a non-admin user. The web interface for all this is also inside the autogen.lua file. Everything would be documented while the code is written itself.

Now coming on the conf file editing feature, it will basically be a huge HTML form will all the fields entered before (We know the conf file the user has). The present values will also be set as placeholders in the input boxes. The user after making changes should submit on which the changed values (can be found using js) would be replaced on. There will also be a small check to check the integrity of the values. The module used for this would be [https://github.com/sailorproject/valua](https://github.com/sailorproject/valua) .

The logout option destroys the session and the user has to signin again to access the dashboard. The user will be redirected the signin page again. The signing page also will have an option to redirect to index.lua.

# B) Integrate Elasticsearch-lua client into Sailor:

Right now, the elasticsearch-lua client works fine independently. The aim of this project is to accomplish exporting the models used in the particular application to elasticsearch indexes so that they can be used inside the application namespace for searching. It’s would include elasticsearch-lua client library as a dependency.

The way the models are represented in the elasticsearch index depends entirely on the search use case scenario and this choice should be left to the user. This project would be focusing on implementing the necessary functions to achieve the above from inside sailor.

# Stage 1: Making connection to the elasticsearch index and exporting models to its indexes as documents.

The first month would be spent discussing with the mentor on various design cases and how the models should be indexed.

The above choice in implementing which way to search the data is left to the user.

The overall plugin (search model) would consist of a few modules. I will explain each one in detail here.

Connection Module :This module will basically deal with the elasticsearch-lua client by requiring it and then making connection to a node in the cluster. All the http methods will also be in our namespace for us to use. Now we can use the connection instance to store and modify data.

Index Module : This module will be used to index/store data into the elasticsearch index.

Client:index() of elasticsearch would be used. Again here, the use case would be dependent on the user as discussed above.

The models based on the present database structure will be stored as necessary in the elasticsearch index. The \_bulk endpoint can be used to store a lot of data in one go.

Indexing relational data in elasticsearch can be done in the following ways: 1) Indexing each row as a document

Each row in the table would be document with id corresponding the ‘id’ column name. 2) Indexing multiple rows as one document

This would first require a join of the tables and then storing the new table into the index. This is an example of a particular use case.

3) Indexing a set of columns as nested object

4) Indexing multiple nested objects per document

All four scenarios are explained in this page I found:

[http://voormedia.com/blog/2014/06/four-ways-to-index-relational-data-in-ela](http://voormedia.com/blog/2014/06/four-ways-to-index-relational-data-in-ela)

sticsearch

Appropriate methods would be made for all these four cases.

# Stage 2: Building the search and the form module.

Search Module: This module would be used for searching the indexes based on the query parameter. Various filter options can also be used to filter the data. The search endpoints in the elasticsearch-lua client shall be used. The result data would also be stored in a variable to be rendered using the page object.

Form Module: ​This is basically just another method in the already existing form module. Form.search(modelname, attributes, html\_options). The modelname to be searched for, the column names (attributes) to be searched under can be specified in the parameters. This will be used in the search module for applying filters.

# C) LuaGoogle:

This would be lua module for getting google search results programmatically. I already helped write a module named pygoogle for PyPi and the code for the same can be found here( [https://github.com/rnikhil275/pygoogle](https://github.com/rnikhil275/pygoogle) ) which does a similar job. It would be made in such a way that it can be imported into the application and the results can be programmatically obtained. It will use the google Ajax API. There would be few methods bundled with the module like

1. search() which returns a table with the results as key/value pairs where title is the key and the url is the value.
2. get\_urls() which returns a list of all the urls. It would just be an array 3) get\_result\_count() which returns the number of results
3. print\_resutls() Prints all the results $->$ for command line interpreter usage.

The number of pages to be retrieved, safe mode, number of results to be retrieved can also be set while making the request. Everything would also be logged. It will use lua sockets for making the http requests and a json parser (probably [https://github.com/grafi-tt/lunajson](https://github.com/grafi-tt/lunajson) )for obtaining the results as a object. This object can be used for all kinds of looping and searching through it. This object will also be used for formatted printing in command line usage and also for returning to the end user in a module usage.

The module would be used in places where google search results are necessary in the backend of the application and people want to loop through them. This would also be my first publication to luarocks.

I am new to the lua community and I was really amazed by the work of the people here. I have done simple things in lua before like writing a simple script to download a particular series whenever the magnet gets posted on main chat. I never got a chance to get involved with a community at this level before and I plan on staying and contributing to the Sailor/lua community in whatever way I can. If time permits, I would also want to work on

[https://github.com/sailorproject/sailor/issues/90](https://github.com/sailorproject/sailor/issues/90) and then make it easy for other developers to develop modules for the Sailor project (like user-login, etc.). It would enable to create an ecosystem like [http://www.yiiframework.com/extensions/](http://www.yiiframework.com/extensions/) .

The priority would be finish the admin center along with the elasticsearch module first, then luagoogle, and then work with Etiene on the above. I am a beginner who wants to get into open source so I feel writing documentation is also a good way to increase my knowledge of the framework. I would also like to make changes to docs of the Sailorproject. I found a few functions to be undocumented/some are outdated and I would also like to write a tutorial explaining lua and Sailor to be published on [http://lua.space/](http://lua.space/) . This tutorial would be beginner friendly tutorial to make a basic blog system in lua using Sailor.

# 2) Please provide a schedule with dates and important milestones/deliverables (preferably in two week increments).

The following below is a tentative timeline for developing admin center, the elasticsearch plugin and luagoogle.

![](https://rnikhil.com/tmp/cf5b1bec-7410-4608-8653-1c9d7523ed6a/images/6afdfd006df13754639c743f17587d43a2eed53f24983db0df12620ce5093196.jpg)

![](https://rnikhil.com/tmp/cf5b1bec-7410-4608-8653-1c9d7523ed6a/images/f69045b0e5933f00ce015081b4ca2017bbc106fc54337708982e0b0e82fd17cd.jpg)

![](https://rnikhil.com/tmp/cf5b1bec-7410-4608-8653-1c9d7523ed6a/images/bb4974103e32610d799bf2c84deedb0a5012f81bfb6b2c3e8b358381c2dbea46.jpg)

# 3) What will be showable two months into the project?

After the end of two months, the admin center would be ready and functional with tests and documentation. Elasticsearch will also be fully integrated with the Sailor framework and most kind of models could be indexed. User documentation for this would also be written. Luagoogle would also be published in luarocks.

# GSOC

1. Have you participated to GSoC before? If so, how many times, which year, which project?

No, I haven’t participated in GSoc before. 2) Have you applied but were not selected? When? Yes. I applied in 2015 to develop a simple Nodejs application which takes geolocation data through an endpoint and then plots it on a map using the google maps API. The project wasn’t selected but the application was finished in the first month itself.

3. Did you apply this year to any other organizations? No, I did not apply to any other organization. I really liked the community and decided to stick with them.

## Product Leader and Innovator
# Experience

DynamoAI (GenAI security and compliance platform backed by YC and Nexus) Jan 2024 – Oct 2024

Product Lead of DynamoEval - LLM Evaluation suite

•Led product strategy and development of DynamoEval, a suite for detecting hallucinations in your RAG pipeline, PII data leakage, toxicity, and jailbreak vulnerabilities. More details here .

•Architected and shipped features for tabular RAG evaluation, enabling customers to evaluate and improve their document retrieval systems with custom datasets

•Established product metrics and KPIs for measuring model security, including Attack Success Rate (ASR) benchmarking across different model types and datasets. Also built explainable RAG hallucination metrics. Details here .

•Built custom annotation workflows and dataset generation pipelines to improve model evaluation accuracy and coverage

# Paytm

Senior Product Manager Jan 2022 – Sep 2023 Bangalore

•Built and scaled Poker to $ 10M ARR and top 5 platform by liquidity in the country. Responsible for the entire product roadmap, strategy, and GTM. Launched new Poker formats, tournaments, and desktop platform •Growth levers : Launched the entire task center suite, enabling growth teams to run segmented engagement and retention campaigns thereby improving core revenue KPIs by $\\mathbf{10%}$ •Acquisition products : Researched and launched short form poker variants to widen TAM and reduce CAC, an automated tutorial bot (FTUE) for new users $&$ industry first features like Pot of Gold improving D7 conversion by ${\\bf6%}$ •Implemented an anti-fraud model reducing chip dumping and collusion fraud by 80%, skill based matchmaking algorithms and worked on the cross-game analytics charter to uncover user insights improving our D30 retention by $1.5%$

# GTOInspector.Poker

Co-founder

Apr 2020 – Nov 2021 India

•Post game analytics : Built and launched an interactive dashboard globally to help Poker players identify and fix their weak points by uploading hand data for analysis using our proprietary game theory optimal(GTO) solutions •The SaaS product and analytics tool combined generated over $\\mathbb{S}250\\mathrm{k}$ in lifetime revenue and was actively used by every PLO Poker professional in India. Coached and financed over 15 players using our proprietary software •Consulted and helped build products for leading gaming companies to combat fraud (multi-accounting, coin dumping, bonus abuse, collusion detection) and designed skill based algorithms for fairer and faster matchmaking

# Flipkart

Associate Product Manager 2 June 2018 – March 2020 Bangalore

•Fraud prevention: Built a rule based fraud prevention framework successfully identifying and preventing RTO frauds and account takeovers leading to $15%$ reductions in CX escalations

•Fintech: Researched and launched a late payment fee structure after A/B testing for the BNPL product leading to $\\mathbf{2.5%}$ increase in revenue without increase in NPA

•Data Platform: Defined and implemented an authentication and authorisation layer and defined access controls for the PII data of 100M users increasing security and reliability. Also built the data ingestion pipelines and analytics products

Google Summer of Code (twice)

Software developer 2016 – 2017 Remote

•Sailor Web Framework: Integrated Elasticsearch with Sailor and developed a real-time server config editor •HTTPS Library: Added support for HTTPS CONNECT Tunnel, HTTPS Redirects, SNI tests and HTTP/2 support for Luasec HTTP networking library bringing it to release

# Wolfram Research

2017 - Summer Massachusetts

Undergraduate Researcher

•Added Network Analysis feature to Mathematica to visualise the packet stream in a real time manner to help in debugging system/network issues. Released as part of Mathematica 11.3

# Education

# Birla Institute of Technology and Science, Pilani, Rajasthan

2013 – 2018

Double Major in M.Sc Economics and Manufacturing Engineering

# Other Activites

•Writing: I blog at [https://rnikhil.com/](https://rnikhil.com/) on AI, gaming, security. Lot of my posts have come on the front page of HN •SSMS: Led a 4 member Student Society for Mess Services team to develop a billing/inventory management system used daily at all messes/cafeterias to handle transactions of about 6L INR monthly for 7500 registered students

## Heliocentrism and Astronomy
Score: 0

Level: 1

GAME OVER

Click to restart

## Fun Games and Challenges
## 404: Page not found

Page not found, but the fun is just beginning!

[![Helicopter Game](https://rnikhil.com/assets/files/helicoptergame.png)\\
Helicopter Game\\
\\
Navigate through caves and test your reflexes](https://www.rnikhil.com/heli) [![River Cross Puzzle](https://rnikhil.com/assets/files/rivercross.jpg)\\
River Cross Puzzle\\
\\
Classic puzzle to challenge your mind](https://www.rnikhil.com/rivercross)

[Share Your High Score @rnikhilcom](https://x.com/rnikhilcom)

