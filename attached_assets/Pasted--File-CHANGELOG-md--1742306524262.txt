================================================
File: CHANGELOG.md
================================================
# Release notes

<!-- do not remove -->

## 0.0.4

### New Features

- Check if in nbdev project ([#10](https://github.com/AnswerDotAI/llms-txt/pull/10)), thanks to [@hamelsmu](https://github.com/hamelsmu)


## 0.0.3

### New Features

- allow saving of file into directory and clean up the code ([#9](https://github.com/AnswerDotAI/llms-txt/pull/9)), thanks to [@hamelsmu](https://github.com/hamelsmu)


## 0.0.2

### New Features

- Download URLs in parallel ([#6](https://github.com/AnswerDotAI/llms-txt/issues/6))





================================================
File: nbs/index.qmd
================================================
---
title: "The /llms.txt file"
date: 2024-09-03
author: "Jeremy Howard"
description: "A proposal to standardise on using an `/llms.txt` file to provide information to help LLMs use a website at inference time."
image: "/sample.png"
---

## Background

Large language models increasingly rely on website information, but face a critical limitation: context windows are too small to handle most websites in their entirety. Converting complex HTML pages with navigation, ads, and JavaScript into LLM-friendly plain text is both difficult and imprecise.

While websites serve both human readers and LLMs, the latter benefit from more concise, expert-level information gathered in a single, accessible location. This is particularly important for use cases like development environments, where LLMs need quick access to programming documentation and APIs.

## Proposal

![llms.txt logo](logo.png){.lightbox width=150px .floatr}

We propose adding a `/llms.txt` markdown file to websites to provide LLM-friendly content. This file offers brief background information, guidance, and links to detailed markdown files.

llms.txt markdown is human and LLM readable, but is also in a precise format allowing fixed processing methods (i.e. classical programming techniques such as parsers and regex).

We furthermore propose that pages on websites that have information that might be useful for LLMs to read provide a clean markdown version of those pages at the same URL as the original page, but with `.md` appended. (URLs without file names should append `index.html.md` instead.)

The [FastHTML project](https://fastht.ml) follows these two proposals for its documentation. For instance, here is the [FastHTML docs llms.txt](https://answerdotai.github.io/fasthtml/llms.txt). And here is an example of a [regular HTML docs page](https://answerdotai.github.io/fasthtml/tutorials/by_example.html), along with exact same URL but with [a .md extension](https://answerdotai.github.io/fasthtml/tutorials/by_example.html.md).

This proposal does not include any particular recommendation for how to process the llms.txt file, since it will depend on the application. For example, the FastHTML project opted to automatically expand the llms.txt to two markdown files with the contents of the linked URLs, using an XML-based structure suitable for use in LLMs such as Claude. The two files are: [llms-ctx.txt](https://answerdotai.github.io/fasthtml/llms-ctx.txt), which does not include the optional URLs, and [llms-ctx-full.txt](https://answerdotai.github.io/fasthtml/llms-ctx-full.txt), which does include them. They are created using the [`llms_txt2ctx`](https://llmstxt.org/intro.html#cli) command line application, and the FastHTML documentation includes information for users about how to use them.

The versatility of llms.txt files means they can serve many purposes - from helping developers find their way around software documentation, to giving businesses a way to outline their structure, or even breaking down complex legislation for stakeholders. They're just as useful for personal websites where they can help answer questions about someone's CV, for e-commerce sites to explain products and policies, or for schools and universities to provide quick access to their course information and resources.

Note that all [nbdev](https://nbdev.fast.ai/) projects now create .md versions of all pages by default. All Answer.AI and fast.ai software projects using nbdev have had their docs regenerated with this feature. For an example, see the [markdown version](https://fastcore.fast.ai/docments.html.md) of [fastcore's docments module](https://fastcore.fast.ai/docments.html).

## Format

At the moment the most widely and easily understood format for language models is Markdown. Simply showing where key Markdown files can be found is a great first step. Providing some basic structure helps a language model to find where the information it needs can come from.

The `llms.txt` file is unusual in that it uses Markdown to structure the information rather than a classic structured format such as XML. The reason for this is that we expect many of these files to be read by language models and agents. Having said that, the information in llms.txt follows a specific format and can be read using standard programmatic-based tools.

The llms.txt file spec is for files located in the root path `/llms.txt` of a website (or, optionally, in a subpath). A file following the spec contains the following sections as markdown, in the specific order:

- An H1 with the name of the project or site. This is the only required section
- A blockquote with a short summary of the project, containing key information necessary for understanding the rest of the file
- Zero or more markdown sections (e.g. paragraphs, lists, etc) of any type except headings, containing more detailed information about the project and how to interpret the provided files
- Zero or more markdown sections delimited by H2 headers, containing "file lists" of URLs where further detail is available
  - Each "file list" is a markdown list, containing a required markdown hyperlink `[name](url)`, then optionally a `:` and notes about the file.

Here is a mock example:

```markdown
# Title

> Optional description goes here

Optional details go here

## Section name

- [Link title](https://link_url): Optional link details

## Optional

- [Link title](https://link_url)
```

Note that the "Optional" section has a special meaning---if it's included, the URLs provided there can be skipped if a shorter context is needed. Use it for secondary information which can often be skipped.

## Existing standards

llms.txt is designed to coexist with current web standards. While sitemaps list all pages for search engines, `llms.txt` offers a curated overview for LLMs. It can complement robots.txt by providing context for allowed content. The file can also reference structured data markup used on the site, helping LLMs understand how to interpret this information in context.

The approach of standardising on a path for the file follows the approach of `/robots.txt` and `/sitemap.xml`. robots.txt and `llms.txt` have different purposes---robots.txt is generally used to let automated tools know what access to a site is considered acceptable, such as for search indexing bots. On the other hand, `llms.txt` information will often be used on demand when a user explicitly requests information about a topic, such as when including a coding library's documentation in a project, or when asking a chat bot with search functionality for information. Our expectation is that `llms.txt` will mainly be useful for *inference*, i.e. at the time a user is seeking assistance, as opposed to for *training*. However, perhaps if `llms.txt` usage becomes widespread, future training runs could take advantage of the information in `llms.txt` files too.

sitemap.xml is a list of all the indexable human-readable information available on a site. This isn’t a substitute for `llms.txt` since it:

- Often won’t have the LLM-readable versions of pages listed
- Doesn’t include URLs to external sites, even though they might be helpful to understand the information
- Will generally cover documents that in aggregate will be too large to fit in an LLM context window, and will include a lot of information that isn’t necessary to understand the site.

## Example

Here’s an example of `llms.txt`, in this case a cut down version of the file used for the FastHTML project (see also the [full version](https://answerdotai.github.io/fasthtml/llms.txt):

```markdown
# FastHTML

> FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore's `FT` "FastTags" into a library for creating server-rendered hypermedia applications.

Important notes:

- Although parts of its API are inspired by FastAPI, it is *not* compatible with FastAPI syntax and is not targeted at creating API services
- FastHTML is compatible with JS-native web components and any vanilla JS library, but not with React, Vue, or Svelte.

## Docs

- [FastHTML quick start](https://answerdotai.github.io/fasthtml/tutorials/quickstart_for_web_devs.html.md): A brief overview of many FastHTML features
- [HTMX reference](https://raw.githubusercontent.com/path/reference.md): Brief description of all HTMX attributes, CSS classes, headers, events, extensions, js lib methods, and config options

## Examples

- [Todo list application](https://raw.githubusercontent.com/path/adv_app.py): Detailed walk-thru of a complete CRUD app in FastHTML showing idiomatic use of FastHTML and HTMX patterns.

## Optional

- [Starlette full documentation](https://gist.githubusercontent.com/path/starlette-sml.md): A subset of the Starlette documentation useful for FastHTML development.
```

To create effective `llms.txt` files, consider these guidelines: 

- Use concise, clear language.
- When linking to resources, include brief, informative descriptions.
- Avoid ambiguous terms or unexplained jargon.
- Run a tool that expands your `llms.txt` file into an LLM context file and test a number of language models to see if they can answer questions about your content.

## Directories

Here are a few directories that list the `llms.txt` files available on the web:

- [llmstxt.site](https://llmstxt.site/)
- [directory.llmstxt.cloud](https://directory.llmstxt.cloud/)

## Integrations

Various tools and plugins are available to help integrate the llms.txt specification into your workflow:

- [`llms_txt2ctx`](https://llmstxt.org/intro.html#cli) - CLI and Python module for parsing llms.txt files and generating LLM context
- [JavaScript Implementation](./llmstxt-js.html) - Sample JavaScript implementation
- [vite-plugin-llms](https://github.com/saschaseniuk/vite-plugin-llms) - Vite plugin that serves markdown files alongside your routes following the llms.txt specification

## Next steps

The `llms.txt` specification is open for community input. A [GitHub repository](https://github.com/AnswerDotAI/llms-txt) hosts [this informal overview](https://github.com/AnswerDotAI/llms-txt/blob/main/nbs/index.md), allowing for version control and public discussion. A [community discord channel](https://discord.gg/aJPygMvPEN) is available for sharing implementation experiences and discussing best practices.




================================================
File: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
File: MANIFEST.in
================================================
include settings.ini
include LICENSE
include CONTRIBUTING.md
include README.md
recursive-exclude * __pycache__



================================================
File: pyproject.toml
================================================
[build-system]
requires = ["setuptools>=64.0"]
build-backend = "setuptools.build_meta"



================================================
File: settings.ini
================================================
[DEFAULT]
repo = llms-txt
lib_name = llms-txt
version = 0.0.5
min_python = 3.8
license = apache2
black_formatting = False
doc_path = _docs
lib_path = llms_txt
nbs_path = nbs
recursive = True
tst_flags = notest
put_version_in_init = True
cell_number = False
branch = main
custom_sidebar = True
doc_host = https://llmstxt.org
doc_baseurl = /
git_url = https://github.com/AnswerDotAI/llms-txt
title = llms-txt
audience = Developers
author = Jeremy Howard
author_email = github@jhoward.fastmail.fm
copyright = 2024 onwards, Jeremy Howard
description = The /llms.txt file, helping language models use your website
keywords = nbdev jupyter notebook python LLMs NLP
language = English
status = 3
user = AnswerDotAI
requirements = fastcore>=1.7.3 httpx
conda_user = fastai
console_scripts = llms_txt2ctx=llms_txt.core:llms_txt2ctx
readme_nb = index.ipynb
allowed_metadata_keys = 
allowed_cell_metadata_keys = 
jupyter_hooks = False
clean_ids = True
clear_all = False
skip_procs = 




================================================
File: setup.py
================================================
from pkg_resources import parse_version
from configparser import ConfigParser
import setuptools, shlex
assert parse_version(setuptools.__version__)>=parse_version('36.2')

# note: all settings are in settings.ini; edit there, not here
config = ConfigParser(delimiters=['='])
config.read('settings.ini', encoding='utf-8')
cfg = config['DEFAULT']

cfg_keys = 'version description keywords author author_email'.split()
expected = cfg_keys + "lib_name user branch license status min_python audience language".split()
for o in expected: assert o in cfg, "missing expected setting: {}".format(o)
setup_cfg = {o:cfg[o] for o in cfg_keys}

licenses = {
    'apache2': ('Apache Software License 2.0','OSI Approved :: Apache Software License'),
    'mit': ('MIT License', 'OSI Approved :: MIT License'),
    'gpl2': ('GNU General Public License v2', 'OSI Approved :: GNU General Public License v2 (GPLv2)'),
    'gpl3': ('GNU General Public License v3', 'OSI Approved :: GNU General Public License v3 (GPLv3)'),
    'bsd3': ('BSD License', 'OSI Approved :: BSD License'),
}
statuses = [ '1 - Planning', '2 - Pre-Alpha', '3 - Alpha',
    '4 - Beta', '5 - Production/Stable', '6 - Mature', '7 - Inactive' ]
py_versions = '3.6 3.7 3.8 3.9 3.10 3.11 3.12'.split()

requirements = shlex.split(cfg.get('requirements', ''))
if cfg.get('pip_requirements'): requirements += shlex.split(cfg.get('pip_requirements', ''))
min_python = cfg['min_python']
lic = licenses.get(cfg['license'].lower(), (cfg['license'], None))
dev_requirements = (cfg.get('dev_requirements') or '').split()

package_data = dict()
pkg_data = cfg.get('package_data', None)
if pkg_data:
    package_data[cfg['lib_name']] =  pkg_data.split() # split as multiple files might be listed
# Add package data to setup_cfg for setuptools.setup(..., **setup_cfg)
setup_cfg['package_data'] = package_data

setuptools.setup(
    name = cfg['lib_name'],
    license = lic[0],
    classifiers = [
        'Development Status :: ' + statuses[int(cfg['status'])],
        'Intended Audience :: ' + cfg['audience'].title(),
        'Natural Language :: ' + cfg['language'].title(),
    ] + ['Programming Language :: Python :: '+o for o in py_versions[py_versions.index(min_python):]] + (['License :: ' + lic[1] ] if lic[1] else []),
    url = cfg['git_url'],
    packages = setuptools.find_packages(),
    include_package_data = True,
    install_requires = requirements,
    extras_require={ 'dev': dev_requirements },
    dependency_links = cfg.get('dep_links','').split(),
    python_requires  = '>=' + cfg['min_python'],
    long_description = open('README.md', encoding='utf-8').read(),
    long_description_content_type = 'text/markdown',
    zip_safe = False,
    entry_points = {
        'console_scripts': cfg.get('console_scripts','').split(),
        'nbdev': [f'{cfg.get("lib_path")}={cfg.get("lib_path")}._modidx:d']
    },
    **setup_cfg)





================================================
File: llms_txt/__init__.py
================================================
__version__ = "0.0.5"
from .core import *



================================================
File: llms_txt/_modidx.py
================================================
# Autogenerated by nbdev

d = { 'settings': { 'branch': 'main',
                'doc_baseurl': '/',
                'doc_host': 'https://llmstxt.org',
                'git_url': 'https://github.com/AnswerDotAI/llms-txt',
                'lib_path': 'llms_txt'},
  'syms': { 'llms_txt.core': { 'llms_txt.core._doc': ('core.html#_doc', 'llms_txt/core.py'),
                               'llms_txt.core._get_config': ('core.html#_get_config', 'llms_txt/core.py'),
                               'llms_txt.core._local_docs_pth': ('core.html#_local_docs_pth', 'llms_txt/core.py'),
                               'llms_txt.core._parse_links': ('core.html#_parse_links', 'llms_txt/core.py'),
                               'llms_txt.core._parse_llms': ('core.html#_parse_llms', 'llms_txt/core.py'),
                               'llms_txt.core._section': ('core.html#_section', 'llms_txt/core.py'),
                               'llms_txt.core.create_ctx': ('core.html#create_ctx', 'llms_txt/core.py'),
                               'llms_txt.core.get_doc_content': ('core.html#get_doc_content', 'llms_txt/core.py'),
                               'llms_txt.core.get_sizes': ('core.html#get_sizes', 'llms_txt/core.py'),
                               'llms_txt.core.llms_txt2ctx': ('core.html#llms_txt2ctx', 'llms_txt/core.py'),
                               'llms_txt.core.mk_ctx': ('core.html#mk_ctx', 'llms_txt/core.py'),
                               'llms_txt.core.named_re': ('core.html#named_re', 'llms_txt/core.py'),
                               'llms_txt.core.opt_re': ('core.html#opt_re', 'llms_txt/core.py'),
                               'llms_txt.core.parse_link': ('core.html#parse_link', 'llms_txt/core.py'),
                               'llms_txt.core.parse_llms_file': ('core.html#parse_llms_file', 'llms_txt/core.py'),
                               'llms_txt.core.search': ('core.html#search', 'llms_txt/core.py')},
            'llms_txt.miniparse': {}}}



================================================
File: llms_txt/core.py
================================================
"""Source code for `llms_txt` Python module, containing helpers to create and use llms.txt files"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_core.ipynb.

# %% auto 0
__all__ = ['opt_re', 'named_re', 'search', 'parse_link', 'parse_llms_file', 'get_doc_content', 'mk_ctx', 'get_sizes',
           'create_ctx', 'llms_txt2ctx']

# %% ../nbs/01_core.ipynb
import re

# %% ../nbs/01_core.ipynb
from fastcore.utils import *
from fastcore.xml import *
from fastcore.script import *
import httpx
from urllib.parse import urlparse

# %% ../nbs/01_core.ipynb
def opt_re(s):
    "Pattern to optionally match `s`"
    return f'(?:{s})?'

def named_re(nm, pat):
    "Pattern to match `pat` in a named capture group"
    return f'(?P<{nm}>{pat})'

def search(pat, txt, flags=0):
    "Dictionary of matched groups in `pat` within `txt`"
    res = re.search(pat, txt, flags=flags)
    return res.groupdict() if res else None

# %% ../nbs/01_core.ipynb
def parse_link(txt):
    "Parse a link section from llms.txt"
    title = named_re('title', r'[^\]]+')
    url = named_re('url', r'[^\)]+')
    desc = named_re('desc', r'.*')
    desc_pat = opt_re(fr":\s*{desc}")
    pat = fr'-\s*\[{title}\]\({url}\){desc_pat}'
    return re.search(pat, txt).groupdict()

# %% ../nbs/01_core.ipynb
def _parse_links(links):
    return [parse_link(l) for l in re.split(r'\n+', links.strip()) if l.strip()]

# %% ../nbs/01_core.ipynb
def _parse_llms(txt):
    start,*rest = re.split(fr'^##\s*(.*?$)', txt, flags=re.MULTILINE)
    d = dict(chunked(rest, 2))
    sects = {k: _parse_links(v) for k,v in d.items()}
    return start.strip(),sects

# %% ../nbs/01_core.ipynb
def parse_llms_file(txt):
    "Parse llms.txt file contents in `txt` to an `AttrDict`"
    start,sects = _parse_llms(txt)
    title = named_re('title', r'.+?$')
    summ = named_re('summary', '.+?$')
    summ_pat = opt_re(fr"^>\s*{summ}$")
    info = named_re('info', '.*')
    pat = fr'^#\s*{title}\n+{summ_pat}\n+{info}'
    d = search(pat, start, (re.MULTILINE|re.DOTALL))
    d['sections'] = sects
    return dict2obj(d)

# %% ../nbs/01_core.ipynb
from fastcore.xml import Sections,Project,Doc

# %% ../nbs/01_core.ipynb
def _local_docs_pth(cfg): return cfg.config_path/'_proc'/cfg.doc_path
def _get_config(): return Config.find('settings.ini')

def get_doc_content(url):
    "Fetch content from local file if in nbdev repo."
    if (cfg:=_get_config()) and url.startswith(cfg.doc_host):
        relative_path = urlparse(url).path.lstrip('/')
        local_path = _local_docs_pth(cfg) / relative_path
        if local_path.exists(): return local_path.read_text()
    return httpx.get(url).text

# %% ../nbs/01_core.ipynb
def _doc(kw):
    "Create a `Doc` FT object with the text retrieved from `url` as the child, and `kw` as attrs."
    url = kw.pop('url')
    txt = get_doc_content(url)
    re_comment = re.compile('^<!--.*-->$', flags=re.MULTILINE)
    re_base64_img = re.compile(r'<img[^>]*src="data:image/[^"]*"[^>]*>')
    txt = '\n'.join([o for o in txt.splitlines() if not re_comment.search(o) and not re_base64_img.search(o)])
    return Doc(txt, **kw)

# %% ../nbs/01_core.ipynb
def _section(nm, items, n_workers=None):
    "Create a section containing a `Doc` object for each child."
    return ft(nm, *parallel(_doc, items, n_workers=n_workers, threadpool=True))

# %% ../nbs/01_core.ipynb
def mk_ctx(d, optional=True, n_workers=None):
    "Create a `Project` with a `Section` for each H2 part in `d`, optionally skipping the 'optional' section."
    skip = '' if optional else 'Optional'
    sections = [_section(k, v, n_workers=n_workers) for k,v in d.sections.items() if k!=skip]
    return Project(title=d.title, summary=d.summary)(d.info, *sections)

# %% ../nbs/01_core.ipynb
def get_sizes(ctx):
    "Get the size of each section of the LLM context"
    return {o.tag:{p.title:len(p.children[0]) for p in o.children} for o in ctx.children if hasattr(o,'tag')}

# %% ../nbs/01_core.ipynb
def create_ctx(txt, optional=False, n_workers=None):
    "A `Project` with a `Section` for each H2 part in `txt`, optionally skipping the 'optional' section."
    d = parse_llms_file(txt)
    ctx = mk_ctx(d, optional=optional, n_workers=n_workers)
    return to_xml(ctx, do_escape=False)

# %% ../nbs/01_core.ipynb
@call_parse
def llms_txt2ctx(
    fname:str, # File name to read
    optional:bool_arg=False, # Include 'optional' section?
    n_workers:int=None, # Number of threads to use for parallel downloading
    save_nbdev_fname:str=None #save output to nbdev `{docs_path}` instead of emitting to stdout
):
    "Print a `Project` with a `Section` for each H2 part in file read from `fname`, optionally skipping the 'optional' section."
    ctx = create_ctx(Path(fname).read_text(), optional=optional, n_workers=n_workers)
    if save_nbdev_fname and (cfg:=_get_config()):
        (_local_docs_pth(cfg) / save_nbdev_fname).mk_write(ctx)
    else: print(ctx)



================================================
File: llms_txt/miniparse.py
================================================
from pathlib import Path
import re,itertools

def chunked(it, chunk_sz):
    it = iter(it)
    return iter(lambda: list(itertools.islice(it, chunk_sz)), [])

def parse_llms_txt(txt):
    "Parse llms.txt file contents in `txt` to a `dict`"
    def _p(links):
        link_pat = '-\s*\[(?P<title>[^\]]+)\]\((?P<url>[^\)]+)\)(?::\s*(?P<desc>.*))?'
        return [re.search(link_pat, l).groupdict()
                for l in re.split(r'\n+', links.strip()) if l.strip()]

    start,*rest = re.split(fr'^##\s*(.*?$)', txt, flags=re.MULTILINE)
    sects = {k: _p(v) for k,v in dict(chunked(rest, 2)).items()}
    pat = '^#\s*(?P<title>.+?$)\n+(?:^>\s*(?P<summary>.+?$)$)?\n+(?P<info>.*)'
    d = re.search(pat, start.strip(), (re.MULTILINE|re.DOTALL)).groupdict()
    d['sections'] = sects
    return d




================================================
File: nbs/00_intro.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Python module & CLI

> Read llms.txt files and create XML context documents for LLMs
"""

#| hide
from fastcore.utils import *

"""
Given an `llms.txt` file, this provides a CLI and Python API to parse the file and create an XML context file from it. The input file should follow this format:

```
# FastHTML

> FastHTML is a python library which...

When writing FastHTML apps remember to:

- Thing to remember

## Docs

- [Surreal](https://host/README.md): Tiny jQuery alternative with Locality of Behavior
- [FastHTML quick start](https://host/quickstart.html.md): An overview of FastHTML features

## Examples

- [Todo app](https://host/adv_app.py)

## Optional

- [Starlette docs](https://host/starlette-sml.md): A subset of the Starlette docs
```
"""

"""
## Install
"""

"""
```sh
pip install llms-txt
```
"""

"""
## How to use
"""

"""
### CLI
"""

"""
After installation, `llms_txt2ctx` is available in your terminal.

To get help for the CLI:

```sh
llms_txt2ctx -h
```

To convert an `llms.txt` file to XML context and save to `llms.md`:

```sh
llms_txt2ctx llms.txt > llms.md
```

Pass `--optional True` to add the 'optional' section of the input file.
"""

"""
### Python module
"""

from llms_txt import *

samp = Path('llms-sample.txt').read_text()

"""
Use `parse_llms_file` to create a data structure with the sections of an llms.txt file (you can also add `optional=True` if needed):
"""

parsed = parse_llms_file(samp)
list(parsed)
# Output:
#   ['title', 'summary', 'info', 'sections']

parsed.title,parsed.summary
# Output:
#   ('FastHTML',

#    'FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\'s `FT` "FastTags" into a library for creating server-rendered hypermedia applications.')

list(parsed.sections)
# Output:
#   ['Docs', 'Examples', 'Optional']

parsed.sections.Optional[0]
# Output:
#   {'title': 'Starlette full documentation',

#    'url': 'https://gist.githubusercontent.com/jph00/809e4a4808d4510be0e3dc9565e9cbd3/raw/9b717589ca44cedc8aaf00b2b8cacef922964c0f/starlette-sml.md',

#    'desc': 'A subset of the Starlette documentation useful for FastHTML development.'}

"""
Use `create_ctx` to create an LLM context file with XML sections, suitable for systems such as Claude (this is what the CLI calls behind the scenes).
"""

ctx = create_ctx(samp)

print(ctx[:300])
# Output:
#   <project title="FastHTML" summary='FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore&#39;s `FT` "FastTags" into a library for creating server-rendered hypermedia applications.'>

#   Remember:

#   

#   - Use `serve()` for running uvicorn (`if __name__ == "__main__"` is not


"""
### Implementation and tests
"""

"""
To show how simple it is to parse `llms.txt` files, here's a complete parser in <20 lines of code with no dependencies:

```python
from pathlib import Path
import re,itertools

def chunked(it, chunk_sz):
    it = iter(it)
    return iter(lambda: list(itertools.islice(it, chunk_sz)), [])

def parse_llms_txt(txt):
    "Parse llms.txt file contents in `txt` to a `dict`"
    def _p(links):
        link_pat = '-\s*\[(?P<title>[^\]]+)\]\((?P<url>[^\)]+)\)(?::\s*(?P<desc>.*))?'
        return [re.search(link_pat, l).groupdict()
                for l in re.split(r'\n+', links.strip()) if l.strip()]

    start,*rest = re.split(fr'^##\s*(.*?$)', txt, flags=re.MULTILINE)
    sects = {k: _p(v) for k,v in dict(chunked(rest, 2)).items()}
    pat = '^#\s*(?P<title>.+?$)\n+(?:^>\s*(?P<summary>.+?$)$)?\n+(?P<info>.*)'
    d = re.search(pat, start.strip(), (re.MULTILINE|re.DOTALL)).groupdict()
    d['sections'] = sects
    return d
```
"""

"""
We have provided a test suite in `tests/test-parse.py` and confirmed that this implementation passes all tests.
"""



================================================
File: nbs/01_core.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Python source

> Source code for `llms_txt` Python module, containing helpers to create and use llms.txt files
"""

#| default_exp core

#| export
import re

#| hide
from nbdev.showdoc import *
import nbdev; nbdev.nbdev_export()

#| export
from fastcore.utils import *
from fastcore.xml import *
from fastcore.script import *
import httpx
from urllib.parse import urlparse

"""
## Introduction
"""

%ai reset

"""
The llms.txt file spec is for files located in the path `llms.txt` of a website (or, optionally, in a subpath). `llms-sample.txt` is a simple example. A file following the spec contains the following sections as markdown, in the specific order:

- An H1 with the name of the project or site. This is the only required section
- A blockquote with a short summary of the project, containing key information necessary for understanding the rest of the file
- Zero or more markdown sections (e.g. paragraphs, lists, etc) of any type, except headings, containing more detailed information about the project and how to interpret the provided files
- Zero or more markdown sections delimited by H2 headers, containing "file lists" of URLs where further detail is available
  - Each "file list" is a markdown list, containing a required markdown hyperlink `[name](url)`, then optionally a `:` and notes about the file.

Here's the start of a sample llms.txt file we'll use for testing:
"""

samp = Path('llms-sample.txt').read_text()
print(samp[:480])
# Output:
#   # FastHTML

#   

#   > FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore's `FT` "FastTags" into a library for creating server-rendered hypermedia applications.

#   

#   Remember:

#   

#   - Use `serve()` for running uvicorn (`if __name__ == "__main__"` is not needed since it's automatic)

#   - When a title is needed with a response, use `Titled`; note that that already wraps children in `Container`, and already includes both the meta title as well as the H1 element


"""
## Reading
"""

"""
We'll implement `parse_llms_file` to pull out the sections of llms.txt into a simple data structure.
"""

#| export
def opt_re(s):
    "Pattern to optionally match `s`"
    return f'(?:{s})?'

def named_re(nm, pat):
    "Pattern to match `pat` in a named capture group"
    return f'(?P<{nm}>{pat})'

def search(pat, txt, flags=0):
    "Dictionary of matched groups in `pat` within `txt`"
    res = re.search(pat, txt, flags=flags)
    return res.groupdict() if res else None

"""
We'll work "outside in" so we can test the innermost matches as we go.
"""

"""
### Parse links
"""

link = '- [FastHTML quick start](https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html.md): A brief overview of FastHTML features'

%%aip 0
Parse the first part of `link` into a dict

title = named_re('title', r'[^\]]+')
pat =  fr'-\s*\[{title}\]'
search(pat, samp)
# Output:
#   {'title': 'internal docs - ed'}

%%aip 0
Do the next bit.

url = named_re('url', r'[^\)]+')
pat += fr'\({url}\)'
search(pat, samp)
# Output:
#   {'title': 'internal docs - ed', 'url': 'https://llmstxt.org/ed.html'}

%%aip 0
Do the final bit. Note it's optional.

desc = named_re('desc', r'.*')
pat += opt_re(fr':\s*{desc}')
search(pat, link)
# Output:
#   {'title': 'FastHTML quick start',

#    'url': 'https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html.md',

#    'desc': 'A brief overview of FastHTML features'}

%%aip 0
Combine those sections into a function `parse_link(txt)`

#| export
def parse_link(txt):
    "Parse a link section from llms.txt"
    title = named_re('title', r'[^\]]+')
    url = named_re('url', r'[^\)]+')
    desc = named_re('desc', r'.*')
    desc_pat = opt_re(fr":\s*{desc}")
    pat = fr'-\s*\[{title}\]\({url}\){desc_pat}'
    return re.search(pat, txt).groupdict()

parse_link(link)
# Output:
#   {'title': 'FastHTML quick start',

#    'url': 'https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html.md',

#    'desc': 'A brief overview of FastHTML features'}

parse_link('-[foo](http://foo)')
# Output:
#   {'title': 'foo', 'url': 'http://foo', 'desc': None}

"""
### Parse sections
"""

sections = '''First bit.

## S1

-[foo](http://foo)
- [foo2](http://foo2): stuff

## S2

- [foo3](http://foo3)'''

start,*rest = re.split(fr'^##\s*(.*?$)', sections, flags=re.MULTILINE)
start
# Output:
#   'First bit.\n\n'

rest
# Output:
#   ['S1',

#    '\n\n-[foo](http://foo)\n- [foo2](http://foo2): stuff\n\n',

#    'S2',

#    '\n\n- [foo3](http://foo3)']

%%aip 0
Concisely create a dict from the pairs in `rest`.

d = dict(chunked(rest, 2))
d
# Output:
#   {'S1': '\n\n-[foo](http://foo)\n- [foo2](http://foo2): stuff\n\n',

#    'S2': '\n\n- [foo3](http://foo3)'}

links = d['S1']
links.strip()
# Output:
#   '-[foo](http://foo)\n- [foo2](http://foo2): stuff'

%%aip 0
Parse `links` into a list of links. There can be multiple newlines between them.

#| export
def _parse_links(links):
    return [parse_link(l) for l in re.split(r'\n+', links.strip()) if l.strip()]

_parse_links(links)
# Output:
#   [{'title': 'foo', 'url': 'http://foo', 'desc': None},

#    {'title': 'foo2', 'url': 'http://foo2', 'desc': 'stuff'}]

%%aip 0
Create a function that uses the above steps to parse an llms.txt into `start` and a dict with keys like `d` and parsed list of links as values.

#| export
def _parse_llms(txt):
    start,*rest = re.split(fr'^##\s*(.*?$)', txt, flags=re.MULTILINE)
    d = dict(chunked(rest, 2))
    sects = {k: _parse_links(v) for k,v in d.items()}
    return start.strip(),sects

start, sects = _parse_llms(samp)
start
# Output:
#   '# FastHTML\n\n> FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\'s `FT` "FastTags" into a library for creating server-rendered hypermedia applications.\n\nRemember:\n\n- Use `serve()` for running uvicorn (`if __name__ == "__main__"` is not needed since it\'s automatic)\n- When a title is needed with a response, use `Titled`; note that that already wraps children in `Container`, and already includes both the meta title as well as the H1 element.'

title = named_re('title', r'.+?$')
summ = named_re('summary', '.+?$')
summ_pat = opt_re(fr"^>\s*{summ}$")
info = named_re('info', '.*')

pat = fr'^#\s*{title}\n+{summ_pat}\n+{info}'
search(pat, start, (re.MULTILINE|re.DOTALL))
# Output:
#   {'title': 'FastHTML',

#    'summary': 'FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\'s `FT` "FastTags" into a library for creating server-rendered hypermedia applications.',

#    'info': 'Remember:\n\n- Use `serve()` for running uvicorn (`if __name__ == "__main__"` is not needed since it\'s automatic)\n- When a title is needed with a response, use `Titled`; note that that already wraps children in `Container`, and already includes both the meta title as well as the H1 element.'}

%%aip 0
Let's finish it off!

#| export
def parse_llms_file(txt):
    "Parse llms.txt file contents in `txt` to an `AttrDict`"
    start,sects = _parse_llms(txt)
    title = named_re('title', r'.+?$')
    summ = named_re('summary', '.+?$')
    summ_pat = opt_re(fr"^>\s*{summ}$")
    info = named_re('info', '.*')
    pat = fr'^#\s*{title}\n+{summ_pat}\n+{info}'
    d = search(pat, start, (re.MULTILINE|re.DOTALL))
    d['sections'] = sects
    return dict2obj(d)

llmsd = parse_llms_file(samp)
llmsd.summary
# Output:
#   'FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\'s `FT` "FastTags" into a library for creating server-rendered hypermedia applications.'

llmsd.sections.Examples
# Output:
#   (#1) [{'title': 'Todo list application', 'url': 'https://raw.githubusercontent.com/AnswerDotAI/fasthtml/main/examples/adv_app.py', 'desc': 'Detailed walk-thru of a complete CRUD app in FastHTML showing idiomatic use of FastHTML and HTMX patterns.'}]

"""
## XML conversion
"""

"""
For some LLMs such as Claude, XML format is preferred, so we'll provide a function to create that format.
"""

#| export
from fastcore.xml import Sections,Project,Doc

#|export
def _local_docs_pth(cfg): return cfg.config_path/'_proc'/cfg.doc_path
def _get_config(): return Config.find('settings.ini')

def get_doc_content(url):
    "Fetch content from local file if in nbdev repo."
    if (cfg:=_get_config()) and url.startswith(cfg.doc_host):
        relative_path = urlparse(url).path.lstrip('/')
        local_path = _local_docs_pth(cfg) / relative_path
        if local_path.exists(): return local_path.read_text()
    return httpx.get(url).text

#| export
def _doc(kw):
    "Create a `Doc` FT object with the text retrieved from `url` as the child, and `kw` as attrs."
    url = kw.pop('url')
    txt = get_doc_content(url)
    re_comment = re.compile('^<!--.*-->$', flags=re.MULTILINE)
    re_base64_img = re.compile(r'<img[^>]*src="data:image/[^"]*"[^>]*>')
    txt = '\n'.join([o for o in txt.splitlines() if not re_comment.search(o) and not re_base64_img.search(o)])
    return Doc(txt, **kw)

#| export
def _section(nm, items, n_workers=None):
    "Create a section containing a `Doc` object for each child."
    return ft(nm, *parallel(_doc, items, n_workers=n_workers, threadpool=True))

#| export
def mk_ctx(d, optional=True, n_workers=None):
    "Create a `Project` with a `Section` for each H2 part in `d`, optionally skipping the 'optional' section."
    skip = '' if optional else 'Optional'
    sections = [_section(k, v, n_workers=n_workers) for k,v in d.sections.items() if k!=skip]
    return Project(title=d.title, summary=d.summary)(d.info, *sections)

ctx = mk_ctx(llmsd)
print(to_xml(ctx, do_escape=False)[:260]+'...')
# Output:
#   <project title="FastHTML" summary='FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore&#39;s `FT` "FastTags" into a library for creating server-rendered hypermedia applications.'>Remember:

#   

#   - Use `serve()` for running uvic...


#| export
def get_sizes(ctx):
    "Get the size of each section of the LLM context"
    return {o.tag:{p.title:len(p.children[0]) for p in o.children} for o in ctx.children if hasattr(o,'tag')}

get_sizes(ctx)
# Output:
#   {'docs': {'internal docs - ed': 34464,

#     'FastHTML quick start': 27383,

#     'HTMX reference': 26812,

#     'Starlette quick guide': 7936},

#    'examples': {'Todo list application': 18558},

#    'optional': {'Starlette full documentation': 48331}}

Path('../fasthtml.md').write_text(to_xml(ctx, do_escape=False))
# Output:
#   164662

#| export
def create_ctx(txt, optional=False, n_workers=None):
    "A `Project` with a `Section` for each H2 part in `txt`, optionally skipping the 'optional' section."
    d = parse_llms_file(txt)
    ctx = mk_ctx(d, optional=optional, n_workers=n_workers)
    return to_xml(ctx, do_escape=False)

#| export
@call_parse
def llms_txt2ctx(
    fname:str, # File name to read
    optional:bool_arg=False, # Include 'optional' section?
    n_workers:int=None, # Number of threads to use for parallel downloading
    save_nbdev_fname:str=None #save output to nbdev `{docs_path}` instead of emitting to stdout
):
    "Print a `Project` with a `Section` for each H2 part in file read from `fname`, optionally skipping the 'optional' section."
    ctx = create_ctx(Path(fname).read_text(), optional=optional, n_workers=n_workers)
    if save_nbdev_fname and (cfg:=_get_config()):
        (_local_docs_pth(cfg) / save_nbdev_fname).mk_write(ctx)
    else: print(ctx)

!llms_txt2ctx llms-sample.txt > ../fasthtml.md

"""
## Export -
"""

#|hide
#|eval: false
from nbdev import nbdev_export
nbdev_export()



================================================
File: nbs/_quarto.yml
================================================
project:
  type: website
  resources: 
    - "*.txt"
    - "*.html"
  preview:
    navigate: false
    port: 3000

format:
  html:
    code-overflow: wrap
    theme: cosmo
    css: styles.css
    toc: true
    keep-md: true
  commonmark: default

website:
  favicon: favicon.ico
  open-graph: true
  repo-actions: [issue]
  twitter-card:
    creator: "@jeremyphoward"
    site: "@answerdotai"
    image: https://llmstxt.org/sample.png
  navbar:
    background: primary
    search: true
    right:
      - icon: github
        href: "https://github.com/answerdotai/llms-txt"
      - icon: twitter
        href: https://x.com/answerdotai
        aria-label: Fast.ai Twitter
  sidebar:
    style: floating

metadata-files: [nbdev.yml, sidebar.yml]




================================================
File: nbs/CNAME
================================================
llmstxt.org



================================================
File: nbs/domains.md
================================================
# llms.txt in Different Domains

This page has some guidelines and suggestions for how different domains could utilize `llms.txt` to allow LLMs to better interface with their site if they so choose.

Remember, when constructing your `llms.txt` you should "use concise, clear language. When linking to resources, include brief, informative descriptions. Avoid ambiguous terms or unexplained jargon." Additionally, the best way to determine if your `llms.txt` works well with LLMs is to test it with them! Here is a minimal way to test Anthropic's Claude against your `llms.txt`:

```python
# /// script
# requires-python = ">=3.8"
# dependencies = [
#     "claudette",
#     "llms-txt",
#     "requests",
# ]
# ///
from claudette import *
from llms_txt import create_ctx

import requests

model = models[1] # Sonnet 3.5
chat = Chat(model, sp="""You are a helpful and concise assistant.""")

url = 'your_url/llms.txt'
text = requests.get(url).text
llm_ctx = create_ctx(text)
chat(llm_ctx + '\n\nThe above is necessary context for the conversation.')

while True:
    msg = input('Your question about the site: ')
    res = chat(msg)
    print('From Claude:', contents(res))
```

The above script utilizes the relatively new [`uv`](https://docs.astral.sh/uv/) syntax for python scripts. If you install `uv`, you can simply run the above script with `uv run test_llms_txt.py` and it will handle installing the necessary library dependencies in an isolated python environment. Else you can install the requirements manually and run it like any ordinary python script with `python test_llms_txt.py`.

## Restaurants

Here is an example `llms.txt` that a restaurant could construct for consumption by LLMs:

```
# Nate the Great's Grill

> Nate the Great's Grill is a popular destination off of Sesame Street that has been serving the community for over 20 years. We offer the best BBQ for a great price.

Here are our weekly hours:

- Monday - Friday: 9am - 9pm
- Saturday: 11am - 9pm
- Sunday: Closed

## Menus

- [Lunch Menu](https://host/lunch.html.md): Our lunch menu served from 11am to 4pm every day.
- [Dinner Menu](https://host/dinner.html.md): Our dinner menu served from 4pm to 9pm every day.

## Optional

- [Dessert Mneu](https://host/dessert.md): A subset of the Starlette docs
```

And here is an example lunch menu taken from [Franklin's BBQ](https://franklinbbq.com/menu):

```
## By The Pound

| Item              | Price         |
| --------------    | -----------   |
| Brisket           | 34            |
| Pork Spare Ribs   | 30            |
| Pulled Pork       | 28            |

## Drinks

| Item              | Price         |
| --------------    | -----------   |
| Iced Tea          | 3             |
| Mexican Coke      | 3             |

## Sides

| Item              | Price         |
| --------------    | -----------   |
| Potato Salad      | 4             |
| Slaw              | 4             |
```


================================================
File: nbs/ed.md
================================================
# `ed`, the standard text editor

In order to understand how llms.txt can be used with editors and IDEs, let's look at how `ed`, the [standard text editor](https://www.gnu.org/fun/jokes/ed-msg.html), could work (assuming it's updated to use this proposal). In our example we will look at how the user might then tell `ed` to retrieve the LLM docs from [docs.fastht.ml](https://docs.fastht.ml), and then use the results to write a simple [FastHTML](https://fastht.ml) web app.

Even if you use a non-standard editor or IDE such as vscode, Cursor, vim, or Emacs, your software's interaction with `/llms.txt` would look similar to this general approach.

```sh
$ ed
* H
```

Our user starts `ed` and enables helpful error messages (just for the purpose of this walkthru - obviously a real `ed` user doesn't need "helpful error messages").

```sh
* L docs.fastht.ml
Checking for /llms.txt at docs.fastht.ml...
Found /llms.txt. Parsing...
Fetching URLs from "Docs" section...  Fetching URLs from "Examples" section...
Skipping "Optional" section for brevity.
Creating XML-based context for Claude...  Context created and loaded.
```

The user invokes the hypothetical `L` (load) command, which in this LLM-enhanced version of `ed` retrieves and processes the `llms.txt` file. `ed` checks for the file (if it didn't exist, it would fall back to scraping the HTML of the website the old-fashioned way), parses it, fetches the relevant URLs, and creates an XML-based context suitable for Claude (perhaps an `ed` config file could be used to choose what LLM to use, and would determine how the context is formatted). All of this happens with the characteristic silence of `ed`, broken only by these reassuring progress messages.

```sh
* x Create a simple FastHTML app which outputs 'Hello, World!', in a <div>.
Analyzing context and prompt...
Generating FastHTML app...
App written to buffer.
```

Next, our user invokes the hypothetical `x` (eXecute AI) command, providing instructions for the LLM to create a simple FastHTML app. In the world of LLM-enhanced `ed`, this is understood as a request to generate code based on the given prompt and the previously loaded context.

```sh
* n
5
* p
from fasthtml.common import *
app,rt = fast_app()
@rt
def index(): return div("Hello, World!")
serve()
```

The editor analyzes the loaded context along with the provided prompt, generates the FastHTML app, and writes it to the buffer. The user then views the generated app line count (`n`) and contents (`p`), marveling at how much functionality is packed into those 5 lines.

```sh
*w hello_world.py
5
*q
```

Finally, our user saves the app to a file and quits `ed`, presumably to run their new FastHTML app and reflect on the unexpected productivity boost provided by their trusty line editor.




================================================
File: nbs/llms-ctx.txt
================================================
<project title="llms.txt">> A proposal that those interested in providing LLM-friendly content add a /llms.txt file to their site. This is a markdown file that provides brief background information and guidance, along with links to markdown files providing more detailed information.<docs><doc title="llms.txt proposal" desc="The proposal for llms.txt"># The /llms.txt file
Jeremy Howard
2024-09-03

## Background

Large language models increasingly rely on website information, but face
a critical limitation: context windows are too small to handle most
websites in their entirety. Converting complex HTML pages with
navigation, ads, and JavaScript into LLM-friendly plain text is both
difficult and imprecise.

While websites serve both human readers and LLMs, the latter benefit
from more concise, expert-level information gathered in a single,
accessible location. This is particularly important for use cases like
development environments, where LLMs need quick access to programming
documentation and APIs.

## Proposal

<figure>
<img src="logo.png" class="lightbox floatr" width="150"
alt="llms.txt logo" />
<figcaption aria-hidden="true">llms.txt logo</figcaption>
</figure>

We propose adding a `/llms.txt` markdown file to websites to provide
LLM-friendly content. This file offers brief background information,
guidance, and links to detailed markdown files.

llms.txt markdown is human and LLM readable, but is also in a precise
format allowing fixed processing methods (i.e. classical programming
techniques such as parsers and regex).

We furthermore propose that pages on websites that have information that
might be useful for LLMs to read provide a clean markdown version of
those pages at the same URL as the original page, but with `.md`
appended. (URLs without file names should append `index.html.md`
instead.)

The [FastHTML project](https://fastht.ml) follows these two proposals
for its documentation. For instance, here is the [FastHTML docs
llms.txt](https://docs.fastht.ml/llms.txt). And here is an example of a
[regular HTML docs
page](https://docs.fastht.ml/tutorials/by_example.html), along with
exact same URL but with [a .md
extension](https://docs.fastht.ml/tutorials/by_example.html.md).

This proposal does not include any particular recommendation for how to
process the llms.txt file, since it will depend on the application. For
example, the FastHTML project opted to automatically expand the llms.txt
to two markdown files with the contents of the linked URLs, using an
XML-based structure suitable for use in LLMs such as Claude. The two
files are: [llms-ctx.txt](https://docs.fastht.ml/llms-ctx.txt), which
does not include the optional URLs, and
[llms-ctx-full.txt](https://docs.fastht.ml/llms-ctx-full.txt), which
does include them. They are created using the
[`llms_txt2ctx`](https://llmstxt.org/intro.html#cli) command line
application, and the FastHTML documentation includes information for
users about how to use them.

The versatility of llms.txt files means they can serve many purposes -
from helping developers find their way around software documentation, to
giving businesses a way to outline their structure, or even breaking
down complex legislation for stakeholders. They’re just as useful for
personal websites where they can help answer questions about someone’s
CV, for e-commerce sites to explain products and policies, or for
schools and universities to provide quick access to their course
information and resources.

Note that all [nbdev](https://nbdev.fast.ai/) projects now create .md
versions of all pages by default. All Answer.AI and fast.ai software
projects using nbdev have had their docs regenerated with this feature.
For an example, see the [markdown
version](https://fastcore.fast.ai/docments.html.md) of [fastcore’s
docments module](https://fastcore.fast.ai/docments.html).

## Format

At the moment the most widely and easily understood format for language
models is Markdown. Simply showing where key Markdown files can be found
is a great first step. Providing some basic structure helps a language
model to find where the information it needs can come from.

The `llms.txt` file is unusual in that it uses Markdown to structure the
information rather than a classic structured format such as XML. The
reason for this is that we expect many of these files to be read by
language models and agents. Having said that, the information in
llms.txt follows a specific format and can be read using standard
programmatic-based tools.

The llms.txt file spec is for files located in the root path `/llms.txt`
of a website (or, optionally, in a subpath). A file following the spec
contains the following sections as markdown, in the specific order:

- An H1 with the name of the project or site. This is the only required
  section
- A blockquote with a short summary of the project, containing key
  information necessary for understanding the rest of the file
- Zero or more markdown sections (e.g. paragraphs, lists, etc) of any
  type except headings, containing more detailed information about the
  project and how to interpret the provided files
- Zero or more markdown sections delimited by H2 headers, containing
  “file lists” of URLs where further detail is available
  - Each “file list” is a markdown list, containing a required markdown
    hyperlink `[name](url)`, then optionally a `:` and notes about the
    file.

Here is a mock example:

``` markdown
# Title

> Optional description goes here

Optional details go here

## Section name

- [Link title](https://link_url): Optional link details

## Optional

- [Link title](https://link_url)
```

Note that the “Optional” section has a special meaning—if it’s included,
the URLs provided there can be skipped if a shorter context is needed.
Use it for secondary information which can often be skipped.

## Existing standards

llms.txt is designed to coexist with current web standards. While
sitemaps list all pages for search engines, `llms.txt` offers a curated
overview for LLMs. It can complement robots.txt by providing context for
allowed content. The file can also reference structured data markup used
on the site, helping LLMs understand how to interpret this information
in context.

The approach of standardising on a path for the file follows the
approach of `/robots.txt` and `/sitemap.xml`. robots.txt and `llms.txt`
have different purposes—robots.txt is generally used to let automated
tools what access to a site is considered acceptable, such as for search
indexing bots. On the other hand, `llms.txt` information will often be
used on demand when a user explicitly requesting information about a
topic, such as when including a coding library’s documentation in a
project, or when asking a chat bot with search functiontionality for
information. Our expectation is that `llms.txt` will mainly be useful
for *inference*, i.e. at the time a user is seeking assistance, as
opposed to for *training*. However, perhaps if `llms.txt` usage becomes
widespread, future training runs could take advantage of the information
in `llms.txt` files too.

sitemap.xml is a list of all the indexable human-readable information
available on a site. This isn’t a substitute for `llms.txt` since it:

- Often won’t have the LLM-readable versions of pages listed
- Doesn’t include URLs to external sites, even although they might be
  helpful to understand the information
- Will generally cover documents that in aggregate will be too large to
  fit in an LLM context window, and will include a lot of information
  that isn’t necessary to understand the site.

## Example

Here’s an example of `llms.txt`, in this case a cut down version of the
file used for the FastHTML project (see also the [full
version](https://docs.fastht.ml/llms.txt):

``` markdown
# FastHTML

> FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore's `FT` "FastTags" into a library for creating server-rendered hypermedia applications.

Important notes:

- Although parts of its API are inspired by FastAPI, it is *not* compatible with FastAPI syntax and is not targeted at creating API services
- FastHTML is compatible with JS-native web components and any vanilla JS library, but not with React, Vue, or Svelte.

## Docs

- [FastHTML quick start](https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html.md): A brief overview of many FastHTML features
- [HTMX reference](https://raw.githubusercontent.com/path/reference.md): Brief description of all HTMX attributes, CSS classes, headers, events, extensions, js lib methods, and config options

## Examples

- [Todo list application](https://raw.githubusercontent.com/path/adv_app.py): Detailed walk-thru of a complete CRUD app in FastHTML showing idiomatic use of FastHTML and HTMX patterns.

## Optional

- [Starlette full documentation](https://gist.githubusercontent.com/path/starlette-sml.md): A subset of the Starlette documentation useful for FastHTML development.
```

To create effective `llms.txt` files, consider these guidelines: Use
concise, clear language. When linking to resources, include brief,
informative descriptions. Avoid ambiguous terms or unexplained jargon.
Run a tool that expands your `llms.txt` file into an LLM context file
and test a number of language models to see if they can answer questions
about your content.

## Directories

Here are a few directories that list the `llms.txt` files available on
the web:

- [llmstxt.site](https://llmstxt.site/)
- [directory.llmstxt.cloud](https://directory.llmstxt.cloud/)

## Next steps

The `llms.txt` specification is open for community input. A [GitHub
repository](https://github.com/AnswerDotAI/llms-txt) hosts [this
informal
overview](https://github.com/AnswerDotAI/llms-txt/blob/main/nbs/index.md),
allowing for version control and public discussion. A [community discord
channel](https://discord.gg/aJPygMvPEN) is available for sharing
implementation experiences and discussing best practices.</doc><doc title="Python library docs" desc="Docs for `llms-txt` python lib"># Python module & CLI



Given an `llms.txt` file, this provides a CLI and Python API to parse
the file and create an XML context file from it. The input file should
follow this format:

    # FastHTML

    > FastHTML is a python library which...

    When writing FastHTML apps remember to:

    - Thing to remember

    ## Docs

    - [Surreal](https://host/README.md): Tiny jQuery alternative with Locality of Behavior
    - [FastHTML quick start](https://host/quickstart.html.md): An overview of FastHTML features

    ## Examples

    - [Todo app](https://host/adv_app.py)

    ## Optional

    - [Starlette docs](https://host/starlette-sml.md): A subset of the Starlette docs

## Install

``` sh
pip install llms-txt
```

## How to use

### CLI

After installation,
[`llms_txt2ctx`](https://llmstxt.org/core.html#llms_txt2ctx) is
available in your terminal.

To get help for the CLI:

``` sh
llms_txt2ctx -h
```

To convert an `llms.txt` file to XML context and save to `llms.md`:

``` sh
llms_txt2ctx llms.txt > llms.md
```

Pass `--optional True` to add the ‘optional’ section of the input file.

### Python module

``` python
from llms_txt import *
```

``` python
samp = Path('llms-sample.txt').read_text()
```

Use [`parse_llms_file`](https://llmstxt.org/core.html#parse_llms_file)
to create a data structure with the sections of an llms.txt file (you
can also add `optional=True` if needed):

``` python
parsed = parse_llms_file(samp)
list(parsed)
```

    ['title', 'summary', 'info', 'sections']

``` python
parsed.title,parsed.summary
```

    ('FastHTML',
     'FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore\'s `FT` "FastTags" into a library for creating server-rendered hypermedia applications.')

``` python
list(parsed.sections)
```

    ['Docs', 'Examples', 'Optional']

``` python
parsed.sections.Optional[0]
```

``` json
{ 'desc': 'A subset of the Starlette documentation useful for FastHTML '
          'development.',
  'title': 'Starlette full documentation',
  'url': 'https://gist.githubusercontent.com/jph00/809e4a4808d4510be0e3dc9565e9cbd3/raw/9b717589ca44cedc8aaf00b2b8cacef922964c0f/starlette-sml.md'}
```

Use [`create_ctx`](https://llmstxt.org/core.html#create_ctx) to create
an LLM context file with XML sections, suitable for systems such as
Claude (this is what the CLI calls behind the scenes).

``` python
ctx = create_ctx(samp)
```

``` python
print(ctx[:300])
```

    <project title="FastHTML" summary='FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore&#39;s `FT` "FastTags" into a library for creating server-rendered hypermedia applications.'>
    Remember:

    - Use `serve()` for running uvicorn (`if __name__ == "__main__"` is not

### Implementation and tests

To show how simple it is to parse `llms.txt` files, here’s a complete
parser in \<20 lines of code with no dependencies:

``` python
from pathlib import Path
import re,itertools

def chunked(it, chunk_sz):
    it = iter(it)
    return iter(lambda: list(itertools.islice(it, chunk_sz)), [])

def parse_llms_txt(txt):
    "Parse llms.txt file contents in `txt` to a `dict`"
    def _p(links):
        link_pat = '-\s*\[(?P<title>[^\]]+)\]\((?P<url>[^\)]+)\)(?::\s*(?P<desc>.*))?'
        return [re.search(link_pat, l).groupdict()
                for l in re.split(r'\n+', links.strip()) if l.strip()]

    start,*rest = re.split(fr'^##\s*(.*?$)', txt, flags=re.MULTILINE)
    sects = {k: _p(v) for k,v in dict(chunked(rest, 2)).items()}
    pat = '^#\s*(?P<title>.+?$)\n+(?:^>\s*(?P<summary>.+?$)$)?\n+(?P<info>.*)'
    d = re.search(pat, start.strip(), (re.MULTILINE|re.DOTALL)).groupdict()
    d['sections'] = sects
    return d
```

We have provided a test suite in `tests/test-parse.py` and confirmed
that this implementation passes all tests.</doc><doc title="ed demo" desc="Tongue-in-cheek example of how llms.txt could be used in the classic `ed` editor, used to show how editors could incorporate llms.txt in general.">

# `ed`, the standard text editor

In order to understand how llms.txt can be used with editors and IDEs,
let’s look at how `ed`, the [standard text
editor](https://www.gnu.org/fun/jokes/ed-msg.html), could work (assuming
it’s updated to use this proposal). In our example we will look at how
the user might then tell `ed` to retrieve the LLM docs from
[docs.fastht.ml](https://docs.fastht.ml), and then use the results to
write a simple [FastHTML](https://fastht.ml) web app.

Even if you use a non-standard editor or IDE such as vscode, Cursor,
vim, or Emacs, your software’s interaction with `/llms.txt` would look
similar to this general approach.

``` sh
$ ed
* H
```

Our user starts `ed` and enables helpful error messages (just for the
purpose of this walkthru - obviously a real `ed` user doesn’t need
“helpful error messages”).

``` sh
* L docs.fastht.ml
Checking for /llms.txt at docs.fastht.ml...
Found /llms.txt. Parsing...
Fetching URLs from "Docs" section...  Fetching URLs from "Examples" section...
Skipping "Optional" section for brevity.
Creating XML-based context for Claude...  Context created and loaded.
```

The user invokes the hypothetical `L` (load) command, which in this
LLM-enhanced version of `ed` retrieves and processes the `llms.txt`
file. `ed` checks for the file (if it didn’t exist, it would fall back
to scraping the HTML of the website the old-fashioned way), parses it,
fetches the relevant URLs, and creates an XML-based context suitable for
Claude (perhaps an `ed` config file could be used to choose what LLM to
use, and would determine how the context is formatted). All of this
happens with the characteristic silence of `ed`, broken only by these
reassuring progress messages.

``` sh
* x Create a simple FastHTML app which outputs 'Hello, World!', in a <div>.
Analyzing context and prompt...
Generating FastHTML app...
App written to buffer.
```

Next, our user invokes the hypothetical `x` (eXecute AI) command,
providing instructions for the LLM to create a simple FastHTML app. In
the world of LLM-enhanced `ed`, this is understood as a request to
generate code based on the given prompt and the previously loaded
context.

``` sh
* n
5
* p
from fasthtml.common import *
app,rt = fast_app()
@rt
def index(): return div("Hello, World!")
serve()
```

The editor analyzes the loaded context along with the provided prompt,
generates the FastHTML app, and writes it to the buffer. The user then
views the generated app line count (`n`) and contents (`p`), marveling
at how much functionality is packed into those 5 lines.

``` sh
*w hello_world.py
5
*q
```

Finally, our user saves the app to a file and quits `ed`, presumably to
run their new FastHTML app and reflect on the unexpected productivity
boost provided by their trusty line editor.</doc></docs></project>



================================================
File: nbs/llms-sample.txt
================================================
# FastHTML

> FastHTML is a python library which brings together Starlette, Uvicorn, HTMX, and fastcore's `FT` "FastTags" into a library for creating server-rendered hypermedia applications.

Remember:

- Use `serve()` for running uvicorn (`if __name__ == "__main__"` is not needed since it's automatic)
- When a title is needed with a response, use `Titled`; note that that already wraps children in `Container`, and already includes both the meta title as well as the H1 element.

## Docs

- [FastHTML quick start](https://docs.fastht.ml/tutorials/quickstart_for_web_devs.html.md): A brief overview of FastHTML features
- [HTMX reference](https://raw.githubusercontent.com/bigskysoftware/htmx/master/www/content/reference.md): Brief description of all HTMX attributes, CSS classes, headers, events, extensions, js lib methods, and config options
- [Starlette quick guide](https://gist.githubusercontent.com/jph00/e91192e9bdc1640f5421ce3c904f2efb/raw/61a2774912414029edaf1a55b506f0e283b93c46/starlette-quick.md)

## Examples

- [Todo list application](https://raw.githubusercontent.com/AnswerDotAI/fasthtml/main/examples/adv_app.py): Detailed walk-thru of a complete CRUD app in FastHTML showing idiomatic use of FastHTML and HTMX patterns.

## Optional

- [Starlette full documentation](https://gist.githubusercontent.com/jph00/809e4a4808d4510be0e3dc9565e9cbd3/raw/9b717589ca44cedc8aaf00b2b8cacef922964c0f/starlette-sml.md): A subset of the Starlette documentation useful for FastHTML development.




================================================
File: nbs/llms.txt
================================================
# llms.txt

> A proposal that those interested in providing LLM-friendly content add a /llms.txt file to their site. This is a markdown file that provides brief background information and guidance, along with links to markdown files providing more detailed information.

## Docs

- [llms.txt proposal](https://llmstxt.org/index.md): The proposal for llms.txt
- [Python library docs](https://llmstxt.org/intro.html.md): Docs for `llms-txt` python lib
- [ed demo](https://llmstxt.org/ed-commonmark.md): Tongue-in-cheek example of how llms.txt could be used in the classic `ed` editor, used to show how editors could incorporate llms.txt in general.




================================================
File: nbs/llmstxt-js.html
================================================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>llms.txt Parser in JavaScript</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; padding: 20px; }
        pre { background-color: #f4f4f4; padding: 10px; border-radius: 5px; overflow-x: auto; }
        h2 { margin-top: 20px; }
    </style>
</head>
<body>
    <h1>llms.txt Parser in JavaScript</h1>
    <p>This page demonstrates a JavaScript implementation of the llms.txt parser. View the source to see the JavaScript being run here. When you're done, you can <a href="/">return home</a>.</p>

    <h2>Input:</h2>
    <pre id="input"></pre>

    <h2>Parser Output:</h2>
    <pre id="output"></pre>

    <script>
        function parseLLMsTxt(txt) {
            function parseLinks(links) {
                const linkPat = /-\s*\[(?<title>[^\]]+)\]\((?<url>[^\)]+)\)(?::\s*(?<desc>.*?))?$/gm;
                return Array.from(links.matchAll(linkPat)).map(match => match.groups);
            }

            const [start, ...rest] = txt.split(/^##\s*(.*?)$/m);
            const sections = Object.fromEntries(
                Array.from({ length: Math.floor(rest.length / 2) }, (_, i) => [
                    rest[i * 2],
                    parseLinks(rest[i * 2 + 1])
                ])
            );

            const pat = /^#\s*(?<title>.+?$)\n+(?:^>\s*(?<summary>.+?$))?\n+(?<info>.*)/ms;
            const match = start.trim().match(pat);
            const result = { ...match.groups, sections };

            return result;
        }

        // Test input
        const testInput = `# Title

> Optional description goes here

Optional details go here

## Section name

- [Link title](https://link_url): Optional link details

## Optional

- [Link title](https://link_url)`;

        // Display input
        document.getElementById('input').textContent = testInput;

        // Parse and display output
        const result = parseLLMsTxt(testInput);
        document.getElementById('output').textContent = JSON.stringify(result, null, 2);
    </script>
</body>
</html>



================================================
File: nbs/nbdev.qmd
================================================
---
title: "How to help LLMs understand your nbdev project"
date: 2024-01-20
author: "Radek Osmulski"
description: "A practical guide to making your nbdev library LLM-friendly using llms.txt, with automation techniques and implementation examples."
---

## Overview

This tutorial demonstrates how to add `llms.txt` to your nbdev project, creating a clear interface between your code and LLMs. You'll learn to generate `llms-ctx.txt` and `llms-ctx-full.txt` files and integrate them with your documentation.

While this guide focuses on `nbdev`, the underlying principles and tools are framework-agnostic and can help make any codebase more accessible to LLMs.

Let's explore how to implement this.

## The key ingredient: llms.txt

The foundation of LLM-friendly documentation is the `llms.txt` file. At its core, it is just a Markdown file with information about your library found at a specific URL (root of your site followed by `/llms.txt`).

However, it needs to follow a certain structure as outlined in the [llms.txt](https://llmstxt.org/#format) format.

Do not be intimidated by the specification, though. In reality, it offers a lot of flexibility and by conforming to it you'll gain access to several very helpful tools that we will look at in a second.

First, let's start working on our `llms.txt` file. If you would like to, you can open your favorite editor and start working on an `llms.txt` for your library as we go along.

Here is how the `llms.txt` file could begin:

```markdown
# FastHTML

> FastHTML is a python library which...

When writing FastHTML apps remember to:

- Thing to remember
```

The required elements are:

- the H1 header (FastHTML)
- a blockquote with a short summary of the project (FastHTML is a python library which...)

And they can optionally be followed by zero or more paragraphs and lists. Usually, this is the place where you would add a short description of your library.

The description can be as simple as this (this is an excerpt from the [llms.txt](https://fastcore.fast.ai/llms.txt) for [fastcore](https://fastcore.fast.ai/)):

```
Here are some tips on using fastcore:

- **Liberal imports**: Utilize `from fastcore.module import *` freely. The library is designed for safe wildcard imports.
- **Enhanced list operations**: Substitute `list` with `L`. This provides advanced indexing, method chaining, and additional functionality while maintaining list-like behavior.
- **Extend existing classes**: Apply the `@patch` decorator to add methods to classes, including built-ins, without subclassing. This enables more flexible code organization.
```

Below are a few ideas on how to make writing the description feel even more seamless:

- Consider the content you already have that can be used as a starting point (e.g. your project's README, blog posts and articles, social media discussions, etc.)
- Think of how you would describe your library to a new team member --- this often yields the right balance of precision and comprehension.
- Use an LLM to help you synthetize content from multiple sources into cohesive prose (though you might need to do some post-processing to combat the LLM's tendency to be verbose).

### Adding resource sections

After the optional description, you can include zero or more sections starting with an H2 heading and containing links to supplementary resources.

Markdown files are strongly recommended here as they offer a good balance of structure and readability. You could attempt linking to other formats, but your results may vary. For instance, HTML tends to be verbose, and formats like CSV rarely contain information that lends itself well to documenting functionality.

Here's an example of what this section might look like:

```markdown
## Docs

- [Surreal](https://host/README.md): Tiny jQuery alternative with Locality of Behavior
- [FastHTML quick start](https://host/quickstart.html.md): An overview of FastHTML features

## Examples

- [Todo app](https://host/adv_app.py)
```

### The Optional section

If you'd like to, you can include a section with `Optional` as the heading. This section has a special meaning and provides a mechanism for managing context size. Resources listed in this section appear only in `llms-ctx-full.txt`, while being omitted from `llms-ctx.txt`. This allows the user (be that a human or an agent) to choose the right amount of context based on their use case and the capabilities of the LLM they plan to use.

- `llms.txt`: just the initial section with an optional description and optional resource sections with unexpanded links
- `llms-ctx.txt`: as above but with links expanded apart from the 'Optional' section
- `llms-ctx-full.txt`: all sections with expanded links

Here is a small example of the `Optional` section:

```markdown
## Optional

- [Starlette docs](https://host/starlette-sml.md): A subset of the Starlette docs
```

Your `llms.txt` file is now complete! Time to give yourself a pat on the back for a job well done and let's move on to the next, automated step.

## Generating context files

The [llms-txt](https://llmstxt.org/intro.html) library automates the process of generating context files from your `llms.txt`. It can be used either through its CLI interface or as a Python module.

Using the CLI:

```bash
llms_txt2ctx llms.txt --save_nbdev_fname llms-ctx.txt
```

Or via Python:

```python
from llms_txt import *
samp = Path('llms-sample.txt').read_text()
parsed = parse_llms_file(samp)
```

Both approaches read your `llms.txt` file and retrieve the linked content. This is the process that takes your `llms.txt` and turns it into `llms-ctx.txt` and `llms-ctx-full.txt`.

But there is another very exciting library --- [pysymbol-llm](https://github.com/AnswerDotAI/pysymbol-llm) --- that will allow us to add even more useful information in an automated way.

## Enhancing context with API reference

While LLMs generally understand high-level concepts, they often struggle with implementation details, especially when their training data is outdated. Providing a comprehensive list of your library's symbols - functions, classes, and their documentation - helps bridge this gap.

This is where the [pysymbol-llm](https://github.com/AnswerDotAI/pysymbol-llm) library enters the picture. It generates a complete API reference in Markdown, extracting existing docstrings along the way.

This is a short excerpt from the [apilist.txt](https://fastcore.fast.ai/apilist.txt) for `fastcore`:

```markdown
# fastcore Module Documentation

## fastcore.ansi

> Filters for processing ANSI colors.

- `def strip_ansi(source)`
    Remove ANSI escape codes from text.

- `def ansi2html(text)`
    Convert ANSI colors to HTML colors.

- `def ansi2latex(text)`
    Convert ANSI colors to LaTeX colors.
```

The tool works great even with larger libraries. For instance, generating the API reference for numpy requires just one command:

```bash
pysym2md numpy
```

To implement this in your project, generate an `apilist.txt`, serve it alongside your documentation, and reference it from your `llms.txt` file.

## Configuration

The final step is to configure your nbdev project to generate and serve these context files. This requires three changes:

1. Add your `llms.txt` file to the `nbs` directory of your project.

2. Add the required dependencies to `settings.ini`:
```
dev_requirements = pysymbol_llm llms-txt
```
3. Configure Quarto's build process in `nbs/_quarto.yml`:
```
project:
  type: website
  pre-render:
    - pysym2md --output_file apilist.txt nbdev
  post-render:
    - llms_txt2ctx llms.txt --optional true --save_nbdev_fname llms-ctx-full.txt
    - llms_txt2ctx llms.txt --save_nbdev_fname llms-ctx.txt
  resources:
    - "*.txt"
```

Remember to manually add a link to the generated `apilist.txt` in your `llms.txt` file. Once you commit these changes and rebuild your docs, your library will be ready for deeper, more accurate conversations with LLMs!

## Learning from examples

It is often useful to study how others went about implementing the thing we are working on. The [fastcore](https://fastcore.fast.ai/llms.txt) and [FastHTML](https://docs.fastht.ml/) projects offer a good reference, and you can find additional examples in the [llmstxt.site](https://llmstxt.site/) and [llmstxt.cloud](https://directory.llmstxt.cloud/) directories.

To see all the necessary changes in one place, here's a [complete example](https://github.com/AnswerDotAI/nbdev/pull/1485/files) of adding `llms.txt` to an existing nbdev project.

Providing the right context opens up new possibilities for AI-assisted development and exploring topics you might want to learn more about. We hope this guide helps you and the users of your library take advantage of these exciting new tools.


================================================
File: nbs/nbdev.yml
================================================
project:
  output-dir: _docs

website:
  title: "llms-txt"
  site-url: "https://llmstxt.org/"
  description: "The /llms.txt file, helping language models use your website"
  repo-branch: main
  repo-url: "https://github.com/AnswerDotAI/llms-txt"



================================================
File: nbs/sidebar.yml
================================================
website:
  sidebar:
    contents:
      - index.md
      - section: Code
        contents:
          - 00_intro.ipynb
          - 01_core.ipynb
          - text: JavaScript
            href: llmstxt-js.html
      - section: Editors and IDEs
        contents:
          - ed.md
      - section: Tutorials
        contents:
          - domains.md
          - nbdev.qmd


================================================
File: nbs/styles.css
================================================
.cell { margin-bottom: 1rem; }
.cell > .sourceCode { margin-bottom: 0; }
.cell-output > pre { margin-bottom: 0; }

.cell-output > pre, .cell-output > .sourceCode > pre, .cell-output-stdout > pre {
  margin-left: 0.8rem;
  margin-top: 0;
  background: none;
  border-left: 2px solid lightsalmon;
  border-top-left-radius: 0;
  border-top-right-radius: 0;
}

.cell-output > .sourceCode { border: none; }

.cell-output > .sourceCode {
  background: none;
  margin-top: 0;
}

div.description {
  padding-left: 2px;
  padding-top: 5px;
  font-size: 1.25rem;
  color: rgba(0, 0, 0, 0.60);
  opacity: 70%;
}

.quarto-figure:has(img.floatr) {
  float:right;
  margin-left: 1rem;
  margin-bottom: 0.5rem;
  margin-top: 0.5rem;
}

.quarto-figure:has(img.floatr) figcaption {
  text-align: center;
  width: 100%;
}

.quarto-figure:has(img.floatl) {
  float: left;
  margin-right: 1rem;
  margin-bottom: 0.5rem;
  margin-top: 0.5rem;
}

.quarto-figure:has(img.floatl) figcaption {
  text-align: center;
  width: 100%;
}




================================================
File: tests/test-parse.py
================================================
import unittest
from llms_txt.miniparse import parse_llms_txt

class TestParseLlmsFileShort(unittest.TestCase):
    def test_basic_parsing(self):
        txt = """# Title

> Optional description goes here

Optional details go here

## Section name

- [Link title](https://link_url): Optional link details

## Optional

- [Link title](https://link_url)
"""
        result = parse_llms_txt(txt)
        self.assertEqual(result['title'], 'Title')
        self.assertEqual(result['summary'], 'Optional description goes here')
        self.assertEqual(result['info'], 'Optional details go here')
        self.assertIn('Section name', result['sections'])
        self.assertIn('Optional', result['sections'])
        self.assertEqual(len(result['sections']['Section name']), 1)
        self.assertEqual(len(result['sections']['Optional']), 1)

    def test_multiple_links(self):
        txt = """# Another Title

> Another description

More details

## Links

- [Google](https://google.com): Search engine
- [OpenAI](https://openai.com)

## More Info

- [Python](https://python.org): Programming language
"""
        result = parse_llms_txt(txt)
        self.assertEqual(result['title'], 'Another Title')
        self.assertEqual(result['summary'], 'Another description')
        self.assertEqual(result['info'], 'More details')
        self.assertEqual(len(result['sections']['Links']), 2)
        self.assertEqual(len(result['sections']['More Info']), 1)

    def test_missing_optional_fields(self):
        txt = """# Only Title

Only details here

## Section

- [Item](https://example.com)
"""
        result = parse_llms_txt(txt)
        self.assertEqual(result['title'], 'Only Title')
        self.assertIsNone(result.get('summary'))
        self.assertEqual(result['info'], 'Only details here')
        self.assertIn('Section', result['sections'])
        self.assertEqual(len(result['sections']['Section']), 1)

    def test_no_links(self):
        txt = """# No Links Title

> No description

Some details without links
"""
        result = parse_llms_txt(txt)
        self.assertEqual(result['title'], 'No Links Title')
        self.assertEqual(result['summary'], 'No description')
        self.assertEqual(result['info'], 'Some details without links')
        self.assertEqual(result['sections'], {})

unittest.main()



================================================
File: .github/workflows/deploy.yaml
================================================
name: Deploy to GitHub Pages

permissions:
  contents: write
  pages: write

on:
  push:
    branches: [ "main", "master" ]
  workflow_dispatch:
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps: [uses: fastai/workflows/quarto-ghp@master]



================================================
File: .github/workflows/test.yaml.off
================================================
name: CI
on:  [workflow_dispatch, pull_request, push]

jobs:
  test:
    runs-on: ubuntu-latest
    steps: [uses: fastai/workflows/nbdev-ci@master]


